"use strict";(globalThis.webpackChunkdocs_locki_io=globalThis.webpackChunkdocs_locki_io||[]).push([[8130],{7735(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"meher-jnxmas-letscode","metadata":{"permalink":"/blog/meher-jnxmas-letscode","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-16-meher-jnxmas.mdx","source":"@site/blog/2026-01-16-meher-jnxmas.mdx","title":"Lets us code","description":"Project Overview & Vision","date":"2026-01-16T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/blog/tags/civictech","description":"Citizen technologies and open source for the public good"}],"readingTime":2.27,"hasTruncateMarker":false,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meher-jnxmas-letscode","title":"Lets us code","authors":["jnxmas"],"tags":["encode","civictech"]},"unlisted":false,"nextItem":{"title":"\xd2 Capistaine Kick-off","permalink":"/blog/ocapistaine-hackathon-kickoff"}},"content":"### Project Overview & Vision\\n\\n- The core idea is building an **AI-powered civic transparency platform** focused on local democracy, citizen engagement, and real-world issues (starting with inspiration from India, but with potential global scalability).\\n- Goal: Create a standardized, bullshit-free alternative to Twitter/X discussions for civic topics \u2014 avoiding noise and enabling structured transparency for citizens, investors, and \\"democracy islands\\" (e.g., places like Audierne).\\n- It\'s tied to the **\\"Commit to Change\\" AI Agents Hackathon** (powered by Opik / Comet), running ~4 weeks starting mid-January 2026, with categories like Community Impact.\\n\\n### Hackathon Focus & Judging Criteria Emphasis\\n\\n- Heavy emphasis on **Opik integration** for observability, evaluation, metrics, dashboards, experiment tracking, and improving LLM/agent quality.\\n- Key criteria to nail: Functionality, real-world relevance (New Year\u2019s/civic goals), effective LLM/agent use, robust evaluation/monitoring, and deep Opik workflow integration (not just fluff).\\n- Plan: Automate Opik feedback into the platform for a \\"virtuous circle\\" of optimization. Showcase Opik at every stage (dev workflow, runtime monitoring, etc.).\\n- Strategy: Prioritize smooth, meaningful Opik use \u2192 even if some parts feel like \\"fluff,\\" lean into it for judging scores.\\n\\n### Team & Collaboration Setup\\n\\n- You created/invited Meher to the project using team join code: **0e10f89d** (valid until Jan 17, 2026).\\n- Repo: **Ocapistaine** (on GitHub) \u2014 you updated it with:\\n  - Clear license\\n  - Collaboration addendum / agreements\\n  - Docusaurus as submodule for docs\\n  - Project board with tasks (including Opik-specific ones)\\n- You proposed a fair structure for handling prize money / motivation (Meher called it \\"very clean\\" and liked it).\\n- Meher was pending \u2192 accepted invite; you both coordinated joining the hackathon portal/team.\\n- Another collaborator (Vic) self-assigned tasks.\\n- You shared the kickoff doc: https://docs.locki.io/blog/ocapistaine-hackathon-kickoff (titled \\"\xd2 Capistaine Kick-off | AI-Powered Civic Transparency for Local Democracy\\").\\n\\n### Monetization & Long-Term Ideas\\n\\n- You have ideas for monetizing / turning it into a full startup (trust-based, you\'ll share more).\\n- Potential global expansion discussed, but start focused (e.g., India as strong testbed).\\n- References to past hackathon success (you + Satish, 4th place with on-chain 3D objects + AI chatbot).\\n- Avoid overkill like Decidim platforms \u2014 keep it practical and thrilling.\\n\\n### Recent Status & Next Steps\\n\\n- Meher was occasionally busy/catching up (dinner, out, etc.) but engaged.\\n- As of last messages (~Jan 15\u201316, 2026):\\n  - Everyone\'s in the team/repo.\\n  - Ready to start **coding** (both excited: \\"tickles in fingers\\").\\n  - Emphasis on transparent task assignment (\\"tell what we do and do what we tell\\").\\n  - Call happened in Ocapistaine channel.\\n  - Brainstorming better Opik showcases ongoing.\\n\\n**Overall vibe**: Enthusiastic, trusting partnership (\\"I trust you!\\"). You\'re leading repo/docs/setup/strategy; Meher is on board, catching up, and eager to code + highlight Opik. Project is now properly set up and ready to build \u2014 focus on delivering a functional, Opik-heavy prototype for the hackathon deadline."},{"id":"ocapistaine-hackathon-kickoff","metadata":{"permalink":"/blog/ocapistaine-hackathon-kickoff","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-15-let-the-journey-begin.mdx","source":"@site/blog/2026-01-15-let-the-journey-begin.mdx","title":"\xd2 Capistaine Kick-off","description":"AI-Powered Civic Transparency for Local Democracy","date":"2026-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/blog/tags/civictech","description":"Citizen technologies and open source for the public good"}],"readingTime":2.17,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"ocapistaine-hackathon-kickoff","title":"\xd2 Capistaine Kick-off","authors":["jnxmas"],"tags":["encode","civictech"]},"unlisted":false,"prevItem":{"title":"Lets us code","permalink":"/blog/meher-jnxmas-letscode"},"nextItem":{"title":"Project scope - Victor + JNS","permalink":"/blog/victor-intro-project description"}},"content":"**AI-Powered Civic Transparency for Local Democracy**\\n\\n## My 2026 Resolution\\n\\n:::tip The Promise\\nThis year, I will finally understand my local elections and get involved as a citizen.\\n:::\\n\\nSound familiar? Every election cycle, millions of citizens want to participate but face the same wall: scattered documents, administrative jargon, and no time to dig through years of municipal decisions.\\n\\n**This January, I stopped just wishing \u2014 and started building.**\\n\\n\x3c!-- truncate --\x3e\\n\\n## What We\'re Building\\n\\n\xd2 Capistaine is my answer to the civic engagement resolution we\'ve all made (and broken). It\'s an AI-powered transparency tool that:\\n\\n| Feature               | Description                                               |\\n| --------------------- | --------------------------------------------------------- |\\n| **Document Crawling** | Index 4,000+ municipal documents with Firecrawl + OCR     |\\n| **Citizen Q&A**       | Answer questions in plain language via RAG                |\\n| **Quality Tracking**  | Monitor LLM accuracy with Opik (hallucination detection)  |\\n| **Multi-Channel**     | N8N workflows for Facebook, email, and chatbot engagement |\\n\\n:::info Live Platform\\nSupporting [audierne2026.fr](https://audierne2026.fr) \u2014 a participatory democracy platform where citizens co-create the 2026 municipal program.\\n:::\\n\\n## Progress Update (Checkpoint 1)\\n\\n### Status Overview\\n\\n| Component              | Status | Details                                                        |\\n| ---------------------- | :----: | -------------------------------------------------------------- |\\n| **audierne2026.fr**    |   \u2705   | Jekyll platform live, citizens contributing                    |\\n| **Document Corpus**    |   \ud83d\udfe1   | 42 Gwaien bulletins collected, 4,000+ arr\xeat\xe9s identified       |\\n| **Firecrawl Pipeline** |   \ud83d\udd34   | Infrastructure designed, crawling not yet operational          |\\n| **Opik Integration**   |   \ud83d\udfe1   | Tracing architecture planned, awaiting RAG implementation      |\\n| **N8N Workflows**      |   \ud83d\udfe1   | Vaettir repo created, FB/email integration designed            |\\n| **RAG System**         |   \ud83d\udd34   | Vector store + retrieval pipeline pending                      |\\n| **Documentation**      |   \u2705   | [docs.locki.io](https://docs.locki.io) live with methodologies |\\n\\n### What\'s Working\\n\\n- Live participation platform with real citizen contributions\\n- Dual-license structure (Apache 2.0 + ELv2) for open collaboration\\n- Bilingual documentation (EN/FR)\\n- Project planning and task tracking on GitHub\\n\\n### Next Steps\\n\\n1. **Fix Firecrawl pipeline** \u2014 Get municipal document crawling operational\\n2. **Deploy Opik tracing** \u2014 LLM observability from day one\\n3. **Build RAG retrieval** \u2014 With hallucination guardrails\\n4. **Launch citizen Q&A** \u2014 First chatbot interactions\\n\\n## Hackathon Tracks\\n\\n| Track                         | Why We Qualify                                                 |\\n| ----------------------------- | -------------------------------------------------------------- |\\n| **Social & Community Impact** | Civic transparency tool enabling local democracy participation |\\n| **Best Use of Opik**          | LLM-as-judge evaluations + tracing for RAG quality assurance   |\\n\\n:::note Democracy Can\'t Afford Hallucinations\\nWhen citizens ask \\"What happened with the school budget?\\", the answer must be accurate and sourced. Opik helps us guarantee that.\\n:::\\n\\n## Team\\n\\n| Name                      | Role                          | GitHub                                             |\\n| ------------------------- | ----------------------------- | -------------------------------------------------- |\\n| Jean-No\xebl Schilling       | Project Lead / Backend        | [@jnschilling](https://github.com/jnschilling)     |\\n| Victor A                  | Backend Python                | [@zcbtvag](https://github.com/zcbtvag)             |\\n| GurmeherSingh             | ML Engineer                   | [@GurmeherSingh](https://github.com/GurmeherSingh) |\\n| _(open for contributors)_ | Frontend / UX / Communication | \u2014                                                  |\\n\\n## Links\\n\\n| Resource      | URL                                                             | Public/private |\\n| ------------- | --------------------------------------------------------------- | -------------- |\\n| Live Platform | [audierne2026.fr](https://audierne2026.fr)                      | public         |\\n| Documentation | [docs.locki.io](https://docs.locki.io)                          | public         |\\n| GitHub        | [locki-io/ocapistaine](https://github.com/locki-io/ocapistaine) | private ATM    |\\n| Project Board | [GitHub Projects](https://github.com/orgs/locki-io/projects/2)  | public         |\\n\\n---\\n\\n_If AI can help us keep our New Year\'s resolutions, maybe the most impactful one is: becoming a better citizen._"},{"id":"victor-intro-project description","metadata":{"permalink":"/blog/victor-intro-project description","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-14-meeting.md","source":"@site/blog/2026-01-14-meeting.md","title":"Project scope - Victor + JNS","description":"Location: Discord voice chat","date":"2026-01-14T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/blog/tags/meeting","description":"Meeting tag description"}],"readingTime":9.05,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"victor-intro-project description","title":"Project scope - Victor + JNS","authors":["jnxmas"],"tags":["meeting"]},"unlisted":false,"prevItem":{"title":"\xd2 Capistaine Kick-off","permalink":"/blog/ocapistaine-hackathon-kickoff"},"nextItem":{"title":"Hackathon kickoff meeting","permalink":"/blog/encode-kickoff"}},"content":"> Location: Discord voice chat\\n> Attendees: jnxmas, Victor\\n\\n## Overview\\n\\nThis document summarizes a series of project meetings focused on building a community-focused AI application for a local election. The discussions cover team composition and recruitment, defining the project\'s scope for a hackathon, and outlining the technical architecture. Key activities include automating the processing of community contributions, developing a neutral chatbot to compare political programs, and initiating web crawling operations to gather data. The plan involves using technologies like Firecrawl, N8N, Pydantic, and a Retrieval-Augmented Generation (RAG) system, with a strong emphasis on collaborative development practices via GitHub.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Key Topics\\n\\n- Two new potential members from Audierne, France, were identified. They are developers focused on websites but are new to AI and Python, so they are considered to be starting from scratch.\\n- Their primary value is their familiarity with the local context of the project (audierne2026), making them a potential bridge to the local population. They are seen as good candidates for an \\"observer\\" role within the hackathon.\\n- They are connected to one of four local political lists, which is interested in participative community movements.\\n- An Indian developer named Satish, with whom a speaker previously worked on an AWS and Next.js project in a 2023 hackathon, is a potential collaborator. However, he is currently cautious about joining due to being busy with his job.\\n- A French individual named Max, who specializes in SEO and social media strategy, was mentioned but is not a coder.\\n- An Indian machine learning specialist, referred to as \\"Meher,\\" is considering joining. He is seen as a key \\"third guy\\" ML for the application architecture.\\n- There was a concern that the project\'s connection to a local election might disqualify it from the hackathon.\\n- A team member named Rebecca clarified in a general chat that the project is eligible to be submitted under the \\"social community impact\\" category.\\n- The team was advised that all questions should be posted in the general chat, as Rebecca will not be replying to DMs.\\n- Progress has been made on the project\'s GitHub Kanban board, with P0 tasks and some unprioritized tickets added.\\n- The data crawling phase (\\"filecrawl\\") is ready to start with an initial dataset of 150 links and 4,000 PDFs that require OCR. The speaker has paused this work to incorporate more contributions.\\n- The N8N orchestration workflow is nearly complete and ready for deployment.\\n  - It will be hosted on a server with a 6-core CPU and 16 gigabytes of RAM.\\n  - The team will consider moving to Vercel if the server cannot handle the load.\\n- N8N is a low-code/no-code platform for building workflows, and an example was shown for automating posts based on GitHub repository issues.\\n- The setup is encapsulated in Docker, making it easier to run.\\n- The project\'s code and tasks will be managed in the Ocapistan repository on GitHub.\\n- A key initial task is to push the ideation file (`ideation 13.1.2026`) to the main branch to serve as a foundation for future work.\\n- The team will use a feature branch workflow:\\n  - For each task, a developer will create a new feature branch from the main branch.\\n  - Once the task is complete, the branch will be pushed to the repository for review by others.\\n  - After review and debugging, the branch will be merged and closed.\\n- The team agreed to prioritize the Firecrawl operation as the starting point, despite its potential difficulty.\\n- Two team members will conduct parallel trials on different fire crawling tasks to gain experience and share learnings.\\n- Each member should get their own free Firecrawl API key, as they may need to use multiple free accounts by registering with different emails to maximize free API calls.\\n- The initial scraping task will target a list of PDFs from a specific URL (`script marie arete mary`).\\n- PDF processing will require testing various libraries like `pdf2ocr`, Tabula, and `pypdf` to find the most effective one.\\n- The team needs to develop a method to identify and set aside documents that only contain signatures, as this information has no value for the LLM.\\n- The project will use Python with type hinting and Pydantic for data handling to improve code quality.\\n- A modular \\"separation of concerns\\" approach will be used for the ETL (Extract, Transform, Load) process.\\n  - Extraction, transformation, and loading will be handled by separate workflows, likely implemented as three distinct classes.\\n  - This modularity will allow for different extraction methods (e.g., for plain text, HTML with Beautiful Soup, or OCR for PDFs) to be developed and called as needed.\\n- The project will use Ocapistan for code management, N8N for workflows, and a flexible AI provider handled by OPIC.\\n- Team members do not need to work at the same time but must communicate effectively. Progress will be tracked through changes in the project repository.\\n- Developers should assign tasks to themselves and break them down into smaller sub-tasks.\\n- Direct discussions will be necessary when merging work on the same files to resolve conflicts.\\n- **Current Process (Manual):**\\n  - Contributions are received via email.\\n  - They are manually reviewed against a \\"chart of contribution\\" to ensure they meet the criteria.\\n  - If approved, they are manually copy-pasted into a GitHub issue.\\n  - A daily summary of contributions is automatically posted to Facebook via M8N, but this post is anonymous and lacks detail.\\n- **Proposed Automated Process:**\\n  - The goal is to automate the entire workflow from email receipt to GitHub issue creation.\\n  - An AI agent will be developed to judge whether an incoming contribution respects the \\"chart of contribution.\\"\\n  - This agent will be part of the \\"OKAPI stand,\\" which will house all agents and the RAG system for the project.\\n- **Purpose:** After a contribution is validated and becomes a GitHub issue, a \\"creative agent\\" (also called the Okapi Sten proper) will process it.\\n- **Functionality:**\\n  - The agent generates an AI-made reply that contextualizes the new contribution.\\n  - It cross-references the submission with previous contributions in the same category to find echoes and avoid repetition.\\n  - The reply includes links to the sources used to construct the contextualization.\\n- **Handling New vs. Existing Topics:**\\n  - The workflow must handle two cases: when a contribution is for a brand-new category, and when it relates to a previously discussed topic.\\n  - In the latter case, the system will search existing issues and the RAG system to build a comprehensive answer.\\n- **LLM Testing:**\\n  - Grok has been used for initial testing. It was effective at searching for context online (including the audierne2026 project) and generating relevant, though coincidental, replies.\\n  - The team discussed that Grok\'s ability to search and synthesize information acts similarly to a basic RAG system.\\n- **RAG System Development:**\\n  - A dedicated RAG (Retrieval-Augmented Generation) system will be built to avoid repetitive outputs and manage context efficiently.\\n  - The team needs to decide how to store source links and other data for the RAG system, considering a NoSQL database like MongoDB for flexibility. A vector store will be used for training on gathered data.\\n- **Key Dates:**\\n  - The election preparation period is currently underway.\\n  - Contribution collection will continue until at least January 31.\\n  - The election day is around March 15-22.\\n- **February Focus:**\\n  - Work in February will focus purely on developing the chatbot.\\n  - The chatbot will be used to compare the programs of the four enlisted municipal lists.\\n  - It will be designed to provide neutral, impartial comparisons on topics like lodging, culture, and budget realism.\\n- **Using OPIK:**\\n  - The OPIK framework will be used to evaluate every AI interaction to ensure quality and impartiality.\\n  - The team is considering creating a feedback loop where OPIK\'s evaluations could automatically improve the prompts in N8N.\\n- **Maintaining Neutrality:**\\n  - A major challenge is ensuring the chatbot remains neutral and does not generate sycophantic or biased responses based on leading questions from users.\\n  - The system may need multiple prompts to check for constraints like budget, realism, and political neutrality before generating a reply.\\n\\n## Open Issues & Risks\\n\\n- It is unclear how the new team members from Audierne, who have limited technical experience in AI, will be integrated into the project.\\n- The availability of a key potential collaborator, Satish, is uncertain due to his current work commitments.\\n- The machine learning specialist, Meher has not yet confirmed if he will join the team.\\n- It is undecided how to best store source links and data for the RAG system, though a NoSQL database is being considered.\\n- It is unclear which LLMs (e.g., Gemini) will be chosen for the final implementation.\\n- A key challenge will be designing the chatbot to remain neutral and avoid generating biased responses to leading questions.\\n- The project\'s success depends on receiving a sufficient number of community contributions, which requires incentivizing and motivating people to participate.\\n\\n## Action Items\\n\\n- [ ] Prioritize project tasks.\\n- [ ] Set up a server for the Vaettir repo so the team can access it with a password.\\n- [ ] Start by building workflows, with more coding to begin next week.\\n- [ ] Set up an ollama platform to experiment with local LLMs.\\n- [ ] Push the `ideation 13.1.2026` file to the main Ocapistaine repository.\\n- [ ] Each team member to get a free Firecrawl API key.\\n- [ ] Begin experimenting with Firecrawl by creating a new branch on the Ocapistaine repository.\\n- [ ] Start working on scraping the documents from the \\"script marie arret\xe9 maririe\\" task.\\n- [ ] Test different PDF reading libraries (`pdf2ocr`, Tabula, `pypdf`) to determine the best option for the project.\\n\\n> **AI Suggestion**\\n> AI has identified the following issues that were not concluded in the meeting or lack clear action items; please pay attention:\\n>\\n> 1. **Critical Staffing and Team Formation Risk:** The project faces a significant risk of stalling due to unresolved team composition. Two key experts, developer Satish and machine learning specialist \\"Mayer,\\" have not committed to the project, leaving critical skill gaps. A clear action plan is needed to secure their participation or find qualified alternatives immediately to ensure the project can proceed.\\n> 2. **Unresolved Core Chatbot Neutrality:** A fundamental and unresolved challenge is how to technically implement and guarantee the election chatbot\'s neutrality and impartiality. There is no defined strategy for preventing the AI from giving biased responses, especially when faced with leading or manipulative user questions, which poses a major reputational and functional risk to the project\'s core objective.\\n> 3. **Lack of a Defined Community Contribution Workflow:** The entire process for receiving, validating, and integrating community-submitted content is undefined. This includes the creation of an AI agent to automate judging submissions and a clear workflow for handling both new and existing topics. Without this, the project cannot scale or effectively leverage community input, which is stated as a dependency for success.\\n> 4. **Undefined Technical Foundation for Data Processing and Storage:** Key decisions about the project\'s technical architecture are still pending. The team has not selected a database for the RAG system (e.g., NoSQL/MongoDB) or the specific Large Language Models (LLMs) for the final implementation. Furthermore, the method for processing varied document types like PDFs remains uncertain. These foundational decisions must be made to avoid delays in development."},{"id":"encode-kickoff","metadata":{"permalink":"/blog/encode-kickoff","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-13-encode_hackathon.md","source":"@site/blog/2026-01-13-encode_hackathon.md","title":"Hackathon kickoff meeting","description":"Date & Time04:06","date":"2026-01-13T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/blog/tags/meeting","description":"Meeting tag description"}],"readingTime":16.75,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"encode-kickoff","title":"Hackathon kickoff meeting","authors":["jnxmas"],"tags":["meeting"]},"unlisted":false,"prevItem":{"title":"Project scope - Victor + JNS","permalink":"/blog/victor-intro-project description"},"nextItem":{"title":"Locki Labs in 2025 - Introducing Valkyria","permalink":"/blog/locki-in-2025"}},"content":"> Date & Time: 2026-01-13 19:04:06\\n> Location: online presentation\\n> `AI Agent Hackathon` `New Year\'s Resolutions` `AI Evaluation`\\n\\n## Theme\\n\\nThis lecture introduces the \\"Commit to Change AI Agent Hackathon,\\" a four-week online event challenging participants to build AI agents that help users stick to their New Year\'s resolutions. The event offers $30,000 in prizes across five tracks: Productivity, Personal Growth, Social Impact, Health/Wellness, and Financial Health. It emphasizes the importance of AI evaluations, defining them as structured measurements of system behavior. The lecture details the hackathon\'s timeline, submission requirements using the ENCODE platform, and the mandatory use of the OPIC tool for evaluation, guiding participants from ideation to final project submission.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Takeaways\\n\\n1.  Introduction to the Commit to Change AI Agent Hackathon.\\n2.  The hackathon\'s goal is to build AI that turns New Year\'s resolutions into real results.\\n3.  Hackathon registration is required on the Encode Cloud platform for all participants, including those from Luma.\\n4.  The hackathon is sponsored by Comet, with supporting partners Basel and Google DeepMind.\\n5.  This is a four-week online hackathon with up to $30,000 in prizes.\\n6.  Statistics on New Year\'s resolutions: 23% give up within 13 days, and 43% give up by the end of January.\\n7.  Hackathon advice: Start with a problem you have faced and build a unique solution.\\n8.  The hackathon features five thematic tracks: Productivity and Work Habits, Personal Growth and Learning, Social and Community Impact, Health, Fitness and Wellness, and Financial Health.\\n9.  It\'s recommended to focus on one category to create a high-quality, specialized app.\\n10. There is an overall challenge for the \'Best use of OPIC\' for projects showcasing excellent evaluation and observability.\\n\\n## Highlights\\n\\n- `\\"AI evals are what turn that sort of really cool, fun prototype into a system that you can actually iterate on with confidence and start to think about exposing to the real world and to real people.\\"-- Abby`\\n- `\\"What\'s even cooler than a really cool prototype is, in my opinion, a cool tool that you can actually use in the real world on real data. And for that, you need some sort of system of evaluations.\\"-- Abby`\\n- `\\"Evaluation turns guesswork into science.\\"-- Abby`\\n- `\\"AI evaluations are how we turn random iteration into progress, and they give us a repeatable way to measure behavior, compare changes, and improve systematically instead of guessing.\\"-- Abby`\\n\\n## Chapters & Topics\\n\\n### Hackathon Overview and Goal\\n\\n> The Commit to Change AI Agent Hackathon is a four-week online event starting in January 2026, aimed at building AI agents and LLM-powered apps that help people stick to their New Year\'s resolutions and goals. It offers up to $30,000 in prizes.\\n\\n- **Keypoints**\\n  - The hackathon runs for four weeks online.\\n  - The goal is to build AI/LLM apps to help users stick to their goals.\\n  - There\'s a prize pool of up to $30,000.\\n  - It is sponsored by Comet, with support from Basel and Google DeepMind.\\n  - Participants must register on the Encode Cloud platform to get all updates and access resources.\\n- **Explanation**\\n  The hackathon is structured to guide participants from ideation to final submission. It includes workshops, deadlines to ensure progress, and resources provided by sponsors like Comet and partners like Google DeepMind. The central theme is leveraging AI to address the common problem of people giving up on their resolutions. Statistics show 23% of people give up 13 days into January, and 43% give up by the end of the month, highlighting the target audience for the projects.\\n\\n### Hackathon Tracks and Challenges\\n\\n> The hackathon is structured around five thematic tracks for projects, plus an overall challenge. The tracks are: Productivity and Work Habits, Personal Growth and Learning, Social and Community Impact, Health, Fitness and Wellness, and Financial Health. The overall challenge is for the \'Best Use of OPIC\', rewarding projects with excellent evaluation and observability.\\n\\n- **Keypoints**\\n  - Productivity and Work Habits: Build tools for smarter work and better routines.\\n  - Personal Growth and Learning: Build apps for learning new skills or developing self-awareness.\\n  - Social and Community Impact: Build tools for organizing communities or supporting environmental/social action.\\n  - Health, Fitness and Wellness: Build solutions for fitness, mental health, or general well-being.\\n  - Financial Health: Build AI/LLM apps for budgeting, saving, or understanding money.\\n  - Best Use of OPIC: A special category for projects with excellent evaluation and observability.\\n- **Explanation**\\n  Participants should choose one of the five themes to focus their project on. The themes are broad to accommodate a wide range of ideas. The \'Health, Fitness and Wellness\' category is noted as a particularly common area for New Year\'s resolutions. In addition to the thematic challenges, all projects are eligible for the \'Best Use of OPIC\' challenge, sponsored by Comet. This special prize can be won in conjunction with a thematic prize.\\n- **Considerations**\\n- Focus on one category rather than trying to build an app that spans multiple, as an app that does one thing well is better than one that does four things less well.\\n- Start with a problem that you yourself have faced to understand it well.\\n- Come up with a solution that sets you apart from everyone else; build something interesting and unique.\\n- Don\'t just do the bare minimum base idea; build on top of it.\\n- The best use of OPIC category can be won alongside a theme prize, which is the only two-in-one win possible.\\n\\n### Hackathon Timeline and Submission Requirements\\n\\n> The hackathon has a structured timeline with key deadlines and specific submission requirements for the final project. The timeline spans four weeks, starting with ideation, moving to building, and culminating in a final submission.\\n\\n- **Keypoints**\\n  - Week 1: Ideation and Project Creation Deadline.\\n  - Week 2: Building and a workshop on Gemini 3.\\n  - Week 2/3: Mid-hackathon Deadline (submit GitHub repo and description).\\n  - Final Submission Deadline: February 8th, 23:59 UTC-12.\\n  - Required final submission items: Video pitch with demo and public code base.\\n  - Recommended submission items: Hosted site and a presentation.\\n  - The mid-hackathon deadline forces early and regular code commits.\\n- **Explanation**\\n  The timeline is designed to keep participants on track.\\n\\n- Week 1: Launch, ideation, and a \'Project Creation Deadline\' to commit to an idea and team.\\n- Week 2: Start building, with a workshop from Google DeepMind on Gemini 3.\\n- End of Week 2/Start of Week 3: \'Mid-hackathon Deadline\' requiring submission of a GitHub repo and project description. This is not judged but ensures progress.\\n- Final Submission Deadline: February 8th at one minute to midnight, UTC-12. This means you can submit if it\'s still before midnight anywhere in the world.\\n  Final submissions must include a video pitch with a demo, a public codebase, and optionally a hosted site and presentation slides. These requirements are designed to give judges a comprehensive view of the project.\\n- **Considerations**\\n- Do not leave commits until the last minute; make regular commits from the start.\\n- The video pitch is the first impression for judges and needs to capture their attention immediately.\\n- While AI can be used for presentations, it is not recommended to use AI to generate the entire video pitch as it can be \'soul destroying\' for judges.\\n- A hosted site and presentation are optional but highly recommended to strengthen your submission.\\n- Do not submit at the last minute to avoid technical issues or mistakes.\\n\\n### Using the ENCODE Platform\\n\\n> The ENCODE platform is the central hub for the hackathon. It contains all necessary information, resources, and submission portals for participants.\\n\\n- **Keypoints**\\n  - The ENCODE platform is the home for the hackathon.\\n  - Participants must register on the platform to get all emails and updates.\\n  - To create a project and team, use the \'create project\' and \'join team code\' features.\\n  - The platform has a \'Lecture\' section with helpful videos.\\n  - The \'Events\' page lists all workshop links.\\n  - Challenge descriptions and partner resources (Comet docs, Gemini credits, etc.) are available on the platform.\\n  - All submissions are made through the participant\'s personal hackathon page on the platform.\\n- **Explanation**\\n  Participants will use the ENCODE platform for all hackathon-related activities. After the introductory session, participants who joined from Luma must register for the hackathon on the platform to receive emails and updates. The platform is where you create your project, add team members using a \'join code\', find lecture videos, access event links for workshops, read detailed challenge descriptions, and find partner resources like the Comet developer documentation and OPIC quick start guide. All submissions, from the mid-hackathon check-in to the final project, will be done through this platform.\\n\\n### Definition of an AI Evaluation\\n\\n> An evaluation is a structured measurement of a system\'s behavior against criteria we care about. This involves defining the vision of success and failure for the application. The process is a structured way to measure an AI system\'s behavior against defined criteria on representative tasks to support decisions and improve product development.\\n\\n- **Keypoints**\\n  - It\'s a structured measurement of a system\'s behavior.\\n  - It\'s measured against predefined criteria that define success.\\n  - The hardest part is often figuring out the criteria you care about.\\n  - It\'s important to think about success, failure, and potential failure modes from the beginning.\\n  - Failure modes can vary, from harmful content and incorrect outputs to having the wrong tone for a brand.\\n  - An evaluation system is often a set of many individual metrics.\\n  - These individual metrics are aggregated into an overall success score.\\n- **Explanation**\\n  To unpack the definition: \'Structure\' means repeatable and explicit, allowing for comparisons over time. \'Behavior\' refers to what the system does, such as responses, tool calls, latency, or cost. \'Criteria\' is how success is predefined, including accuracy, helpfulness, safety, or product-specific outcomes. An evaluation system is typically a set of many metrics aggregated into an overall success score.\\n\\n### The Four Ingredients of a Good Evaluation\\n\\n> A good evaluation generally consists of four main ingredients: a target, a test set/task, a scoring method, and a decision rule. These components work together to form a repeatable and useful evaluation process.\\n\\n- **Keypoints**\\n  - A target: The specific capability or outcome being tested (e.g., factual QA, customer support resolution).\\n  - A test set or task: Examples representing the real world, including edge cases and outliers.\\n  - A scoring method: A metric, rubric, or judge (human or LLM) to score performance, including how individual scores are aggregated (e.g., math equation, voting system).\\n  - A decision rule: Determines what to do with the results, such as shipping a feature, rolling it back, or retraining. It often includes a threshold (e.g., \'if the success rate improves by at least 20%, then ship it\').\\n- **Explanation**\\n  First, the \'target\' specifies the capability or outcome being tested (e.g., factual QA, tool use). Second, the \'test set\' includes real-world examples and edge cases. Third, the \'scoring method\' defines how performance is measured (e.g., a metric, rubric, LLM judge) and how scores are aggregated. Finally, the \'decision rule\' dictates the action to be taken based on the evaluation score, such as shipping a feature or rolling it back, often based on a threshold or comparison to a baseline.\\n\\n### Difference Between Benchmarks and Application Evals\\n\\n> Benchmarks are standardized test sets, often from academia, used for broad comparisons across different models. Application evaluations are specific to a product, matching its real distribution of prompts, workflows, and constraints, and are used to determine if a system is good enough to ship.\\n\\n- **Keypoints**\\n  - Benchmarks are standardized tests for comparing models.\\n  - Application evals are product-specific tests for system performance.\\n  - Benchmarks assess general ability; application evals assess behavior in a specific context.\\n  - Benchmarks score the model in isolation; application evals test the entire system (prompts, RAG, tools).\\n  - The biggest gap is distribution: benchmarks rarely match real traffic, edge cases, or domain language.\\n  - A model can score high on a benchmark but fail in your specific application context.\\n  - Benchmarks help narrow model choices; product evals tell you if the system is ready to ship.\\n- **Explanation**\\n  Benchmarks are useful for getting a quick read on a model\'s general capabilities and comparing model families (e.g., comparing one foundation model to another). However, a model can perform well on a benchmark and still fail in production because production success depends on behavior in a specific context. Application evals test the entire system\u2014including prompts, RAG, and tool use\u2014against your specific definition of success. The main gap is that benchmarks rarely match the distribution of real-world traffic, including edge cases and domain-specific language.\\n\\n### Challenges in Evaluating LLMs\\n\\n> Evaluating LLMs and agentic systems is inherently difficult due to several unique challenges that distinguish them from traditional software. These challenges include non-determinism, the subjectivity of tasks, high sensitivity to inputs, and the possibility of silent failures.\\n\\n- **Keypoints**\\n  - LLMs are non-deterministic: The same input does not guarantee the same output, making traditional monitoring difficult.\\n  - Many AI tasks lack a single correct answer: Tasks like summarization or content generation can have multiple valid outputs, making simple match comparisons insufficient.\\n  - Heuristic methods are largely ineffective: Simple heuristics like regex or pattern matching don\'t consider semantic meaning.\\n  - Evaluation metrics are subjective: Concepts like relevance, coherence, and conciseness are open to interpretation.\\n  - Human feedback is imperfect: It is expensive, can be inconsistent, and is difficult to scale.\\n  - LLMs are extremely sensitive to prompts and context: Small changes can drastically alter the output.\\n  - LLMs have silent failures: A system can produce a correct output but use flawed or unsafe reasoning to get there, which is a failure that isn\'t immediately obvious.\\n  - There\'s no standard set of evaluation metrics applicable to all products.\\n- **Explanation**\\n  LLMs are non-deterministic, meaning the same input can produce different outputs, making hard-coded logic and simple error handling ineffective. Many tasks like summarization have no single correct answer, so simple matching (like regex) fails; semantic meaning must be considered. Metrics like \'relevance\' are subjective, and even human annotators may disagree. LLMs are also very sensitive to small changes in prompts or context. Finally, they can have \'silent failures,\' where the final output appears correct, but the underlying reasoning was flawed or discriminatory, which can only be caught by observing the entire process.\\n- **Examples**\\n  > Traditional software monitoring uses tools like try-and-accept clauses to handle anticipated errors. However, with LLMs, we cannot anticipate every single possible output they might produce due to their non-deterministic nature. Therefore, a simple accept clause is not a scalable or effective solution for handling LLM failures.\\n\\n### Challenges in Monitoring AI Agents\\n\\n> Monitoring AI agents is significantly more complex than monitoring standalone Large Language Models (LLMs) because agents are composed of multiple LLMs and external tools, leading to compounded variability and numerous failure modes.\\n\\n- **Keypoints**\\n  - Agents are built on top of LLMs, inheriting their non-deterministic nature.\\n  - Chaining multiple LLM calls compounds variability and potential for error.\\n  - Agents are multi-step workflows with more moving parts and thus more failure modes.\\n  - The use of external tools introduces external dependencies, potential silent failures, and added unpredictability.\\n  - Dynamic memory and context in agents can lead to intent drift and performance degradation over time.\\n  - Evaluation of agents must include not just the final output, but also the reasoning, tool choice, and every step along the way.\\n- **Explanation**\\n  Agents are built on top of LLMs, which are non-deterministic systems. When you chain multiple LLM calls together, as is common in agents, the variability and potential for error at the beginning of the chain can be amplified through subsequent steps. Agents are also multi-step workflows with more moving parts, external tool dependencies (which can have silent failures), and dynamic memory/context. This complexity increases the number of failure modes and necessitates a more thorough evaluation process that goes beyond just the final output to include reasoning, tool choice, and each intermediate step. As agents are deployed in real-world scenarios with more complex workflows and higher usage frequency, tracking all these aspects becomes extremely difficult.\\n- **Examples**\\n  > A user engaged with a dealership\'s chatbot and managed to get it to agree to sell them a Chevy Tahoe for one US dollar. The chatbot even stated \'no takesies backsies\'. This agreement was legally upheld in court, forcing the dealership to sell the car for one dollar.\\n  - This example illustrates a real-world consequence of an AI agent (chatbot) going wrong.\\n  - The non-deterministic and unconstrained nature of the LLM powering the chatbot led to an unintended and costly outcome for the dealership.\\n  - It highlights the critical need for robust monitoring and evaluation of agent behavior to prevent such incidents.\\n  - The phrase \'no takesies backsies\' being considered legally binding underscores how interactions with AI can have unforeseen legal ramifications.\\n\\n### Hackathon Logistics and Rules\\n\\n> The \'Resolve to Evolve\' Hackathon is an event where participants build AI or LLM-powered applications to help people maintain their New Year\'s resolutions. The event has specific rules regarding submissions, team formation, judging, and tooling.\\n\\n- **Keypoints**\\n  - Objective: Build an AI/LLM-powered app to help with New Year\'s resolutions.\\n  - Team Formation: Solo or teams of any size are permitted (recommendation: 5 or less).\\n  - Submissions: You can submit to multiple tracks but win at most one.\\n  - Prizing: $5,000 for each of the five themes, plus a $5,000 special prize for the best use of OPIC.\\n  - Required Tooling: OPIC must be used for evaluation.\\n  - Allowed Tooling: Any LLM (e.g., Gemini, etc.) can be used.\\n  - Submission deliverable: A video demo is a mandatory and critical part of the submission, presenting the project and its functionality.\\n  - Project Scope: Build an MVP. Full production-ready apps are not expected.\\n  - Timeline: The hackathon has started, and coding can begin now. It lasts approximately 28 days.\\n  - Prior Work: You can build on a pre-existing project, but only functionality added during the hackathon will be judged.\\n- **Explanation**\\n  Participants are tasked with creating an MVP (Minimum Viable Product) of a web or mobile app. They can work solo or in teams of any size, though teams of 5 or fewer are recommended. Submissions can target multiple prize categories, but a project can only win one. Judging criteria are available on the hackathon platform. A key component of the submission is a video demo that serves as both a product pitch and a functional walkthrough. While participants can use any LLM, they are required to use OPIC for evaluation. The hackathon provides access to partner services with generous free tiers instead of specific credits. Participants can start coding immediately and can even build upon existing projects, but only work done during the hackathon period will be judged.\\n- **Special Circumstances**\\n- If building a mobile app that cannot be easily shared or hosted for judging, a very thorough demo video showing all functionality is sufficient.\\n- If you want to work on a project you have already started, you can, but you will only be judged on the new functionality and features built during the hackathon period.\\n\\n## Assignments & Suggestions\\n\\n- If you are joining from Luma, go into your programs page and register for the hackathon after the session.\\n- If you have questions that aren\'t answered live, put them in the Q&A to be answered in the Discord.\\n- Decide on the project you want to build, the theme to focus on, the solution to come up with, and what makes it special during the ideation stage in week one.\\n- By the project creation deadline at the end of week one, create and commit to the project idea, the challenge theme, and add team members.\\n- Start the building process in week two.\\n- For the mid-hackathon deadline, submit your publicly available GitHub repo and a fuller description of what you\'re building.\\n- For the final submission deadline on February 8th, submit a video pitch including a product demo, your public code base, a hosted site (optional but recommended), and a presentation (optional but recommended).\\n- Watch the helpful, short lecture videos on the platform to prepare for workshops and the wider hackathon.\\n- Run the code from the QR code provided to see how evaluations are created and look in OPIC. The QR code leads to a simple recipe generator agent in a GitHub gist. You need to copy the script, follow the directions for creating online evaluations, create a Comet account if you don\'t have one (it\'s free), and add your API key."},{"id":"locki-in-2025","metadata":{"permalink":"/blog/locki-in-2025","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2025-01-15-locki-in-2025.mdx","source":"@site/blog/2025-01-15-locki-in-2025.mdx","title":"Locki Labs in 2025 - Introducing Valkyria","description":"After months of development on our horse racing analysis platform, we\'re taking a bold step forward. In 2025, Locki Labs shifts focus from real-time data aggregation to something far more ambitious: Valkyria \u2014 a temporal prediction system designed for scientific rigor and reproducible results.","date":"2025-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Locki Labs","permalink":"/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"AI and Machine Learning","permalink":"/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"Temporal Predictions","permalink":"/blog/tags/temporal-predictions","description":"Insights into temporal prediction models and applications"},{"inline":false,"label":"Machine Learning","permalink":"/blog/tags/machine-learning","description":"Articles on machine learning and related technologies"}],"readingTime":3.94,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"locki-in-2025","title":"Locki Labs in 2025 - Introducing Valkyria","authors":["jnxmas"],"tags":["locki","valkyria","temporal-predictions","machine-learning"]},"unlisted":false,"prevItem":{"title":"Hackathon kickoff meeting","permalink":"/blog/encode-kickoff"},"nextItem":{"title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","permalink":"/blog/locki-journey-2023-2025"}},"content":"After months of development on our horse racing analysis platform, we\'re taking a bold step forward. In 2025, Locki Labs shifts focus from real-time data aggregation to something far more ambitious: **Valkyria** \u2014 a temporal prediction system designed for scientific rigor and reproducible results.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Problem We Set Out to Solve\\n\\nOur existing platform excels at real-time race analysis. But we discovered a fundamental limitation when it came to developing prediction models: **temporal blindness**.\\n\\nWhen analyzing a historical race from, say, November 16th, our system would use horse data from _today_ \u2014 including races that happened _after_ the race we\'re analyzing. This is called **data leakage**, and it makes prediction models unreliable.\\n\\n```\\nScenario: Analyzing a race from November 16, 2025\\n\\n\u274c Current approach:\\n   Uses horse career data as of TODAY\\n   \u2192 Includes future races (data leakage)\\n   \u2192 Predictions are scientifically invalid\\n\\n\u2705 Valkyria approach:\\n   Uses horse career data as of November 16\\n   \u2192 Only past information available\\n   \u2192 Predictions are reproducible and valid\\n```\\n\\n## What is Valkyria?\\n\\nValkyria is a **temporal prediction laboratory** \u2014 a system that can reproduce predictions with historical accuracy. The core principle is simple but powerful:\\n\\n> **Analyze any race using only the data that would have been available at that exact moment in time.**\\n\\nThis enables:\\n\\n- **Time-Travel Analysis**: Query any race from the past 18 months with temporally-accurate data\\n- **Model Training**: Train prediction algorithms on clean, causally-valid datasets\\n- **Backtesting**: Validate strategies on historical races without information leakage\\n- **Reproducibility**: Same race, same analysis, same results \u2014 every time\\n\\n## The Three-Tier Architecture\\n\\nValkyria operates on a three-tier temporal system:\\n\\n### Tier 1: Real-Time (48 hours)\\n\\nLive operations for current and upcoming races. Odds tracking, race analysis, chat features \u2014 all powered by Redis cache with 15-minute refresh cycles.\\n\\n### Tier 2: Recent History (7 days)\\n\\nFast access to recently finished races. Runner snapshots stored in Redis with file backup for durability.\\n\\n### Tier 3: Historical Archive (18 months)\\n\\n**This is the innovation.** A SQLite-based temporal database containing runner snapshots \u2014 immutable records of each horse\'s state at race time. No future information, ever.\\n\\n## Campaign-Based Population\\n\\nRather than fetching all historical data upfront, Valkyria uses a **campaign-based approach**:\\n\\n| Campaign | Period       | Estimated Races | Status   |\\n| -------- | ------------ | --------------- | -------- |\\n| Q4-2025  | Oct-Dec 2025 | ~4,500          | Priority |\\n| Q3-2025  | Jul-Sep 2025 | ~4,500          | Next     |\\n| Q2-2025  | Apr-Jun 2025 | ~4,500          | Planned  |\\n\\nEach campaign represents a 3-month slice of racing data, populated incrementally during off-peak hours. The database grows organically while maintaining full temporal accuracy.\\n\\n## Model Unification: One Model, Multiple Lifecycles\\n\\nA key architectural decision: **CanonicalRunner** becomes the single source of truth across all lifecycle stages:\\n\\n1. **Pre-Race**: Upcoming participant with updating odds\\n2. **Post-Race**: Finished runner with final results\\n3. **Career History**: Stored snapshot for temporal queries\\n\\nThis eliminates 88% of field duplication from our previous dual-model system and ensures consistency across the entire platform.\\n\\n## What This Means for Predictions\\n\\nWith Valkyria, we can finally build prediction models with scientific integrity:\\n\\n```\\nHistorical snapshots (18 months)\\n    \u2193\\nFeature engineering (career metrics, confrontations)\\n    \u2193\\nModel training (XGBoost, Neural Networks)\\n    \u2193\\nBacktesting (temporal validation)\\n    \u2193\\nProduction deployment (high confidence)\\n```\\n\\nWe\'ll be able to:\\n\\n- Compare multiple models on the same historical data\\n- Calculate accuracy by race type (HARNESS, FLAT, Quint\xe9)\\n- Calibrate confidence scores based on actual performance\\n- Generate algorithmic selections with transparent methodology\\n\\n## The Road Ahead\\n\\nValkyria development follows a phased approach:\\n\\n**Foundation** \u2014 Database schema, storage functions, basic snapshot capabilities\\n\\n**Daily Population** \u2014 Automated jobs to capture yesterday\'s races every night\\n\\n**Workflow Integration** \u2014 Career workflows query the temporal database for historical analysis\\n\\n**Campaign Population** \u2014 Bulk population of 3-month historical periods\\n\\n**Model Unification** \u2014 Full migration to CanonicalRunner across all analyzers\\n\\nEach phase delivers value independently. If we complete only the foundation and daily population, we still have a working temporal snapshot system. The full vision builds incrementally.\\n\\n## Storage & Retention\\n\\nThe numbers are reassuring:\\n\\n- **18 months of racing**: ~27,000 races, ~324,000 runner snapshots\\n- **Storage requirement**: ~486 MB\\n- **Cleanup policy**: Monthly removal of data older than 18 months\\n\\nSQLite handles this efficiently, and the system remains lightweight.\\n\\n## Why This Matters\\n\\nWithout temporal accuracy, predictions are anecdotal. With Valkyria:\\n\\n- \u2705 **Causal validity**: Only past data influences predictions\\n- \u2705 **Reproducibility**: Results can be verified and replicated\\n- \u2705 **Testability**: Objective performance metrics across historical data\\n- \u2705 **Confidence**: Know when and where models perform reliably\\n\\nThis isn\'t just a technical improvement \u2014 it\'s the foundation for next-generation prediction algorithms built on scientific rigor rather than intuition.\\n\\n## Looking Forward\\n\\n2025 marks a transition for Locki Labs. We\'re moving from \\"what does the data say right now?\\" to \\"what would we have known then, and how can we learn from it?\\"\\n\\nValkyria represents our commitment to building prediction systems we can trust, test, and continuously improve. One snapshot at a time.\\n\\n---\\n\\n_Stay tuned for updates as we progress through the Valkyria implementation phases._"},{"id":"locki-journey-2023-2025","metadata":{"permalink":"/blog/locki-journey-2023-2025","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2023-09-29-locki-labs-journey.mdx","source":"@site/blog/2023-09-29-locki-labs-journey.mdx","title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","description":"Locki started as a vision during the Encode MultiversX Hackathon in October 2023, with the ambitious goal of creating a decentralized platform for minting, viewing, and interacting with 3D Data NFTs using the Itheum protocol.","date":"2024-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Locki Labs","permalink":"/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"Blockchain","permalink":"/blog/tags/blockchain","description":"Articles related to blockchain technology"},{"inline":false,"label":"MultiversX","permalink":"/blog/tags/multiversx","description":"Content about the MultiversX ecosystem"},{"inline":false,"label":"Itheum","permalink":"/blog/tags/itheum","description":"Posts regarding Itheum platform"},{"inline":false,"label":"RAG","permalink":"/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Web3 Technologies","permalink":"/blog/tags/web3","description":"Discussions on Web3 technologies and trends"}],"readingTime":3.43,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"locki-journey-2023-2025","title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","authors":["jnxmas"],"tags":["locki","blockchain","multiversx","itheum","rag","web3"],"date":"2024-01-15T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Locki Labs in 2025 - Introducing Valkyria","permalink":"/blog/locki-in-2025"},"nextItem":{"title":"Locki blog introduction","permalink":"/blog/help me write in the blog"}},"content":"Locki started as a vision during the **Encode MultiversX Hackathon in October 2023**, with the ambitious goal of creating a decentralized platform for minting, viewing, and interacting with 3D Data NFTs using the Itheum protocol.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Current Status\\n\\n:::info Project Status\\n\\nLocki dApp is currently in **alpha phase** on MultiversX devnet, and has been supported by the **xPand Itheum program**.\\n\\n:::\\n\\nThe platform has evolved significantly since its inception, now featuring:\\n\\n- **3D Data NFT minting and visualization** using Three.js and React Three Fiber\\n- **AI-powered chat assistant** for Blender Python scripting guidance\\n- **Whitelist management system** for controlled access\\n- **Integration with MultiversX wallets** including xAlias support\\n\\n## The Challenge of Collecting RAG Data and Intellectual Property\\n\\nOne of the most significant hurdles we\'ve encountered is **building a quality dataset for our RAG (Retrieval-Augmented Generation) system** while respecting intellectual property rights.\\n\\n### The IP Dilemma\\n\\nCreating an effective AI assistant for 3D modeling and Blender scripting requires extensive training data:\\n\\n- **Documentation licensing**: Much of the best Blender documentation exists under various licenses that complicate commercial use\\n- **Community content**: Forum posts, tutorials, and Stack Exchange answers have complex attribution requirements\\n- **Proprietary scripts**: Many advanced Blender scripts are commercial products with restrictive licenses\\n- **Version fragmentation**: Blender\'s rapid release cycle means documentation quickly becomes outdated\\n\\n### Our Approach\\n\\nWe\'ve had to carefully curate our data sources, focusing on:\\n\\n1. **Open-source documentation** with permissive licenses\\n2. **Original content creation** to fill knowledge gaps\\n3. **User-generated content** with explicit consent\\n4. **Partnerships** with content creators in the Blender ecosystem\\n\\n:::tip Locki Companion Status\\n\\nThe Locki companion AI feature is currently **on pause** while we navigate these data collection challenges and ensure full compliance with IP rights.\\n\\n:::\\n\\n## Technical Challenges: The Blockchain Moving Target\\n\\nPerhaps the most demanding aspect of maintaining Locki has been keeping pace with the **rapid evolution of blockchain infrastructure**.\\n\\n### SDK Version Churn\\n\\nThe MultiversX ecosystem has undergone substantial changes:\\n\\n```json\\n// Our current dependency snapshot\\n\\"@multiversx/sdk-core\\": \\"12.18.0\\",\\n\\"@multiversx/sdk-dapp\\": \\"2.28.7\\",\\n\\"@multiversx/sdk-network-providers\\": \\"2.3.0\\",\\n\\"@itheum/sdk-mx-data-nft\\": \\"2.7.0-beta.4\\"\\n```\\n\\nEach major version brings:\\n\\n- **Breaking API changes** requiring code refactoring\\n- **New authentication patterns** (we\'ve integrated xAlias, native auth tokens)\\n- **Smart contract interface updates** affecting our ABI integrations\\n- **Wallet provider deprecations** forcing migration to new connection methods\\n\\n### Specific Challenges We\'ve Faced\\n\\n1. **SSR Compatibility**: Next.js App Router with blockchain SDKs requires careful dynamic imports to avoid server-side rendering issues\\n\\n2. **Transaction Handling**: The move from legacy transaction signing to the new `signAndSendTransactions` utility required substantial refactoring\\n\\n3. **Smart Contract ABIs**: Contract updates on devnet mean our local ABIs must be continuously synchronized\\n\\n4. **Network Provider Changes**: API endpoint changes and rate limiting adjustments have required multiple backend adaptations\\n\\n### The Maintenance Burden\\n\\n```\\nRecent commits reflecting ongoing maintenance:\\n- \\"Upgrade: Status locki companion\\"\\n- \\"fix vulnerabilities\\"\\n- \\"Fixed build issues\\"\\n- \\"Fixes smart contract dependencies and code refactoring\\"\\n```\\n\\nEach vulnerability fix in upstream dependencies cascades through our codebase. The security-conscious nature of blockchain applications means we cannot defer these updates.\\n\\n## Lessons Learned\\n\\n### For Blockchain Developers\\n\\n1. **Abstract your SDK interactions**: Create wrapper classes (like our `baseSmartContract.ts`) to isolate breaking changes\\n2. **Pin versions carefully**: Use exact versions in production, but test against latest regularly\\n3. **Monitor ecosystem announcements**: Join Discord channels and follow GitHub releases\\n4. **Build with deprecation in mind**: What works today may be obsolete in 6 months\\n\\n### For AI/RAG Builders\\n\\n1. **Document your data sources**: Track provenance from day one\\n2. **Build consent mechanisms**: Make it easy for users to contribute data with clear licensing\\n3. **Plan for re-training**: Your model will need updates as source material evolves\\n4. **Consider synthetic data**: Generate training examples where real data is restricted\\n\\n## What\'s Next for Locki\\n\\nDespite these challenges, we remain committed to the vision:\\n\\n- **Mainnet deployment** once alpha testing is complete\\n- **Enhanced 3D NFT features** with improved GLTF/GLB support\\n- **Expanded AI capabilities** with properly licensed training data\\n- **Community governance** for whitelist and platform decisions\\n\\n---\\n\\n_Locki is an open-source project. We welcome contributors who share our passion for decentralized 3D asset ownership and AI-assisted creativity._\\n\\n**Special Collections on MultiversX Devnet:**\\n\\n- `DATANFTFT-e0b917`\\n- `I3TICKER-03e5c2`\\n- `COLNAMA-539838`"},{"id":"help me write in the blog","metadata":{"permalink":"/blog/help me write in the blog","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Locki blog introduction","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"}],"readingTime":0.85,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"help me write in the blog","title":"Locki blog introduction","authors":["jnxmas"],"tags":["facebook","hello"]},"unlisted":false,"prevItem":{"title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","permalink":"/blog/locki-journey-2023-2025"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\n\\n:::tip\\nThe blog is interesting because it allows our agent in cursor and claude code to dive into our reflexion to have a set of the status and the priorities of the project.\\nUse it referencing our discussion for your feature branches.\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n:::tip\\nThe blog is interesting because it allows our agent in cursor and claude code to dive into our reflexion to have a set of the status and the priorities of the project.\\nUse it referencing our discussion for your feature branches.\\n:::\\nSimply add Markdown files (or folders) to the `blog` directory.\\n\\nRegular blog authors can be added to `authors.yml`.\\n\\nThe blog post date can be extracted from filenames, such as:\\n\\n- `2019-05-30-welcome.md`\\n- `2019-05-30-welcome/index.md`\\n\\nA blog post folder can be convenient to co-locate blog post images:\\n\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\\n\\nThe blog supports tags as well!"}]}}')}}]);