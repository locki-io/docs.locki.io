"use strict";(globalThis.webpackChunkdocs_locki_io=globalThis.webpackChunkdocs_locki_io||[]).push([[9419],{8245(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"app/opik/EXPERIMENT_WORKFLOW","title":"Experiment Workflow","description":"This document describes the prompt optimization experiment workflow using Opik\'s native evaluation API.","source":"@site/docs/app/opik/EXPERIMENT_WORKFLOW.md","sourceDirName":"app/opik","slug":"/app/opik/EXPERIMENT_WORKFLOW","permalink":"/fr/docs/app/opik/EXPERIMENT_WORKFLOW","draft":false,"unlisted":false,"editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/docs/app/opik/EXPERIMENT_WORKFLOW.md","tags":[],"version":"current","frontMatter":{}}');var s=i(4848),r=i(8453);const l={},d="Experiment Workflow",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Two LLMs",id:"two-llms",level:2},{value:"Task LLM (Sidebar)",id:"task-llm-sidebar",level:3},{value:"Judge LLM (Opik)",id:"judge-llm-opik",level:3},{value:"Available Metrics",id:"available-metrics",level:2},{value:"Opik Built-in Metrics (LLM Judges)",id:"opik-built-in-metrics-llm-judges",level:3},{value:"Custom Metrics",id:"custom-metrics",level:3},{value:"Workflow Components",id:"workflow-components",level:2},{value:"1. workflow_dataset.py",id:"1-workflow_datasetpy",level:3},{value:"2. workflow_experiment.py",id:"2-workflow_experimentpy",level:3},{value:"Dataset Item Format",id:"dataset-item-format",level:2},{value:"Agent Feature Registry",id:"agent-feature-registry",level:2},{value:"Evaluation Flow",id:"evaluation-flow",level:2},{value:"Admin Dashboard Integration",id:"admin-dashboard-integration",level:2},{value:"Files",id:"files",level:2},{value:"References",id:"references",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"experiment-workflow",children:"Experiment Workflow"})}),"\n",(0,s.jsx)(n.p,{children:"This document describes the prompt optimization experiment workflow using Opik's native evaluation API."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The experiment workflow enables systematic evaluation and optimization of LLM prompts used by OCapistaine agents. It leverages Opik's built-in LLM judge metrics to assess prompt quality."}),"\n",(0,s.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Experiment Workflow                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Dataset   \u2502\u2500\u2500\u2500\u25b6\u2502  Evaluation \u2502\u2500\u2500\u2500\u25b6\u2502   Opik Platform     \u2502 \u2502\n\u2502  \u2502   (Opik)    \u2502    \u2502    Task     \u2502    \u2502   (Results)         \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                            \u2502                                    \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510                            \u2502\n\u2502                     \u25bc             \u25bc                            \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502              \u2502 Task LLM \u2502  \u2502 Judge LLM    \u2502                    \u2502\n\u2502              \u2502 (Sidebar)\u2502  \u2502 (OpenAI)     \u2502                    \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"two-llms",children:"Two LLMs"}),"\n",(0,s.jsx)(n.p,{children:"The experiment uses two separate LLMs for different purposes:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"LLM"}),(0,s.jsx)(n.th,{children:"Purpose"}),(0,s.jsx)(n.th,{children:"Configuration"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Task LLM"})}),(0,s.jsx)(n.td,{children:"Runs the actual Forseti agent (validation/classification)"}),(0,s.jsx)(n.td,{children:"Sidebar selection (Gemini, Claude, Mistral, Ollama)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Judge LLM"})}),(0,s.jsx)(n.td,{children:"Runs Opik's evaluation metrics (Hallucination, Moderation)"}),(0,s.jsx)(n.td,{children:"Admin dashboard (default: OpenAI gpt-4o-mini)"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"task-llm-sidebar",children:"Task LLM (Sidebar)"}),"\n",(0,s.jsx)(n.p,{children:"The task LLM is the same provider selected in the sidebar. It executes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Charter validation (",(0,s.jsx)(n.code,{children:"charter_validation"})," span)"]}),"\n",(0,s.jsxs)(n.li,{children:["Category classification (",(0,s.jsx)(n.code,{children:"category_classification"})," span)"]}),"\n",(0,s.jsx)(n.li,{children:"Other agent features"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"judge-llm-opik",children:"Judge LLM (Opik)"}),"\n",(0,s.jsx)(n.p,{children:"The judge LLM runs Opik's built-in metrics. Configuration stored in Redis db=5:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Default configuration\n{\n    "provider": "openai",\n    "model": "gpt-4o-mini",\n    "api_key_env": "OPENAI_API_KEY"\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Configure via Admin dashboard: ",(0,s.jsx)(n.strong,{children:"Opik Judge LLM"})," section."]}),"\n",(0,s.jsx)(n.h2,{id:"available-metrics",children:"Available Metrics"}),"\n",(0,s.jsx)(n.h3,{id:"opik-built-in-metrics-llm-judges",children:"Opik Built-in Metrics (LLM Judges)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"hallucination"})}),(0,s.jsx)(n.td,{children:"Detects generated false information"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"moderation"})}),(0,s.jsx)(n.td,{children:"Checks adherence to content standards"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"answer_relevance"})}),(0,s.jsx)(n.td,{children:"Evaluates how well the answer fits the question"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"context_recall"})}),(0,s.jsx)(n.td,{children:"Measures retrieval of relevant context (RAG)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"context_precision"})}),(0,s.jsx)(n.td,{children:"Measures precision of retrieved context (RAG)"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"custom-metrics",children:"Custom Metrics"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"charter_compliance"})}),(0,s.jsx)(n.td,{children:"Checks if is_valid matches expected output"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"confidence"})}),(0,s.jsx)(n.td,{children:"Checks if confidence meets threshold"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"workflow-components",children:"Workflow Components"}),"\n",(0,s.jsx)(n.h3,{id:"1-workflow_datasetpy",children:"1. workflow_dataset.py"}),"\n",(0,s.jsx)(n.p,{children:"Creates Opik datasets from various sources:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from app.processors.workflows import create_dataset_from_spans\n\nresult = create_dataset_from_spans(\n    experiment_type="charter_optimization",\n    dataset_name="charter-opt-20260204",\n    max_correctness=0.7,  # Spans with Correctness < 0.7\n    max_items=50,\n    task_provider="gemini",  # Track which LLM was used\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Sources:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Opik spans (filtered by Correctness feedback score)"}),"\n",(0,s.jsx)(n.li,{children:"MockupStorage records (filtered by confidence)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-workflow_experimentpy",children:"2. workflow_experiment.py"}),"\n",(0,s.jsxs)(n.p,{children:["Runs experiments using Opik's native ",(0,s.jsx)(n.code,{children:"evaluate()"})," API:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from app.processors.workflows import OpikExperimentConfig, run_opik_experiment\n\nconfig = OpikExperimentConfig(\n    experiment_name="charter-eval-20260204",\n    dataset_name="charter-opt-20260204",\n    experiment_type="charter_optimization",\n    task_provider="gemini",  # Sidebar LLM for Forseti\n    metrics=["hallucination", "moderation"],\n)\n\nresults = run_opik_experiment(config)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"dataset-item-format",children:"Dataset Item Format"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "id": "unique-id",\n  "input": {\n    "title": "Contribution title...",\n    "body": "Contribution body...",\n    "category": "economie",\n    "original_confidence": 0.8,\n    "original_is_valid": true,\n    "record_id": "span_019c27cb..."\n  },\n  "expected_output": {\n    "is_valid": true,\n    "confidence_threshold": 1.0\n  },\n  "tags": [],\n  "created_at": "2026-02-04T08:34:58Z"\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"agent-feature-registry",children:"Agent Feature Registry"}),"\n",(0,s.jsxs)(n.p,{children:["Experiment types are defined in ",(0,s.jsx)(n.code,{children:"AGENT_FEATURE_REGISTRY"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'AGENT_FEATURE_REGISTRY = {\n    "charter_optimization": {\n        "agent": "forseti",\n        "feature": "charter_validation",  # Span name\n        "prompt_key": "forseti.charter_validation",\n        "dataset_prefix": "charter-optimization",\n    },\n    "category_optimization": {\n        "agent": "forseti",\n        "feature": "category_classification",\n        "prompt_key": "forseti.category_classification",\n        "dataset_prefix": "category-optimization",\n    },\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"To add a new optimizable feature:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Ensure the feature logs ",(0,s.jsx)(n.code,{children:"Correctness"})," feedback via ",(0,s.jsx)(n.code,{children:"tracer.log_span_feedback()"})]}),"\n",(0,s.jsxs)(n.li,{children:["Add ",(0,s.jsx)(n.code,{children:"added_to_dataset: False"})," metadata to the span"]}),"\n",(0,s.jsxs)(n.li,{children:["Register in ",(0,s.jsx)(n.code,{children:"AGENT_FEATURE_REGISTRY"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"evaluation-flow",children:"Evaluation Flow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"1. Load dataset from Opik\n        \u2193\n2. For each dataset item:\n   a. Run evaluation_task (Forseti with task_provider LLM)\n   b. Get output: {input, output, context, is_valid, confidence}\n        \u2193\n3. Opik evaluate() with scoring_metrics (judge_provider LLM)\n   - Hallucination metric\n   - Moderation metric\n   - Custom metrics\n        \u2193\n4. Results logged to Opik platform\n   - Per-item scores\n   - Aggregate statistics\n"})}),"\n",(0,s.jsx)(n.h2,{id:"admin-dashboard-integration",children:"Admin Dashboard Integration"}),"\n",(0,s.jsx)(n.p,{children:"The Admin tab includes:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Opik Judge LLM Configuration"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Provider selection (OpenAI, Anthropic)"}),"\n",(0,s.jsx)(n.li,{children:"Model selection (gpt-4o-mini, gpt-4o, claude-3-haiku)"}),"\n",(0,s.jsx)(n.li,{children:"API key status indicator"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Experiment Type Selection"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Dynamic from AGENT_FEATURE_REGISTRY"}),"\n",(0,s.jsx)(n.li,{children:"Shows agent and feature info"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Opik Span Statistics"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Total spans by type"}),"\n",(0,s.jsx)(n.li,{children:"Spans with Correctness below threshold"}),"\n",(0,s.jsx)(n.li,{children:"Already added to dataset count"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"files",children:"Files"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"File"}),(0,s.jsx)(n.th,{children:"Purpose"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"app/processors/workflows/workflow_dataset.py"})}),(0,s.jsx)(n.td,{children:"Dataset creation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"app/processors/workflows/workflow_experiment.py"})}),(0,s.jsx)(n.td,{children:"Experiment execution"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"app/services/opik_config.py"})}),(0,s.jsx)(n.td,{children:"Judge LLM config (Redis db=5)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"app/services/tasks/__init__.py"})}),(0,s.jsx)(n.td,{children:"AGENT_FEATURE_REGISTRY"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.comet.com/docs/opik/evaluation/metrics/overview",children:"Opik Evaluation Metrics"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.comet.com/docs/opik/evaluation/metrics/custom_metric",children:"Opik Custom Metrics"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.comet.com/docs/opik/evaluation/manage_datasets",children:"Opik Datasets"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8453(e,n,i){i.d(n,{R:()=>l,x:()=>d});var t=i(6540);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);