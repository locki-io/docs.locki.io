"use strict";(globalThis.webpackChunkdocs_locki_io=globalThis.webpackChunkdocs_locki_io||[]).push([[6114],{8502(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"grounding-ai-in-reality","metadata":{"permalink":"/fr/blog/grounding-ai-in-reality","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-02-04-grounding-ai-in-reality.md","source":"@site/blog/2026-02-04-grounding-ai-in-reality.md","title":"Grounding AI in Reality: How Field Data Keeps Our Agents Honest","description":"How real-world inputs from recordings, meetings, and press keep AI agents from drifting into comfortable bubbles","date":"2026-02-04T00:00:00.000Z","tags":[{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"Methodology","permalink":"/fr/blog/tags/methodology","description":"Development methodologies, practices, and processes"},{"inline":false,"label":"Continuous Improvement","permalink":"/fr/blog/tags/continuous-improvement","description":"Articles on continuous improvement of AI systems and prompts"},{"inline":false,"label":"Forseti","permalink":"/fr/blog/tags/forseti","description":"Articles on Forseti AI agent and its applications"}],"readingTime":9.31,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"grounding-ai-in-reality","title":"Grounding AI in Reality: How Field Data Keeps Our Agents Honest","authors":["jnxmas"],"tags":["ai-ml","civictech","methodology","continuous-improvement","forseti"],"image":"/img/continuous_improvement_loop.png","description":"How real-world inputs from recordings, meetings, and press keep AI agents from drifting into comfortable bubbles"},"unlisted":false,"nextItem":{"title":"The Impossible Sprint: Building Civic AI in 4 Weeks","permalink":"/fr/blog/hackathon-final-sprint"}},"content":"**The daily practice of challenging AI prompts with messy, real-world data**\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Bubble Problem\\n\\nEvery AI system risks becoming a bubble. Train it on clean data, test it on similar clean data, and it performs beautifully\u2014in the lab. Then reality arrives:\\n\\n- A citizen uses slang the model never saw\\n- A press article frames an issue differently than our categories expect\\n- A field recording captures a concern that doesn\'t fit our charter\'s neat boxes\\n- An official explains a nuance that our prompts don\'t account for\\n\\n**The AI doesn\'t know what it doesn\'t know.** And worse: it will confidently give wrong answers, because its training data said that\'s how the world works.\\n\\nThis is the gap between [our trust-building vision](/blog/self-improving-civic-ai) and daily reality. The vision is beautiful. The practice is messy. This article is about the messy part.\\n\\n## Our Reality Streams\\n\\nWe\'re constantly receiving signals from the field. Each one is a potential challenge to our AI\'s worldview:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        REALITY STREAMS INTO SYSTEM                           \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                              \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502  PLAUD AI    \u2502   \u2502  CITIZEN     \u2502   \u2502  OFFICIAL    \u2502   \u2502    PRESS     \u2502  \u2502\\n\u2502  \u2502  Recordings  \u2502   \u2502  Contribs    \u2502   \u2502  Meetings    \u2502   \u2502   Articles   \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502         \u2502                  \u2502                  \u2502                  \u2502          \u2502\\n\u2502         \u2502   Unstructured   \u2502   Structured     \u2502   Context-rich   \u2502  External\u2502\\n\u2502         \u2502   Spontaneous    \u2502   Intentional    \u2502   Nuanced        \u2502  Framing \u2502\\n\u2502         \u2502   Local dialect  \u2502   Formal tone    \u2502   Political      \u2502  Diverse \u2502\\n\u2502         \u2502                  \u2502                  \u2502                  \u2502          \u2502\\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\\n\u2502                            \u2502                  \u2502                              \u2502\\n\u2502                            \u25bc                  \u25bc                              \u2502\\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\\n\u2502                    \u2502      DOES THIS CHALLENGE        \u2502                       \u2502\\n\u2502                    \u2502      OUR AI\'S ASSUMPTIONS?      \u2502                       \u2502\\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\\n\u2502                                                                              \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n### Plaud AI Recordings\\n\\nWe record field conversations (with consent). A fisherman explaining why the port needs work doesn\'t speak like a formal contribution. He uses local terms, references shared history, expresses frustration in ways our polite training data never showed.\\n\\n**Challenge**: Can Forseti recognize validity when the tone is raw?\\n\\n### Citizen Contributions\\n\\nThese are our bread and butter\u2014but they surprise us constantly. Edge cases appear weekly:\\n- A contribution that\'s clearly well-intentioned but technically violates charter rules\\n- A valid concern expressed as a complaint about a specific person (borderline personal attack?)\\n- A suggestion that spans multiple categories\\n\\n**Challenge**: Are our categories and rules aligned with how citizens actually think?\\n\\n### Official Meetings\\n\\nWhen we meet with municipal staff, they explain the *why* behind policies. \\"We categorize it this way because of budget structure.\\" \\"That phrase is actually a compliment in local context.\\" These insights rarely make it into training data.\\n\\n**Challenge**: Does our AI understand institutional context, or just surface patterns?\\n\\n### Press Articles\\n\\nLocal journalists frame issues differently than citizens or officials. They highlight tensions, use dramatic language, connect dots across topics. When Gwaien (local bulletin) publishes about port renovation, it\'s a different lens than a citizen contribution about the same topic.\\n\\n**Challenge**: Can our AI maintain consistent judgment across different framings of the same issue?\\n\\n## The Daily Practice\\n\\nUnderstanding that reality challenges our AI is step one. Step two is building a *daily practice* of grounding. Here\'s ours:\\n\\n### 1. Morning: Error Cleanup\\n\\nBefore any analysis, we clean the noise:\\n\\n```python\\nfrom app.processors.workflows.workflow_experiment import cleanup_error_traces\\n\\n# Every morning: remove traces that contain errors\\n# These pollute our optimization if left in place\\nresult = cleanup_error_traces()\\nprint(f\\"Cleaned {result[\'deleted\']} error traces\\")\\n```\\n\\n**Why daily?** Errors accumulate. \\"Gemini retries exhausted\\" isn\'t a valid data point\u2014it\'s infrastructure noise. Leaving it in skews our metrics toward false pessimism.\\n\\n### 2. Midday: Format Compliance Check\\n\\nWe measure how well our AI outputs match the *ideal* format:\\n\\n```python\\n# The ideal output we\'re optimizing toward\\nIDEAL_CHARTER_OUTPUT = {\\n    \\"is_valid\\": True,\\n    \\"violations\\": [],\\n    \\"encouraged_aspects\\": [\\n        \\"Concrete and argued proposals\\",\\n        \\"Constructive criticism\\",\\n        \\"Questions and requests for clarification\\",\\n    ],\\n    \\"reasoning\\": \\"Clear explanation...\\",\\n    \\"confidence\\": 0.95,\\n}\\n```\\n\\nThe `output_format` metric scores every output against this ideal (0.0 to 1.0):\\n- Missing fields? Score drops.\\n- Error in reasoning? Score drops significantly.\\n- Valid but no positive aspects identified? Score drops.\\n\\n**Why format matters?** An AI that gives the right answer in the wrong format is hard to integrate, hard to audit, hard to trust. Consistency enables trust.\\n\\n### 3. Afternoon: New Data Evaluation\\n\\nThe scheduled task processes any new spans from the morning\'s work:\\n\\n```\\nEvery 30 minutes:\\n\u251c\u2500 Search for spans not yet evaluated\\n\u251c\u2500 Create dataset from new spans\\n\u251c\u2500 Run Opik evaluate() with metrics\\n\u2502   \u251c\u2500 hallucination (is the AI making things up?)\\n\u2502   \u2514\u2500 output_format (is output structured correctly?)\\n\u2514\u2500 Report results\\n```\\n\\nThis catches drift *the same day* it appears. Not next week. Not at quarterly review. Today.\\n\\n### 4. Evening: Field Data Integration\\n\\nThis is the creative part. We take the day\'s field inputs and ask: **does any of this break our AI?**\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    EVENING CHALLENGE PROTOCOL                                \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                              \u2502\\n\u2502  For each new field input (recording, article, meeting note):                \u2502\\n\u2502                                                                              \u2502\\n\u2502  1. EXTRACT the core claim/concern                                           \u2502\\n\u2502     \\"The port access road is dangerous\\" (from Plaud recording)               \u2502\\n\u2502                                                                              \u2502\\n\u2502  2. FORMULATE as a test contribution                                         \u2502\\n\u2502     Title: \\"S\xe9curit\xe9 de la route d\'acc\xe8s au port\\"                           \u2502\\n\u2502     Body: [transcribed concern in citizen language]                          \u2502\\n\u2502                                                                              \u2502\\n\u2502  3. RUN through Forseti                                                      \u2502\\n\u2502     \u2192 Is it classified correctly?                                            \u2502\\n\u2502     \u2192 Is confidence appropriate?                                             \u2502\\n\u2502     \u2192 Does reasoning make sense?                                             \u2502\\n\u2502                                                                              \u2502\\n\u2502  4. IF surprising result:                                                    \u2502\\n\u2502     \u2192 Log as potential prompt challenge                                      \u2502\\n\u2502     \u2192 Add to next experiment batch                                           \u2502\\n\u2502     \u2192 Consider: is the AI wrong, or are our rules wrong?                    \u2502\\n\u2502                                                                              \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nThe last question is crucial: sometimes the AI is wrong and needs fixing. Sometimes our rules are wrong and need updating. Both are valid outcomes.\\n\\n## The Metrics That Matter\\n\\nWe track specific signals that indicate grounding vs. drift:\\n\\n### Grounding Indicators (Good)\\n\\n| Metric | Meaning | Target |\\n|--------|---------|--------|\\n| Output format score | AI produces consistent structure | \u2265 0.85 |\\n| Confidence calibration | When AI says 90%, it\'s right 90% | Within 5% |\\n| Field case accuracy | AI handles real recordings correctly | \u2265 80% |\\n| Category consistency | Same topic \u2192 same category | \u2265 90% |\\n\\n### Drift Indicators (Warning)\\n\\n| Metric | Meaning | Concern Level |\\n|--------|---------|---------------|\\n| Rising error rate | More \\"validation error\\" traces | High |\\n| Dropping format score | Outputs becoming inconsistent | Medium |\\n| Confidence inflation | AI overconfident on edge cases | High |\\n| Category confusion | Same topic \u2192 different categories | Medium |\\n\\n### Bubble Indicators (Critical)\\n\\n| Signal | What It Means |\\n|--------|---------------|\\n| Field cases consistently fail | AI model doesn\'t match reality |\\n| Officials disagree with classifications | Institutional context missing |\\n| Press framings confuse the AI | Limited linguistic flexibility |\\n| Citizens appeal correct classifications | Rules don\'t match expectations |\\n\\nWhen bubble indicators appear, we don\'t just tune the model. We question the rules.\\n\\n## Challenging the Prompt: A Worked Example\\n\\nHere\'s how a single Plaud recording becomes a prompt challenge:\\n\\n### The Recording\\n\\nA fisherman at the port, speaking informally:\\n\\n> \\"Le quai l\xe0, c\'est n\'importe quoi. \xc7a fait trois ans qu\'on demande et rien. Les touristes ils passent, ils voient \xe7a, qu\'est-ce qu\'ils pensent? Faut arr\xeater de d\xe9penser pour les conneries et s\'occuper du port.\\"\\n\\n### Initial AI Response\\n\\n```\\nis_valid: false\\nviolations: [\\"Potentially inappropriate language: \'conneries\'\\"]\\nconfidence: 0.72\\nreasoning: \\"The contribution contains informal language that may\\n            violate charter guidelines on respectful discourse.\\"\\n```\\n\\n### The Challenge\\n\\nWait. This is a legitimate concern about port infrastructure, expressed in authentic local language. Is \\"conneries\\" really a charter violation, or is our prompt too sanitized?\\n\\n### The Investigation\\n\\nWe check:\\n1. **Charter text**: Does it actually prohibit informal language? No\u2014it prohibits personal attacks and insults.\\n2. **Official input**: Would municipal staff consider this offensive? We ask. They laugh. \\"That\'s how people talk here.\\"\\n3. **Citizen expectation**: Would the speaker feel unfairly filtered? Almost certainly yes.\\n\\n### The Prompt Update\\n\\nWe add to our charter validation prompt:\\n\\n```\\nNote: Informal or colloquial language common in Brittany\\n(e.g., expressing frustration with strong words about situations,\\nnot people) should not be confused with charter violations.\\nThe charter prohibits attacks on individuals, not passionate\\nexpression about issues.\\n```\\n\\n### The Verification\\n\\nRe-run the same input:\\n\\n```\\nis_valid: true\\nviolations: []\\nencouraged_aspects: [\\"Concrete concern about infrastructure\\"]\\nconfidence: 0.88\\nreasoning: \\"The contribution expresses legitimate frustration about\\n            port maintenance using informal but non-offensive language.\\n            The criticism targets infrastructure neglect, not individuals.\\"\\n```\\n\\n**The AI now matches human judgment.**\\n\\n## The Continuous Loop\\n\\nThis isn\'t a one-time fix. It\'s a daily loop:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                     THE GROUNDING LOOP                                       \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                              \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                         \u2502\\n\u2502     \u2502  Real World  \u2502  Recordings, contributions, meetings, press             \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\\n\u2502            \u2502                                                                 \u2502\\n\u2502            \u25bc                                                                 \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                         \u2502\\n\u2502     \u2502   Observe    \u2502  Does this challenge our AI?                            \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\\n\u2502            \u2502                                                                 \u2502\\n\u2502            \u25bc                                                                 \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                         \u2502\\n\u2502     \u2502    Test      \u2502  Run through Forseti, measure metrics                   \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\\n\u2502            \u2502                                                                 \u2502\\n\u2502            \u25bc                                                                 \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                         \u2502\\n\u2502     \u2502   Analyze    \u2502  AI wrong, or rules wrong?                              \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\\n\u2502            \u2502                                                                 \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                          \u2502\\n\u2502     \u25bc             \u25bc                                                          \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                  \u2502\\n\u2502  \u2502Fix AI  \u2502  \u2502Update Rules\u2502                                                  \u2502\\n\u2502  \u2502(prompt)\u2502  \u2502(charter)   \u2502                                                  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                  \u2502\\n\u2502      \u2502             \u2502                                                         \u2502\\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\\n\u2502             \u2502                                                                \u2502\\n\u2502             \u25bc                                                                \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                         \u2502\\n\u2502     \u2502   Verify     \u2502  Re-test, measure improvement                           \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\\n\u2502            \u2502                                                                 \u2502\\n\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 Tomorrow: new data arrives         \u2502\\n\u2502                                                                              \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## What We\'re Really Doing\\n\\nThis practice isn\'t about making AI smarter. It\'s about making AI **humbler**.\\n\\nAn AI that performs perfectly on test data but fails on field recordings is worse than one that admits uncertainty. At least the uncertain AI knows it needs help.\\n\\nOur goal:\\n\\n- **Not**: AI that always knows the answer\\n- **Instead**: AI that knows when it doesn\'t know, and improves when shown\\n\\nThe trust we\'re building with citizens and officials depends on this humility. An AI that overconfidently misclassifies their contribution destroys trust faster than one that says \\"I\'m not sure, let me flag this for human review.\\"\\n\\n## Tomorrow\'s Challenge\\n\\nWe don\'t know what tomorrow\'s Plaud recording will contain. We don\'t know what issue the next press article will raise. We don\'t know what nuance an official will explain in the next meeting.\\n\\n**That uncertainty is the point.**\\n\\nWe\'re building a system that can say:\\n1. \\"This is what I think, with this confidence\\"\\n2. \\"Here\'s my reasoning\\"\\n3. \\"If I\'m wrong, teach me\\"\\n\\nThe continuous improvement loop ensures that teaching happens\u2014not quarterly, not monthly, but daily.\\n\\n## Coming Tomorrow: The Field-to-Feature Pipeline\\n\\nThe manual process described above works, but it doesn\'t scale. Tomorrow we build the automated pipeline:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    FIELD-TO-FEATURE PIPELINE (Tomorrow)                      \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                              \u2502\\n\u2502  INGEST                                                                      \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\\n\u2502  \u2502  Plaud AI    \u2502   \u2502    Press     \u2502   \u2502   Meeting    \u2502                     \u2502\\n\u2502  \u2502  Recordings  \u2502   \u2502   Articles   \u2502   \u2502    Notes     \u2502                     \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\\n\u2502         \u2502                  \u2502                  \u2502                              \u2502\\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\\n\u2502                            \u25bc                                                 \u2502\\n\u2502  TRANSFORM          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                         \u2502\\n\u2502                     \u2502 Speech-to-   \u2502  Whisper / Plaud transcription          \u2502\\n\u2502                     \u2502 Text + LLM   \u2502  Summarize or keep raw                  \u2502\\n\u2502                     \u2502 Processing   \u2502                                         \u2502\\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\\n\u2502                            \u2502                                                 \u2502\\n\u2502                            \u25bc                                                 \u2502\\n\u2502  GENERATE           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                         \u2502\\n\u2502                     \u2502   Mockup     \u2502  Generate contributions:                \u2502\\n\u2502                     \u2502  Generator   \u2502  \u2022 Valid examples                       \u2502\\n\u2502                     \u2502              \u2502  \u2022 Charter violations                   \u2502\\n\u2502                     \u2502              \u2502  \u2022 Edge cases                           \u2502\\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\\n\u2502                            \u2502                                                 \u2502\\n\u2502                            \u25bc                                                 \u2502\\n\u2502  EVALUATE           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                         \u2502\\n\u2502                     \u2502   Forseti    \u2502  Run all features:                      \u2502\\n\u2502                     \u2502   Features   \u2502  \u2022 charter_validation                   \u2502\\n\u2502                     \u2502              \u2502  \u2022 category_classification              \u2502\\n\u2502                     \u2502              \u2502  \u2022 (future features)                    \u2502\\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\\n\u2502                            \u2502                                                 \u2502\\n\u2502                            \u25bc                                                 \u2502\\n\u2502  MEASURE            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                         \u2502\\n\u2502                     \u2502   Metrics    \u2502  \u2022 output_format                        \u2502\\n\u2502                     \u2502  + Opik      \u2502  \u2022 hallucination                        \u2502\\n\u2502                     \u2502              \u2502  \u2022 confidence calibration               \u2502\\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\\n\u2502                            \u2502                                                 \u2502\\n\u2502                            \u25bc                                                 \u2502\\n\u2502  IMPROVE            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                         \u2502\\n\u2502                     \u2502   Prompt     \u2502  Automatic suggestions for              \u2502\\n\u2502                     \u2502  Refinement  \u2502  prompt improvements                    \u2502\\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\\n\u2502                                                                              \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n### The Key Innovation: Synthetic Challenges\\n\\nWe won\'t just transcribe recordings\u2014we\'ll **generate variations** that stress-test the agent:\\n\\n| Input | Generated Variations |\\n|-------|---------------------|\\n| Valid concern from recording | Same concern with: aggressive tone, personal attack, off-topic tangent |\\n| Press article about port | Contribution that: agrees, disagrees, misunderstands, exaggerates |\\n| Official meeting insight | Edge case that: tests the boundary, uses ambiguous language |\\n\\n**Why generate violations?** An agent that only sees valid inputs gets complacent. We need to keep it sharp by regularly testing its ability to detect problems.\\n\\n### Deployed Across All Forseti Features\\n\\nThe pipeline won\'t just test `charter_validation`. It will challenge every feature:\\n\\n```python\\n# Tomorrow\'s goal: feature-agnostic challenge pipeline\\nFEATURES_TO_CHALLENGE = [\\n    \\"charter_validation\\",      # Does it catch violations?\\n    \\"category_classification\\", # Does it categorize correctly?\\n    # Future features:\\n    # \\"sentiment_analysis\\",\\n    # \\"priority_scoring\\",\\n    # \\"duplicate_detection\\",\\n]\\n\\nfor feature in FEATURES_TO_CHALLENGE:\\n    challenges = generate_challenges_from_field_data(\\n        recordings=today_plaud_files,\\n        articles=today_press_articles,\\n        include_violations=True,\\n        variation_count=5,\\n    )\\n    results = run_forseti_evaluation(feature, challenges)\\n    log_to_opik(feature, results)\\n```\\n\\n### The Schedule\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    DAILY CHALLENGE SCHEDULE                      \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                  \u2502\\n\u2502  00:00  Ingest new field data (recordings, articles)             \u2502\\n\u2502                                                                  \u2502\\n\u2502  01:00  Transcribe and process                                   \u2502\\n\u2502                                                                  \u2502\\n\u2502  02:00  Generate mockup contributions (valid + violations)       \u2502\\n\u2502                                                                  \u2502\\n\u2502  03:00  Run through all Forseti features                         \u2502\\n\u2502                                                                  \u2502\\n\u2502  04:00  Measure and log to Opik                                  \u2502\\n\u2502                                                                  \u2502\\n\u2502  06:00  task_contributions_analysis (real contributions)         \u2502\\n\u2502                                                                  \u2502\\n\u2502  07:00+ task_opik_evaluate (every 30 min)                        \u2502\\n\u2502         \u2514\u2500\u25b6 Includes field-generated challenges                  \u2502\\n\u2502                                                                  \u2502\\n\u2502  Morning report: \\"3 new challenges failed - review needed\\"       \u2502\\n\u2502                                                                  \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n### Why This Matters\\n\\nToday\'s approach is reactive: we wait for problems, then fix them.\\n\\nTomorrow\'s approach is **proactive**: we manufacture challenges before they happen in production. The agent faces synthetic violations every night, so when a real one arrives, it\'s ready.\\n\\n**The agent stays on edge. The agent stays grounded. The agent earns trust.**\\n\\n---\\n\\n*The path from [trust-building vision](/blog/self-improving-civic-ai) to trusted reality runs through daily practice. No shortcuts. No silver bullets. Just the messy, humbling work of keeping AI grounded in the world as it actually is.*\\n\\n*Tools we use: [Continuous Improvement Methodology](/docs/app/opik/CONTINUOUS_IMPROVEMENT) | [Experiment Workflow](/docs/app/opik/EXPERIMENT_WORKFLOW) | [Field Input Workflow](/docs/app/FIELD_INPUT_WORKFLOW)*\\n\\n---\\n\\n*Tomorrow: Building the automated Field-to-Feature Pipeline using the [Field Input](/docs/app/FIELD_INPUT_WORKFLOW) feature*"},{"id":"hackathon-final-sprint","metadata":{"permalink":"/fr/blog/hackathon-final-sprint","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-02-03-hackathon-final-sprint.md","source":"@site/blog/2026-02-03-hackathon-final-sprint.md","title":"The Impossible Sprint: Building Civic AI in 4 Weeks","description":"How we pivoted from OCR blockers to Mistral Document AI in the final hours of the Encode Hackathon - and why civic transparency is worth the chaos.","date":"2026-02-03T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"Opik","permalink":"/fr/blog/tags/opik","description":"Articles on Opik LLM observability and prompt optimization"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Mistral AI","permalink":"/fr/blog/tags/mistral","description":"Articles on Mistral AI integration and Document AI"}],"readingTime":4.77,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"hackathon-final-sprint","title":"The Impossible Sprint: Building Civic AI in 4 Weeks","authors":["jnxmas"],"tags":["encode","civictech","ai-ml","opik","rag","mistral"],"image":"/img/article_audierne2026_en.png","description":"How we pivoted from OCR blockers to Mistral Document AI in the final hours of the Encode Hackathon - and why civic transparency is worth the chaos."},"unlisted":false,"prevItem":{"title":"Grounding AI in Reality: How Field Data Keeps Our Agents Honest","permalink":"/fr/blog/grounding-ai-in-reality"},"nextItem":{"title":"Sprint Planning: Mistral Document AI RAG Prototype","permalink":"/fr/blog/sprint-planning-mistral-rag"}},"content":"> \\"It looks impossible - but it\'s a hackathon. Cheers!\\"\\n\\nThis is the story of **OCapistaine**, a civic transparency AI built during the Encode \\"Commit to Change\\" Hackathon. It\'s a story of blocked pipelines, strategic pivots, 4,000 municipal PDFs, and the belief that AI can help citizens understand their local democracy.\\n\\n**Spoiler**: We shipped it. Barely.\\n![impossible is not ocapistaine](/img/the_impossible_sprint.jpg)\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Mission\\n\\nAudierne is a small coastal town in Brittany, France. Like many municipalities, it has years of public documents - council deliberations, municipal decrees, budget reports - scattered across websites and PDFs. Citizens _technically_ have access, but practically? Good luck finding what you need.\\n\\n**OCapistaine** aims to change that: a RAG-powered Q&A system where citizens can ask questions in plain French and get answers with source citations. No hallucinations. Full transparency. Trust through traceability.\\n\\n## The Journey (A Timeline of Chaos)\\n\\n### Week 1: Foundation\\n\\n- Built the **Forseti agent** for charter validation (contribution moderation)\\n- Deployed **N8N orchestration** on our Vaettir server\\n- Set up **Opik** for LLM observability\\n- Scraped ~4,000 municipal PDFs via Firecrawl\\n\\n**Feeling**: Optimistic. We got this.\\n\\n### Week 2: The OCR Wall\\n\\n- Text extraction worked for ~1,800 PDFs\\n- But ~3,000 were **image-based scans** requiring OCR\\n- Tested pdf2ocr, Tabula, pypdf... all blocked by installation issues\\n- Victor spent days fighting library dependencies\\n\\n**Feeling**: Concerned. The RAG needs documents.\\n\\n### Week 3: The Opik Pivot\\n\\n- Shifted focus to what _was_ working: **prompt optimization**\\n- Built an **Opik Prompt Library** - no more hardcoded prompts\\n- Created **mockup generation** for testing Forseti with synthetic contributions\\n- Forseti accuracy jumped from ~20% to **90%+**\\n\\n**Feeling**: Progress, but RAG still blocked.\\n\\n### Week 4 (Today): The Mistral Gambit\\n\\n**Sunday, February 3rd, 2026 - 48 hours to deadline**\\n\\nThe team sync call started with bad news: OCR was still blocked. Then someone asked:\\n\\n> \\"What if we don\'t build OCR? What if someone else already did?\\"\\n\\nEnter **Mistral Document AI**.\\n\\n- Native PDF processing with **built-in OCR**\\n- Batch endpoint with **50% discount**\\n- Agent API for RAG queries\\n- ~$2 per 1,000 pages\\n\\n**The pivot**: Instead of custom RAG infrastructure, use Mistral\'s managed solution. Upload documents, train an agent, integrate Opik tracing, ship.\\n\\n**Feeling**: Terrified excitement. Classic hackathon energy.\\n\\n## The Architecture (Post-Pivot)\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                     OCapistaine Architecture                     \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                 \u2502\\n\u2502  Municipal PDFs \u2500\u2500\u25ba Mistral Document AI \u2500\u2500\u25ba Trained Agent       \u2502\\n\u2502  (~4,000 docs)        (OCR + indexing)       (RAG queries)      \u2502\\n\u2502                                                    \u2502            \u2502\\n\u2502                                                    \u25bc            \u2502\\n\u2502  Streamlit UI \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Agent API          \u2502\\n\u2502       \u2502                                           \u2502            \u2502\\n\u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Opik Tracing \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\\n\u2502                    (observability)                              \u2502\\n\u2502                                                                 \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502  Forseti Agent: Charter validation for citizen contributions    \u2502\\n\u2502  N8N Workflows: Email/Facebook \u2192 GitHub issue automation        \u2502\\n\u2502  Vaettir Server: Orchestration and webhook handling             \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## What We Built\\n\\n### 1. Forseti 461 - The Charter Guardian\\n\\nAn LLM agent that validates citizen contributions against the participation charter:\\n\\n- No personal attacks or naming individuals\\n- Constructive and factual content\\n- Relevant to local issues\\n- Proper category classification (7 categories)\\n\\n**Results**: 90%+ accuracy after Opik-guided prompt optimization.\\n\\n### 2. Auto-Contribution Workflow\\n\\nCitizens can submit ideas via email or Facebook. The system:\\n\\n1. Receives submission via N8N webhook\\n2. Validates against charter (Forseti)\\n3. Creates GitHub issue if compliant\\n4. Tracks everything in Opik\\n\\n### 3. RAG Q&A (The Final Sprint)\\n\\nUpload 4,000+ municipal documents to Mistral, train an agent, let citizens ask:\\n\\n- \\"What was the 2024 budget for road maintenance?\\"\\n- \\"When was the last deliberation about the port?\\"\\n- \\"What environmental measures has the council discussed?\\"\\n\\nEvery answer comes with **source citations**. No trust without transparency.\\n\\n### 4. Opik Observability\\n\\nEvery LLM call is traced:\\n\\n- Prompt versions tracked in Opik Prompt Library\\n- Latency, tokens, and costs monitored\\n- Hallucination detection via evaluation pipelines\\n- A/B testing for prompt improvements\\n\\n## The Trust Architecture\\n\\nThis isn\'t just about answering questions. It\'s about **building trust** between citizens and AI systems.\\n\\nOur approach:\\n\\n| Layer          | Mechanism          | Transparency              |\\n| -------------- | ------------------ | ------------------------- |\\n| **Input**      | Charter validation | Citizens know the rules   |\\n| **Processing** | Opik tracing       | Every decision is logged  |\\n| **Output**     | Source citations   | Answers are verifiable    |\\n| **Feedback**   | Accuracy metrics   | Performance is measurable |\\n\\nThe goal: Civil servants and citizens can **audit** the AI\'s reasoning. If it\'s wrong, we know. If it improves, we can prove it.\\n\\n## Lessons Learned\\n\\n### 1. Pivots Are Not Failures\\n\\nThe OCR blocker felt like a disaster. The Mistral pivot turned it into an advantage - better OCR, managed infrastructure, faster shipping.\\n\\n### 2. Observability Is Non-Negotiable\\n\\nWithout Opik, we\'d have no idea if Forseti was improving. The prompt library and tracing made optimization possible in days, not weeks.\\n\\n### 3. Hackathons Require Scope Ruthlessness\\n\\nWe wanted custom embeddings, MongoDB, a full document service. We shipped a working demo by choosing \\"good enough now\\" over \\"perfect later.\\"\\n\\n### 4. Civic Tech Needs Humans\\n\\nThe best AI can\'t replace citizen participation. It can only make it **easier** to participate and **harder** for information to be hidden.\\n\\n## What\'s Next\\n\\nPost-hackathon roadmap:\\n\\n- [ ] Custom vector embeddings for better retrieval\\n- [ ] MongoDB for document tracking and change detection\\n- [ ] Multi-channel deployment (dedicated chatbot, Facebook integration)\\n- [ ] Breton language support (yes, really)\\n- [ ] Self-improving feedback loops via Opik experiments\\n\\n## The Team\\n\\n- **@jnxmas** - Lead, infrastructure, Opik integration, sleep deprivation\\n- **@zcbtvag** - Backend, Firecrawl scraping, OCR battles, Mistral uploads\\n\\n## Try It\\n\\n- **Live Demo**: [ocapistaine.ngrok.app](https://ocapistaine.ngrok.app)\\n- **GitHub**: [locki-io/ocapistaine](https://github.com/locki-io/ocapistaine)\\n- **Docs**: [docs.locki.io](https://docs.locki.io)\\n- **Opik Dashboard**: [comet.com/opik](https://www.comet.com/opik)\\n\\n---\\n\\n## To the Jury\\n\\nThis project exists because we believe:\\n\\n1. **Local democracy matters** - and it\'s broken by information asymmetry\\n2. **AI can help** - but only if it\'s transparent and auditable\\n3. **Civic tech should be open** - our code, our process, our mistakes are all public\\n\\nWe didn\'t build a perfect system. We built a **working** system in 4 weeks, with:\\n\\n- Real municipal documents (not synthetic data)\\n- Real observability (not just logs)\\n- Real transparency (source citations, not \\"trust me\\")\\n\\nThe impossible sprint taught us that the hardest part of civic AI isn\'t the technology. It\'s earning the trust of the people it\'s supposed to serve.\\n\\nWe\'re just getting started.\\n\\n---\\n\\n_Built with caffeine, Opik traces, and the stubborn belief that citizens deserve better tools._\\n\\n**#EncodeHackathon #CommitToChange #CivicTech #OCapistaine**"},{"id":"sprint-planning-mistral-rag","metadata":{"permalink":"/fr/blog/sprint-planning-mistral-rag","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-02-03-mistral-rag-sprint.mdx","source":"@site/blog/2026-02-03-mistral-rag-sprint.mdx","title":"Sprint Planning: Mistral Document AI RAG Prototype","description":"Sprint planning call between Johnny (@jnxmas) and Victor (@zcbtvag) to align on the Sunday midnight deadline. Key decision: pivot to Mistral Document AI + Batch + Agent for a rapid RAG prototype.","date":"2026-02-03T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"Opik","permalink":"/fr/blog/tags/opik","description":"Articles on Opik LLM observability and prompt optimization"}],"readingTime":4.69,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"sprint-planning-mistral-rag","title":"Sprint Planning: Mistral Document AI RAG Prototype","authors":["jnxmas"],"tags":["meeting","rag","ai-ml","opik"]},"unlisted":false,"prevItem":{"title":"The Impossible Sprint: Building Civic AI in 4 Weeks","permalink":"/fr/blog/hackathon-final-sprint"},"nextItem":{"title":"Construire la Confiance par une IA Transparente : Un Partenariat Humain-Machine pour la Participation Citoyenne","permalink":"/fr/blog/self-improving-civic-ai"}},"content":"Sprint planning call between Johnny (@jnxmas) and Victor (@zcbtvag) to align on the Sunday midnight deadline. Key decision: **pivot to Mistral Document AI + Batch + Agent** for a rapid RAG prototype.\\n\\n## Call Goals\\n\\n- Align on immediate priorities before Sunday midnight\\n- Decide RAG approach and OCR path\\n- Clarify repo/branch workflow and submodule handling\\n- Assign ownership for Mistral Document AI setup\\n- Coordinate API keys and cost management\\n\\n\x3c!-- truncate --\x3e\\n\\n## Summary\\n\\n### Timeline & Data Status\\n\\n- **Deadline:** Sunday at midnight\\n- **Scraping:** Completed ~1.5-2 weeks ago; ~4,000 PDFs downloaded\\n- **Text extraction:** ~1,800 text-based PDFs processed\\n- **OCR needed:** ~3,000 image-based PDFs still pending\\n\\n### Strategic Pivot: Mistral Document AI\\n\\nInstead of building custom in-app RAG (deferring Nomic), we\'ll leverage **Mistral Document AI + Batch + Agent** to ship faster:\\n\\n| Feature            | Capability                                  |\\n| ------------------ | ------------------------------------------- |\\n| **Document AI**    | Handles PDFs and images (OCR), accepts URLs |\\n| **Batch endpoint** | 50% discount, high capacity                 |\\n| **Pricing**        | ~$2 per 1,000 pages                         |\\n| **Limits**         | 50 MB per doc, up to 1,000 pages per doc    |\\n\\n**Plan:**\\n\\n1. Upload existing municipal documents (text + image PDFs) to Mistral Document AI\\n2. Run batch processing\\n3. Train 1-2 times before deadline\\n4. Create Agent with API key for search queries from app\\n\\n### Contributions & Forseti\\n\\n- Forseti agent validates charter compliance\\n- Performance improved from ~20% to ~90%+ via manual optimization\\n- Desire to instrument with Opik for continuous improvement and traceability\\n\\n### Git Submodule Issues\\n\\nThe docs submodule caused merge friction - commit pointer in main repo can lag behind when merging older branches. Solution: take 5 minutes at merge time to realign submodule pointers.\\n\\n---\\n\\n## Alignment Check\\n\\n| Area              | Status        | Notes                                                        |\\n| ----------------- | ------------- | ------------------------------------------------------------ |\\n| **Project goals** | Aligned       | Accelerates citizen Q&A chatbot via managed RAG              |\\n| **Neutrality**    | Requires work | Third-party RAG demands strict guardrails + source citations |\\n| **Scope fit**     | Acceptable    | Defers custom RAG infra for hackathon prototype              |\\n\\n### Risks\\n\\n| Risk                             | Mitigation                  |\\n| -------------------------------- | --------------------------- |\\n| Upload/process time for ~4k PDFs | Start batch ASAP            |\\n| Mistral limits/costs unknown     | Verify before large uploads |\\n| Submodule merge errors           | Plan explicit merge steps   |\\n| Hallucination without evaluation | Add Opik tracing now        |\\n| OCR quality for scans            | Test subset first           |\\n\\n---\\n\\n## Decisions\\n\\n1. **Use Mistral Document AI + Batch + Agent** for RAG prototype\\n2. **Victor** focuses on documents and Mistral API integration\\n3. **Johnny** sets up Mistral workspace, coordinates batch runs and context links\\n4. Continue feature-branch workflow; handle docs submodule at merge time\\n\\n---\\n\\n## Action Plan & Tasks\\n\\n### 1. Mistral Setup (Priority: Critical)\\n\\n- **Task:** Create Mistral workspace and share API keys\\n  - **Owner:** @jnxmas\\n  - **Description:** Set up Mistral workspace using jnlockey3d.com, invite victoragrest@gmail.com, generate API key for batch/agent operations. Confirm billing setup and budget cap.\\n  - **Deadline:** Tomorrow morning\\n  - **Success Criteria:** Victor receives invite and API key; billing confirmed.\\n\\n- **Task:** Verify Mistral Document AI limits and pricing\\n  - **Owner:** @zcbtvag\\n  - **Description:** Confirm batch limits (documents per job, max requests, file size/page limits), OCR capabilities, and expected cost for ~4,000 PDFs. Document findings in repo docs.\\n  - **Deadline:** ASAP (before starting large uploads)\\n  - **Success Criteria:** Clear documented constraints and cost estimate.\\n\\n### 2. Document Processing (Priority: Critical)\\n\\n- **Task:** Prepare document list and upload script\\n  - **Owner:** @zcbtvag\\n  - **Description:** Create Python script to iterate over 4,000 PDFs, sending to Mistral Document AI batch endpoint. Start with 50-100 file pilot to validate throughput and OCR quality.\\n  - **Deadline:** Pilot today; full batch tomorrow\\n  - **Success Criteria:** Pilot completes with &gt;95% success; script ready for full batch.\\n\\n- **Task:** Batch training and Agent creation\\n  - **Owner:** @jnxmas\\n  - **Description:** Once documents processed, run 1-2 trainings to create Mistral Agent. Generate scoped API key. Document how to query Agent for RAG search.\\n  - **Deadline:** Before Sunday midnight\\n  - **Success Criteria:** Agent returns accurate results with citations; API key available to app.\\n\\n### 3. Observability (Priority: High)\\n\\n- **Task:** Integrate Opik tracing for RAG queries\\n  - **Owner:** @jnxmas\\n  - **Description:** Add Opik instrumentation for all RAG queries (request/response logging, sources, latency, hallucination flags). Set up evaluation dashboard.\\n  - **Deadline:** Before Sunday midnight\\n  - **Success Criteria:** Opik dashboard shows traces; evaluation runs without errors.\\n\\n### 4. Context & Workflow (Priority: Medium)\\n\\n- **Task:** Context links workflow\\n  - **Owner:** @jnxmas\\n  - **Description:** Prepare N8N micro-workflow to pull contribution-related context links (HTML/URLs) and queue for Mistral ingestion.\\n  - **Deadline:** Draft by Saturday\\n  - **Success Criteria:** At least 20 context links processed and added to corpus.\\n\\n### 5. Repo Hygiene (Priority: Medium)\\n\\n- **Task:** Repo merge hygiene (docs submodule)\\n  - **Owner:** @zcbtvag + @jnxmas\\n  - **Description:** Coordinate at merge time to realign docs submodule commit pointer to latest before merging into dev.\\n  - **Deadline:** Next merge event\\n  - **Success Criteria:** Clean merge with correct submodule pointer; CI passes.\\n\\n---\\n\\n## Open Questions\\n\\n1. Should we prioritize a minimal Q&A demo by Sunday using Mistral Agent + Opik, even with partial corpus?\\n2. Do we need a separate categorization microservice this week, or rely on Agent + prompt tooling?\\n3. Which topics from the 4 municipal lists must be in the first demo corpus?\\n\\n---\\n\\n## Suggestions & Risk Mitigations\\n\\n- **Pilot first:** Start with 200 PDFs across key categories (housing, culture, budget) to validate OCR and retrieval\\n- **Strict prompting:** Require source citations; \\"no answer without source\\" policy; log refusals in Opik\\n- **Budget guardrail:** Set spending cap; monitor pages processed; batch by priority\\n- **Breton names:** Maintain custom glossary file in corpus; instruct Agent to prefer glossary matches\\n- **Repo docs:** Create \\"submodule merge checklist\\" to avoid repeated confusion\\n\\n---\\n\\n## Status Dashboard\\n\\n| Component                | Status      | Notes                                  |\\n| ------------------------ | ----------- | -------------------------------------- |\\n| Firecrawl/Docs ingestion | In Progress | ~1,800 text PDFs done, ~3,000 need OCR |\\n| Mistral setup            | Starting    | Workspace creation pending             |\\n| RAG Agent integration    | Not Started | Blocked on batch completion            |\\n| Opik tracing             | In Progress | Ready to add once Agent exists         |\\n\\n**Open High-Priority Tasks:**\\n\\n1. Verify Mistral limits/pricing (@zcbtvag)\\n2. Create Mistral workspace and share API key (@jnxmas)\\n3. Pilot upload script + batch start (@zcbtvag)\\n4. Agent creation + Opik integration (@jnxmas)\\n5. Submodule merge alignment (@zcbtvag + @jnxmas)\\n\\n**Next Milestone:** Sunday midnight - deliver working RAG Q&A demo using Mistral Agent with Opik tracing and citations."},{"id":"self-improving-civic-ai","metadata":{"permalink":"/fr/blog/self-improving-civic-ai","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-02-03-self-improving-civic-ai.md","source":"@site/i18n/fr/docusaurus-plugin-content-blog/2026-02-03-self-improving-civic-ai.md","title":"Construire la Confiance par une IA Transparente : Un Partenariat Humain-Machine pour la Participation Citoyenne","description":"Comment OCapistaine construit la confiance avec les citoyens et les agents publics gr\xe2ce \xe0 une IA fiable et mesurable pour la d\xe9mocratie participative","date":"2026-02-03T00:00:00.000Z","tags":[{"inline":false,"label":"IA et Machine Learning","permalink":"/fr/blog/tags/ia-ml","description":"Articles sur l\'IA, le machine learning et les technologies associ\xe9es"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"Confiance","permalink":"/fr/blog/tags/confiance","description":"Articles sur la confiance et la s\xe9curit\xe9 dans les syst\xe8mes IA"},{"inline":false,"label":"Collaboration","permalink":"/fr/blog/tags/collaboration","description":"Articles on collaboration in AI development and research"},{"inline":false,"label":"Forseti","permalink":"/fr/blog/tags/forseti","description":"Articles on Forseti AI agent and its applications"}],"readingTime":9.81,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"self-improving-civic-ai","title":"Construire la Confiance par une IA Transparente : Un Partenariat Humain-Machine pour la Participation Citoyenne","authors":["jnxmas"],"tags":["ia-ml","civictech","confiance","collaboration","forseti"],"image":"/img/article_audierne2026_fr.png","description":"Comment OCapistaine construit la confiance avec les citoyens et les agents publics gr\xe2ce \xe0 une IA fiable et mesurable pour la d\xe9mocratie participative"},"unlisted":false,"prevItem":{"title":"Sprint Planning: Mistral Document AI RAG Prototype","permalink":"/fr/blog/sprint-planning-mistral-rag"},"nextItem":{"title":"Project Sync: Opik Progress & OCR Blockers","permalink":"/fr/blog/project-sync-opik-ocr"}},"content":"**Comment \xd2 Capistaine construit la confiance avec les citoyens et les agents publics gr\xe2ce \xe0 une fiabilit\xe9 mesurable de l\'IA**\\n![building trust](/img/article_audierne2026_fr.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n## La confiance est le produit\\n\\nQuand nous d\xe9ployons l\'IA dans des applications civiques, nous ne vendons pas un logiciel \u2014 nous demandons la confiance. La confiance de deux groupes aux pr\xe9occupations tr\xe8s diff\xe9rentes :\\n\\n- **Les citoyens** ont besoin de croire que leur voix compte, qu\'un algorithme ne rejettera pas silencieusement leur contribution\\n- **Les agents publics** ont besoin de croire que l\'IA est un coll\xe8gue, pas une menace pour leur expertise et leur emploi\\n\\nCes deux formes de confiance partagent un fondement commun : **une fiabilit\xe9 d\xe9montr\xe9e dans le temps**. Pas des promesses. Pas du marketing. Des preuves mesur\xe9es, visibles, continues que le syst\xe8me fonctionne _avec_ les humains, pas \xe0 leur place.\\n\\n## La peur que nous devons affronter\\n\\nSoyons directs sur l\'\xe9l\xe9phant dans la pi\xe8ce : les agents publics s\'inqui\xe8tent que l\'IA prenne leur emploi. Cette peur est l\xe9gitime et nous refusons de la balayer.\\n\\nNotre r\xe9ponse n\u2019est pas \xab l\u2019IA ne vous remplacera pas \xbb (promesse que nous ne pouvons pas tenir). Nous pr\xe9f\xe9rons \xeatre honn\xeates :\\n\\n> **Dans la participation citoyenne, l\'IA ne peut pas et ne devrait pas remplacer le jugement humain. Elle peut seulement gagner le droit de g\xe9rer les t\xe2ches routini\xe8res en faisant ses preuves, lib\xe9rant les humains pour le travail qui n\xe9cessite v\xe9ritablement la sagesse humaine.**\\n\\nL\'objectif n\'est pas l\'automatisation, mais **l\'augmentation** \u2014 cr\xe9er une \xe9quipe o\xf9 chacun apporte ses forces.\\n\\n## Le Mod\xe8le d\'\xc9quipe Humain-IA\\n\\nNous n\'impl\xe9mentons pas \xab l\'automatisation par IA \xbb. Nous construisons une **\xe9quipe** avec des r\xf4les clairs :\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    LE MOD\xc8LE DE COLLABORATION                   \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                 \u2502\\n\u2502   L\'IA APPORTE                   \u2502    L\'HUMAIN APPORTE          \u2502\\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                   \u2502    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2502\\n\u2502   \u2022 Rapidit\xe9 (disponible 24/7)   \u2502    \u2022 Jugement (contexte)     \u2502\\n\u2502   \u2022 Coh\xe9rence (m\xeames r\xe8gles)     \u2502    \u2022 Empathie (intention)    \u2502\\n\u2502   \u2022 Reconnaissance de patterns   \u2502    \u2022 Responsabilit\xe9          \u2502\\n\u2502   \u2022 Tri infatigable              \u2502    \u2022 Connaissance locale     \u2502\\n\u2502                                  \u2502    \u2022 L\xe9gitimit\xe9 d\xe9mocratique \u2502\\n\u2502                                                                 \u2502\\n\u2502   L\'IA NE FAIT JAMAIS            \u2502    L\'HUMAIN FAIT TOUJOURS    \u2502\\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500            \u2502    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2502\\n\u2502   \u2022 Rejet d\xe9finitif              \u2502    \u2022 Examen des appels       \u2502\\n\u2502   \u2022 D\xe9cisions politiques         \u2502    \u2022 R\xe9solution cas limites  \u2502\\n\u2502   \u2022 Communication aux citoyens   \u2502    \u2022 V\xe9rification confiance  \u2502\\n\u2502                                                                 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nCe n\'est pas une \xe9chelle o\xf9 l\'IA grimpe vers le remplacement des humains. C\'est un **partenariat stable** o\xf9 les responsabilit\xe9s sont divis\xe9es par comp\xe9tence, pas par commodit\xe9.\\n\\n## Comment la confiance se construit : Transparence \xe0 chaque \xe9tape\\n\\nLa confiance ne se d\xe9cr\xe8te pas \u2014 elle se gagne par la transparence. Chaque d\xe9cision de l\'IA dans \xd2 Capistaine vient avec une divulgation compl\xe8te :\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502  CONTRIBUTION CITOYENNE : \\"Le port a besoin de modernisation\\"   \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                 \u2502\\n\u2502  \xc9VALUATION IA (visible par l\'agent public) :                   \u2502\\n\u2502                                                                 \u2502\\n\u2502  \u2713 Conforme \xe0 la Charte : OUI                                   \u2502\\n\u2502  \u2713 Cat\xe9gorie : \xe9conomie                                         \u2502\\n\u2502  \u2713 Confiance : 92%                                              \u2502\\n\u2502                                                                 \u2502\\n\u2502  Raisonnement : \\"*Proposition concr\xe8te concernant les           \u2502\\n\u2502  infrastructures portuaires, sans attaque personnelle,          \u2502\\n\u2502  en rapport direct avec Audierne.*\\"                             \u2502\\n\u2502                                                                 \u2502\\n\u2502  Aspects positifs d\xe9tect\xe9s :                                    \u2502\\n\u2502  \u2022 Proposition concr\xe8te                                         \u2502\\n\u2502  \u2022 Pertinence locale                                            \u2502\\n\u2502                                                                 \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\\n\u2502  \u2502  [\u2713 Approuver]  [\u2717 Corriger]  [? Demander r\xe9vision]     \u2502    \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\\n\u2502                                                                 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nL\'agent public voit **tout** : la d\xe9cision, le niveau de confiance, le raisonnement et les aspects sp\xe9cifiques qui ont influenc\xe9 l\'IA. Il peut approuver en un clic, corriger avec une explication, ou escalader vers un coll\xe8gue.\\n\\n**L\'IA ne cache jamais son travail.** Cette transparence sert deux objectifs :\\n\\n1. Les agents publics peuvent v\xe9rifier le jugement de l\'IA par rapport \xe0 leur propre expertise\\n2. Avec le temps, des patterns \xe9mergent \u2014 les humains apprennent quand faire confiance \xe0 l\'IA, et quand v\xe9rifier\\n\\n## Le Cycle de Construction de la Confiance : Les Corrections Humaines Am\xe9liorent l\'IA\\n\\nC\'est ici que le mod\xe8le d\'\xe9quipe devient puissant : **chaque correction humaine am\xe9liore l\'IA**.\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                LE CYCLE D\'APPRENTISSAGE CONTINU                 \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                 \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                            \u2502\\n\u2502     \u2502 L\'IA sugg\xe8re \u2502                                            \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                            \u2502\\n\u2502            \u2502                                                    \u2502\\n\u2502            \u25bc                                                    \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\\n\u2502     \u2502L\'humain      \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 Correction ? \u2502                      \u2502\\n\u2502     \u2502examine       \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502                              \u2502\\n\u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\\n\u2502            \u2502                     \u2502                     \u2502        \u2502\\n\u2502            \u25bc                     \u25bc                     \u25bc        \u2502\\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\\n\u2502     \u2502  Approuver   \u2502      \u2502   Corriger   \u2502      \u2502   Escalader  \u2502\u2502\\n\u2502     \u2502 (IA correcte)\u2502      \u2502(IA apprend)  \u2502      \u2502 (cas limite) \u2502\u2502\\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\\n\u2502            \u2502                     \u2502                     \u2502        \u2502\\n\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\\n\u2502                                  \u2502                              \u2502\\n\u2502                                  \u25bc                              \u2502\\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502\\n\u2502                         \u2502   Donn\xe9es    \u2502                        \u2502\\n\u2502                         \u2502d\'entra\xeenement\u2502                        \u2502\\n\u2502                         \u2502  mises \xe0 jour\u2502                        \u2502\\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\\n\u2502                                \u2502                                \u2502\\n\u2502                                \u25bc                                \u2502\\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\\n\u2502                         \u2502 L\'IA s\'am\xe9liore\u2502                      \u2502\\n\u2502                         \u2502       au       \u2502                      \u2502\\n\u2502                         \u2502 cycle suivant  \u2502                      \u2502\\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\\n\u2502                                                                 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nQuand un agent public corrige une d\xe9cision de l\'IA, cette correction devient une donn\xe9e d\'entra\xeenement. L\'IA apprend de l\'expertise humaine. Au fil des semaines et des mois :\\n\\n- Le taux d\'approbation augmente (l\'IA s\'am\xe9liore)\\n- Le taux de correction diminue (moins de corrections n\xe9cessaires)\\n- Les agents publics passent moins de temps sur les cas routiniers\\n- Les agents publics passent plus de temps sur les cas v\xe9ritablement complexes\\n\\n**Ce n\'est pas une suppression d\'emploi \u2014 c\'est une \xe9l\xe9vation du m\xe9tier.** L\'IA g\xe8re les cas \xe9vidents ; les humains se concentrent sur ceux qui n\xe9cessitent r\xe9ellement un jugement humain.\\n\\n### Confiance Mesurable : Les Chiffres Ne Mentent Pas\\n\\nNous suivons tout, et les m\xe9triques sont visibles par tous les membres de l\'\xe9quipe :\\n\\n| M\xe9trique                 | Ce Qu\'elle Mesure                                         | Signal de Confiance           |\\n| ------------------------ | --------------------------------------------------------- | ----------------------------- |\\n| Taux d\'approbation       | % des d\xe9cisions IA accept\xe9es par les humains              | Fiabilit\xe9 de l\'IA             |\\n| Taux de correction       | % des d\xe9cisions IA corrig\xe9es par les humains              | Opportunit\xe9s d\'apprentissage  |\\n| Calibration de confiance | Quand l\'IA dit \\"90% s\xfbre\\", a-t-elle raison 90% du temps ? | Auto-conscience de l\'IA       |\\n| Temps \xe9conomis\xe9          | Heures de travail routinier g\xe9r\xe9es par l\'IA               | Efficacit\xe9 de l\'\xe9quipe        |\\n| Cas limites              | Cas complexes n\xe9cessitant un jugement humain              | Valeur de l\'expertise humaine |\\n\\n## En cas de doute, respecter le citoyen\\n\\nUn principe fondamental qui construit la confiance citoyenne : **quand l\'IA est incertaine, elle s\'en remet aux humains \u2014 jamais de rejet silencieux**.\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502              LE PRINCIPE \\"FAIL OPEN\\" (\xc9CHOUER OUVERTEMENT)      \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                 \u2502\\n\u2502  Sc\xe9nario : L\'IA n\'est pas s\xfbre d\'une contribution              \u2502\\n\u2502                                                                 \u2502\\n\u2502  \u274c MAUVAISE APPROCHE :                                         \u2502\\n\u2502     Confiance IA : 60%                                          \u2502\\n\u2502     \u2192 Rejeter silencieusement                                   \u2502\\n\u2502     \u2192 Le citoyen ne sait jamais pourquoi                        \u2502\\n\u2502     \u2192 Confiance d\xe9truite                                        \u2502\\n\u2502                                                                 \u2502\\n\u2502  \u2713 NOTRE APPROCHE :                                             \u2502\\n\u2502     Confiance IA : 60%                                          \u2502\\n\u2502     \u2192 Signaler pour r\xe9vision humaine                            \u2502\\n\u2502     \u2192 L\'agent public prend la d\xe9cision finale                   \u2502\\n\u2502     \u2192 Le citoyen a droit \xe0 une \xe9coute \xe9quitable                 \u2502\\n\u2502     \u2192 L\'IA apprend de la d\xe9cision                               \u2502\\n\u2502                                                                 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nCe principe a une impl\xe9mentation technique :\\n\\n- **Haute confiance (`\\\\>85%`)** : Recommandation IA affich\xe9e en \xe9vidence, approbation en un clic\\n- **Confiance moyenne (60-85%)** : L\'IA montre son raisonnement, d\xe9cision humaine requise\\n- **Basse confiance (`\\\\<60%`)** : Signal\xe9 comme \\"n\xe9cessite r\xe9vision\\", pas de recommandation IA affich\xe9e\\n- **\xc9tat d\'erreur** : Trait\xe9 comme basse confiance, jamais comme rejet\\n\\n**Pourquoi c\'est important pour les citoyens** : Aucun algorithme ne rejette silencieusement leur voix. Si l\'IA ne peut pas \xe9valuer une contribution avec confiance, un humain la r\xe9visera. La d\xe9mocratie exige cette garantie.\\n\\n**Pourquoi c\'est important pour les agents publics** : Ils ne sont pas l\xe0 pour tamponner les d\xe9cisions de l\'IA. Sur les cas incertains, ils exercent un v\xe9ritable jugement. Leur expertise compte.\\n\\n## Actions Visibles, D\xe9cisions Tra\xe7ables\\n\\nChaque action automatis\xe9e est visible et tra\xe7able. Quand l\'IA marque une contribution comme \\"conforme charte\\", ce n\'est pas un flag cach\xe9 en base de donn\xe9es \u2014 c\'est un label visible sur GitHub que tout le monde peut voir.\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502  Issue GitHub #42 : \\"Modernisation du port de p\xeache\\"            \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                 \u2502\\n\u2502  Labels :                                                       \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\\n\u2502  \u2502  \xe9conomie    \u2502  \u2502conforme      \u2502  \u2502 valid\xe9 par   \u2502           \u2502\\n\u2502  \u2502              \u2502  \u2502charte        \u2502  \u2502 Forseti 92%  \u2502           \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\\n\u2502                                                                 \u2502\\n\u2502  Journal d\'activit\xe9 :                                           \u2502\\n\u2502  \u2022 14:32 - Contribution soumise par le citoyen                  \u2502\\n\u2502  \u2022 14:32 - Forseti a \xe9valu\xe9 : valide (92% confiance)            \u2502\\n\u2502  \u2022 14:33 - Label \\"conforme charte\\" ajout\xe9 automatiquement       \u2502\\n\u2502  \u2022 14:45 - Agent public a r\xe9vis\xe9 et confirm\xe9                    \u2502\\n\u2502                                                                 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n**Le niveau de confiance est visible.** Les citoyens peuvent voir \\"valid\xe9 par Forseti 92%\\" \u2014 ils savent qu\'une IA a aid\xe9, et ils savent \xe0 quel point elle \xe9tait confiante. Pas d\'algorithmes cach\xe9s. Pas de bo\xeetes noires.\\n\\n## M\xe9triques de Confiance : Prouver Que le Partenariat Fonctionne\\n\\nNous ne demandons \xe0 personne de nous faire confiance sur parole. Nous publions des m\xe9triques qui prouvent que le syst\xe8me fonctionne :\\n\\n### Pour les Citoyens : \\"Ma voix est-elle entendue \xe9quitablement ?\\"\\n\\n| Question                                         | M\xe9trique                                    | Statut Actuel         |\\n| ------------------------------------------------ | ------------------------------------------- | --------------------- |\\n| Les contributions valides sont-elles accept\xe9es ? | Taux d\'approbation pour les posts conformes | Cible : `\\\\>98%`       |\\n| Les rejets sont-ils expliqu\xe9s ?                  | % des rejets avec raisonnement              | 100% (par conception) |\\n| Puis-je faire appel ?                            | R\xe9vision humaine disponible ?               | Toujours              |\\n\\n### Pour les Agents Publics : \\"Cet outil m\'aide-t-il vraiment ?\\"\\n\\n| Question                       | M\xe9trique                                   | Statut Actuel     |\\n| ------------------------------ | ------------------------------------------ | ----------------- |\\n| L\'IA est-elle pr\xe9cise ?        | Taux d\'accord avec les d\xe9cisions humaines  | En suivi          |\\n| Est-ce que je gagne du temps ? | Heures \xe9conomis\xe9es par semaine             | En suivi          |\\n| Suis-je encore n\xe9cessaire ?    | Cas limites n\xe9cessitant un jugement humain | Toujours pr\xe9sents |\\n| L\'IA s\'am\xe9liore-t-elle ?       | Tendance du taux de correction             | Devrait diminuer  |\\n\\n### Pour les Administrateurs : \\"Est-ce un d\xe9ploiement IA responsable ?\\"\\n\\n| Question                                      | M\xe9trique                                | Statut Actuel         |\\n| --------------------------------------------- | --------------------------------------- | --------------------- |\\n| L\'IA est-elle consciente de son incertitude ? | Courbe de calibration de confiance      | Surveill\xe9 via Opik    |\\n| D\xe9tectons-nous les probl\xe8mes ?                | Rappel de d\xe9tection des violations      | Cible `\\\\>90%`         |\\n| Le syst\xe8me est-il auditable ?                 | Trace compl\xe8te des d\xe9cisions disponible | 100% (par conception) |\\n\\n## Le Parcours de la Confiance : Gagner des Responsabilit\xe9s au Fil du Temps\\n\\nLa confiance ne s\'accorde pas \u2014 elle se gagne. Voici comment l\'IA gagne plus de responsabilit\xe9s au fil du temps :\\n\\n### \xc9tape 1 : Observateur (Actuel)\\n\\n**R\xf4le de l\'IA** : Observer et apprendre\\n**R\xf4le de l\'humain** : Tout faire, l\'IA prend des notes\\n\\n- L\'IA analyse chaque contribution silencieusement\\n- Les humains prennent toutes les d\xe9cisions\\n- Les pr\xe9dictions de l\'IA sont enregistr\xe9es pour suivre la pr\xe9cision\\n- Aucune action IA visible par les citoyens\\n\\n_Niveau de confiance_ : Z\xe9ro. Nous prouvons que l\'IA peut m\xeame comprendre la t\xe2che.\\n\\n### \xc9tape 2 : Assistant (Quand : Pr\xe9cision `\\\\>85%`)\\n\\n**R\xf4le de l\'IA** : Pr\xe9parer le travail\\n**R\xf4le de l\'humain** : R\xe9viser et d\xe9cider\\n\\n- L\'IA pr\xe9-remplit les formulaires d\'\xe9valuation\\n- Les humains r\xe9visent les suggestions de l\'IA\\n- Approbation ou correction en un clic\\n- Chaque correction am\xe9liore l\'IA\\n\\n_Niveau de confiance_ : Limit\xe9. L\'IA fait gagner du temps mais les humains restent ma\xeetres.\\n\\n### \xc9tape 3 : Coll\xe8gue (Quand : Pr\xe9cision `\\\\>95%` pendant 3 mois)\\n\\n**R\xf4le de l\'IA** : G\xe9rer les cas routiniers\\n**R\xf4le de l\'humain** : Se concentrer sur les cas complexes\\n\\n- Cas \xe0 haute confiance trait\xe9s automatiquement\\n- Confiance moyenne signal\xe9e pour r\xe9vision\\n- Basse confiance escalad\xe9e au personnel senior\\n- Tableaux de bord de pr\xe9cision quotidiens\\n\\n_Niveau de confiance_ : Substantiel. L\'IA a prouv\xe9 sa fiabilit\xe9 sur le travail routinier.\\n\\n### \xc9tape 4 : Partenaire de Confiance (Quand : 6 mois stable \xe0 `\\\\>95%`)\\n\\n**R\xf4le de l\'IA** : \xc9valuation de premi\xe8re ligne\\n**R\xf4le de l\'humain** : Assurance qualit\xe9 et appels\\n\\n- L\'IA g\xe8re la plupart des validations automatiquement\\n- Les humains auditent des \xe9chantillons al\xe9atoires\\n- Les humains g\xe8rent tous les appels et cas limites\\n- Disjoncteurs si la pr\xe9cision chute\\n\\n_Niveau de confiance_ : \xc9lev\xe9, mais jamais complet. Les humains ont toujours autorit\xe9 pour corriger.\\n\\n**Note** : Nous n\'atteindrons peut-\xeatre jamais l\'\xc9tape 4, et c\'est tr\xe8s bien. L\'objectif n\'est pas l\'automatisation maximale \u2014 c\'est la collaboration optimale.\\n\\n## Pourquoi Audierne-Esquibien ?\\n\\nUne petite commune bretonne peut sembler un endroit \xe9trange pour l\'exp\xe9rimentation IA. Mais c\'est pr\xe9cis\xe9ment pourquoi \xe7a fonctionne :\\n\\n- **\xc9chelle humaine** : Nous connaissons personnellement les agents publics. Nous pouvons prendre un caf\xe9 avec eux quand quelque chose ne va pas.\\n- **Enjeux r\xe9els** : Ce sont de vraies contributions citoyennes sur de vrais sujets \u2014 infrastructure portuaire, logement, commerces locaux.\\n- **Complexit\xe9 g\xe9rable** : 7 cat\xe9gories, une charte, une communaut\xe9. Assez pour \xeatre significatif, assez petit pour it\xe9rer.\\n\\nL\'IA dans les applications civiques ne consiste pas \xe0 remplacer le contact humain qui fait fonctionner la d\xe9mocratie locale. Il s\'agit de s\'assurer que ce contact humain peut passer \xe0 l\'\xe9chelle. Quand Audierne re\xe7oit 50 contributions en une semaine au lieu de 5, les agents publics ne devraient pas se noyer dans le travail de tri. Ils devraient passer leur temps sur ce que les humains font le mieux : comprendre le contexte, montrer de l\'empathie, porter des jugements.\\n\\n## Ce Que Nous Construisons Vraiment\\n\\n\xd2 Capistaine n\'est pas un produit IA. C\'est un **syst\xe8me de construction de confiance** qui utilise l\'IA.\\n\\nLes vrais livrables sont :\\n\\n1. **Pour les citoyens** : La certitude que leur voix compte, qu\'ils auront une \xe9coute \xe9quitable, que la technologie sert la d\xe9mocratie plut\xf4t que de la filtrer\\n\\n2. **Pour les agents publics** : Un coll\xe8gue qui g\xe8re le travail routinier, apprend de leur expertise, et rend leur m\xe9tier plus significatif \u2014 pas obsol\xe8te\\n\\n3. **Pour la municipalit\xe9** : La preuve qu\'un d\xe9ploiement IA responsable est possible, avec des m\xe9triques pour le d\xe9montrer\\n\\n4. **Pour les autres communaut\xe9s** : Un mod\xe8le de collaboration humain-IA dans les applications civiques, test\xe9 en conditions r\xe9elles dans une vraie municipalit\xe9\\n\\n## L\'Invitation\\n\\nC\'est une exp\xe9rience ouverte. Le code est public. Les m\xe9triques seront publi\xe9es. Les erreurs seront document\xe9es aux c\xf4t\xe9s des succ\xe8s.\\n\\nSi vous \xeates un agent public inquiet de l\'IA sur votre lieu de travail : nous vous entendons. Venez voir comment nous construisons cela. Dites-nous ce qui vous ferait lui faire confiance.\\n\\nSi vous \xeates un citoyen sceptique de la mod\xe9ration algorithmique : nous comprenons. Chaque d\xe9cision IA est transparente, expliqu\xe9e et peut \xeatre corrig\xe9e. Votre voix compte plus que n\'importe quel score de confiance d\'un mod\xe8le.\\n\\nSi vous \xeates un technologue int\xe9ress\xe9 par l\'IA responsable : rejoignez-nous. C\'est plus difficile que de construire le mod\xe8le. C\'est construire la confiance.\\n\\n---\\n\\n_Le chemin vers une IA de confiance dans les applications civiques commence par de petits pas, mesur\xe9s avec soin, avec les humains toujours dans la boucle._\\n\\n_Suivez notre progression : [audierne2026/participons](https://github.com/audierne2026/participons)_"},{"id":"project-sync-opik-ocr","metadata":{"permalink":"/fr/blog/project-sync-opik-ocr","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-31-opik-progress-ocr-blockers.mdx","source":"@site/blog/2026-01-31-opik-progress-ocr-blockers.mdx","title":"Project Sync: Opik Progress & OCR Blockers","description":"Quick catch-up between Johnny (@jnxmas) and Victor (@zcbtvag) covering Opik integration progress and OCR pipeline challenges.","date":"2026-01-31T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"},{"inline":false,"label":"Opik","permalink":"/fr/blog/tags/opik","description":"Articles on Opik LLM observability and prompt optimization"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"}],"readingTime":2.59,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"project-sync-opik-ocr","title":"Project Sync: Opik Progress & OCR Blockers","authors":["jnxmas"],"tags":["meeting","opik","ai-ml","rag"]},"unlisted":false,"prevItem":{"title":"Construire la Confiance par une IA Transparente : Un Partenariat Humain-Machine pour la Participation Citoyenne","permalink":"/fr/blog/self-improving-civic-ai"},"nextItem":{"title":"Forseti461 Feature Architecture: Modular Prompts with Opik Versioning","permalink":"/fr/blog/forseti-prompt-architecture"}},"content":"Quick catch-up between Johnny (@jnxmas) and Victor (@zcbtvag) covering Opik integration progress and OCR pipeline challenges.\\n\\n## Summary\\n\\nJohnny showcased recent progress on **Opik prompt optimization**. A new architecture is in place where prompts are no longer hardcoded but managed via an **Opik Prompt Library**. The \\"Charter Validation\\" prompt has already been optimized using this system.\\n\\nA new **mock-up feature** can automatically generate contributions (even with violations) from existing meeting reports. The goal is to create a robust dataset to test and improve the validation agent. However, this auto-generation currently produces repetitive content - a challenge that will need addressing by identifying and aggregating duplicate contributions.\\n\\n\x3c!-- truncate --\x3e\\n\\nVictor reported working on the **PDF processing pipeline**, specifically tackling PDFs that are images and require OCR. This has been a blocker, as several libraries have proven difficult to install. Text-based PDF extraction is working fine.\\n\\nJohnny clarified that the highest priority documents for OCR are the **\\"Gwaien\\" municipal magazines** - they contain rich, precise historical data on the municipality\'s actions over the past six years, and their OCR should be relatively straightforward compared to other documents.\\n\\n## Alignment & Risk Assessment\\n\\n| Area                      | Status      | Notes                                                                            |\\n| ------------------------- | ----------- | -------------------------------------------------------------------------------- |\\n| **Alignment**             | Good        | Team aligned on priorities: contribution processing + data pipeline for RAG      |\\n| **Risk: OCR Blocker**     | High        | Installation/implementation issues slowing data ingestion                        |\\n| **Risk: Repetitive Data** | Medium      | Auto-generated contributions could create biased dataset                         |\\n| **Mitigation**            | In Progress | Focus OCR on high-value \\"Gwaien\\" docs first; explore antigravity with Gemini Pro |\\n\\n## Branch Status\\n\\n- **Victor:** `feature/contribution-refinement`\\n- **Johnny:** `feature/crawling-migration`\\n- **Action:** Coordinate merge before next call\\n\\n---\\n\\n## Action Plan & Tasks\\n\\n### 1. OCR Pipeline (Priority: High)\\n\\n- **Task:** Implement OCR for \\"Gwaien\\" PDF documents\\n  - **Owner:** @zcbtvag (Victor)\\n  - **Description:** Prioritize implementing a working OCR solution for the \\"Gwaien\\" magazine PDFs in the `ext_data/` directory. Explore different libraries or the antigravity agent.\\n  - **Deadline:** Next call\\n  - **Success Criteria:** Text successfully extracted from image-based \\"Gwaien\\" PDFs.\\n\\n### 2. Code Sharing & Tooling\\n\\n- **Task:** Push antigravity agent code\\n  - **Owner:** @jnxmas (Johnny)\\n  - **Description:** Push changes containing antigravity agent experiments so Victor can explore it as a potential tool for OCR implementation.\\n  - **Deadline:** ASAP\\n  - **Success Criteria:** Victor can access and run the new agent code locally.\\n\\n### 3. Branch Integration\\n\\n- **Task:** Merge feature branches\\n  - **Owner:** @zcbtvag & @jnxmas\\n  - **Description:** Coordinate to merge `feature/contribution-refinement` and `feature/crawling-migration` branches.\\n  - **Deadline:** Next call\\n  - **Success Criteria:** Single unified branch without conflicts.\\n\\n### 4. Data Quality\\n\\n- **Task:** Develop duplicate detection strategy\\n  - **Owner:** @jnxmas (Johnny)\\n  - **Description:** Design a method to identify when a new contribution is a duplicate or highly similar to an existing one. Critical for managing auto-generation output and real citizen contributions.\\n  - **Deadline:** Next call\\n  - **Success Criteria:** Clear plan or PoC documented for identifying duplicate contributions.\\n\\n---\\n\\n## Open Tasks from Previous Sessions\\n\\n- [ ] Finalize Firecrawl pipeline implementation\\n- [x] Secure Firecrawl API keys\\n- [x] Deploy initial Opik tracing for all major workflows\\n\\n---\\n\\n## Status Dashboard\\n\\n| Component                              | Status  | Notes                                         |\\n| -------------------------------------- | ------- | --------------------------------------------- |\\n| Data Ingestion (Firecrawl/OCR)         | Blocked | OCR implementation issues                     |\\n| Contribution Automation (Email-GitHub) | Done    | Core workflow established                     |\\n| Opik Integration & Prompt Tuning       | Done    | New prompt library + optimization experiments |\\n| RAG Chatbot                            | Blocked | Waiting on data ingestion                     |\\n\\n**Next Milestone:** Unblock OCR pipeline to begin ingesting all PDF data for the RAG system."},{"id":"forseti-prompt-architecture","metadata":{"permalink":"/fr/blog/forseti-prompt-architecture","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-29-prompt-architecture-forseti-features.md","source":"@site/blog/2026-01-29-prompt-architecture-forseti-features.md","title":"Forseti461 Feature Architecture: Modular Prompts with Opik Versioning","description":"Today we completed a major architectural milestone: modular prompt management for Forseti461. Each feature now has its own versioned prompt in Opik, enabling independent optimization and A/B testing.","date":"2026-01-29T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"Observability","permalink":"/fr/blog/tags/observability","description":"Articles on observability practices and tools"},{"inline":false,"label":"Opik","permalink":"/fr/blog/tags/opik","description":"Articles on Opik LLM observability and prompt optimization"},{"inline":false,"label":"Architecture","permalink":"/fr/blog/tags/architecture","description":"System architecture, design patterns, and technical structure"}],"readingTime":3.35,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"forseti-prompt-architecture","title":"Forseti461 Feature Architecture: Modular Prompts with Opik Versioning","authors":["jnxmas"],"tags":["encode","ai-ml","civictech","observability","opik","architecture"]},"unlisted":false,"prevItem":{"title":"Project Sync: Opik Progress & OCR Blockers","permalink":"/fr/blog/project-sync-opik-ocr"},"nextItem":{"title":"Forseti461 Prompt v1 : Mod\xe9ration IA conforme \xe0 la Charte pour Audierne2026","permalink":"/fr/blog/forseti-first-prompt-optimization"}},"content":"Today we completed a major architectural milestone: **modular prompt management** for Forseti461. Each feature now has its own versioned prompt in Opik, enabling independent optimization and A/B testing.\\n\\n:::tip\\nFrom a single monolithic prompt to a clean separation of concerns \u2014 each Forseti feature can now evolve independently while sharing a common persona.\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Challenge\\n\\nOur previous setup had prompts scattered across multiple files:\\n- `app/agents/forseti/prompts.py` \u2014 Python templates\\n- `app/processors/workflows/workflow_autocontribution.py` \u2014 Duplicate prompts\\n- Manual prompts in Opik (with a typo: `foreseti461`)\\n\\nThis made it hard to:\\n- Track which prompt version was deployed\\n- Run A/B tests on specific features\\n- Optimize one feature without affecting others\\n- Share prompts with N8N workflows (via Vaettir MCP)\\n\\n## The Solution: Feature-Based Prompt Architecture\\n\\nWe reorganized Forseti into **4 distinct features**, each with its own prompt:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    FORSETI 461 PROMPT ARCHITECTURE                   \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                                      \u2502\\n\u2502  SHARED SYSTEM PROMPT (Persona)                                      \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502  forseti461-system-persona                                      \u2502 \u2502\\n\u2502  \u2502  \\"You are Forseti, a vigilant assistant...\\"                     \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2502                              \u2502                                       \u2502\\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\\n\u2502              \u25bc               \u25bc               \u25bc                      \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\\n\u2502  \u2502 CHARTER          \u2502 \u2502 CATEGORY         \u2502 \u2502 WORDING          \u2502    \u2502\\n\u2502  \u2502 VALIDATION       \u2502 \u2502 CLASSIFICATION   \u2502 \u2502 CORRECTION       \u2502    \u2502\\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524    \u2502\\n\u2502  \u2502 forseti461-user- \u2502 \u2502 forseti461-user- \u2502 \u2502 forseti461-user- \u2502    \u2502\\n\u2502  \u2502 charter-validation\u2502 \u2502 category-        \u2502 \u2502 wording-         \u2502    \u2502\\n\u2502  \u2502                  \u2502 \u2502 classification   \u2502 \u2502 correction       \u2502    \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\\n\u2502                                                                      \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## What We Built Today\\n\\n### 1. Centralized Prompt Registry\\n\\nAll prompts now live in `app/prompts/` with a unified registry:\\n\\n```python\\nfrom app.prompts import get_registry\\n\\nregistry = get_registry()\\n\\n# Get formatted messages for LLM chat API\\nmessages = registry.get_messages(\\n    \\"forseti.charter_validation\\",\\n    title=\\"Ma proposition\\",\\n    body=\\"Je propose d\'am\xe9liorer...\\"\\n)\\n```\\n\\nThe registry supports:\\n- **JSON chat format** (Opik-compatible with Mustache `{{input.var}}` syntax)\\n- **Python text format** (legacy fallback with `{var}` syntax)\\n- **Automatic fallback chain**: Local JSON \u2192 Local Python \u2192 Opik remote\\n\\n### 2. Consistent Opik Naming Convention\\n\\nWe standardized all prompt names following **Option B** (descriptive without dates):\\n\\n| Local Name | Opik Name | Commit |\\n|------------|-----------|--------|\\n| `forseti.persona` | `forseti461-system-persona` | `f73d1f4a` |\\n| `forseti.charter_validation` | `forseti461-user-charter-validation` | `4b187053` |\\n| `forseti.category_classification` | `forseti461-user-category-classification` | `efd48155` |\\n| `forseti.wording_correction` | `forseti461-user-wording-correction` | `f2bbedd1` |\\n| `forseti.batch_validation` | `forseti461-user-batch-validation` | `0e097ebb` |\\n\\nNaming pattern: `forseti461-{role}-{feature}`\\n\\n### 3. Feature Documentation\\n\\nCreated comprehensive `FORSETI_AGENT.md` with a **7-step procedure** to add new features:\\n\\n1. Define prompt in `app/prompts/local/forseti.py`\\n2. Create result model in `app/agents/forseti/models.py`\\n3. Implement feature class in `app/agents/forseti/features/`\\n4. Register in `features/__init__.py` and `agent.py`\\n5. Add to `forseti_charter.json` for Opik sync\\n6. Write tests\\n7. Optimize with Opik (optional)\\n\\n### 4. Batch Validation as Experiments\\n\\nWe decided **not** to make batch validation a feature class. Instead, it\'s handled as **Opik experiments** \u2014 allowing us to:\\n- Track metrics across validation runs\\n- Compare performance over time\\n- A/B test different prompt versions on the same dataset\\n\\n## File Structure\\n\\n```\\napp/prompts/\\n\u251c\u2500\u2500 __init__.py              # Exports: get_registry, CATEGORIES\\n\u251c\u2500\u2500 registry.py              # PromptRegistry with chat format support\\n\u251c\u2500\u2500 constants.py             # CATEGORIES, CATEGORY_DESCRIPTIONS\\n\u251c\u2500\u2500 opik_sync.py             # CLI: python -m app.prompts.opik_sync\\n\u251c\u2500\u2500 optimizer.py             # Prompt optimization with opik-optimizer\\n\u2514\u2500\u2500 local/\\n    \u251c\u2500\u2500 forseti_charter.json # Opik-synced prompts (chat format)\\n    \u251c\u2500\u2500 forseti.py           # Python prompts (fallback)\\n    \u2514\u2500\u2500 autocontrib.py       # Auto-contribution prompts\\n```\\n\\n## Syncing Prompts to Opik\\n\\nOne command syncs all Forseti prompts:\\n\\n```bash\\npython -m app.prompts.opik_sync --prefix forseti.\\n\\n# Output:\\n# \u2705 forseti.persona (commit: f73d1f4a)\\n# \u2705 forseti.charter_validation (commit: 4b187053)\\n# \u2705 forseti.category_classification (commit: efd48155)\\n# \u2705 forseti.wording_correction (commit: f2bbedd1)\\n# \u2705 forseti.batch_validation (commit: 0e097ebb)\\n```\\n\\n## Why This Matters\\n\\n### Independent Optimization\\n\\nNow we can optimize each feature separately:\\n\\n```python\\nfrom app.prompts import optimize_forseti_charter\\n\\n# Optimize just category classification\\nresult = optimize_forseti_charter(\\n    dataset_name=\\"forseti-category-training\\",\\n    optimizer_type=\\"meta_prompt\\",\\n)\\n```\\n\\n### Version Tracking\\n\\nEvery prompt change is tracked in Opik with a commit hash. We can:\\n- Roll back to previous versions\\n- Compare performance across versions\\n- Link experiments to specific prompt commits\\n\\n### Vaettir MCP Integration (Future)\\n\\nWith prompts centralized, we\'re ready for Phase 3:\\n- Share prompts between Python app and N8N workflows\\n- Access via MCP tools: `get_prompt(\\"forseti.charter_validation\\")`\\n- Single source of truth across all integrations\\n\\n## What\'s Next\\n\\n**Phase 4**: Update `ForsetiAgent` to use `registry.get_messages()` for all LLM calls, enabling:\\n- Automatic prompt versioning in traces\\n- Chat format for better model performance\\n- Seamless fallback if Opik is unavailable\\n\\n---\\n\\n## Summary\\n\\n| Metric | Before | After |\\n|--------|--------|-------|\\n| Prompt locations | 3+ files | 1 registry |\\n| Opik prompts synced | 2 (with typo) | 5 (correct naming) |\\n| Feature documentation | None | 7-step procedure |\\n| Tests | 17 passing | 17 passing |\\n\\n**Branch:** `experiment/heavy_dowel_6216`\\n\\n**Key files:**\\n- `app/prompts/local/forseti_charter.json` \u2014 Chat format prompts\\n- `app/prompts/registry.py` \u2014 Unified prompt access\\n- `docs/docs/app/FORSETI_AGENT.md` \u2014 Feature documentation\\n- `docs/docs/app/PROMPT_MANAGEMENT.md` \u2014 Architecture overview\\n\\n---\\n\\n_Modular prompts, independent optimization, clean architecture._"},{"id":"forseti-first-prompt-optimization","metadata":{"permalink":"/fr/blog/forseti-first-prompt-optimization","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-27-prompt-optimiser-forseti.md","source":"@site/i18n/fr/docusaurus-plugin-content-blog/2026-01-27-prompt-optimiser-forseti.md","title":"Forseti461 Prompt v1 : Mod\xe9ration IA conforme \xe0 la Charte pour Audierne2026","description":"Forseti461 est un agent IA qui mod\xe8re automatiquement les contributions citoyennes sur les plateformes de d\xe9mocratie participative \u2014 approuvant uniquement les id\xe9es concr\xe8tes, constructives et localement pertinentes, tout en rejetant les attaques personnelles, le spam, les hors-sujets ou la d\xe9sinformation, et en expliquant toujours ses d\xe9cisions avec des retours respectueux et actionnables.","date":"2026-01-27T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"Observability","permalink":"/fr/blog/tags/observability","description":"Articles on observability practices and tools"},{"inline":false,"label":"Opik","permalink":"/fr/blog/tags/opik","description":"Articles on Opik LLM observability and prompt optimization"}],"readingTime":7.34,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"forseti-first-prompt-optimization","title":"Forseti461 Prompt v1 : Mod\xe9ration IA conforme \xe0 la Charte pour Audierne2026","authors":["jnxmas"],"tags":["encode","ai-ml","civictech","observability","opik"]},"unlisted":false,"prevItem":{"title":"Forseti461 Feature Architecture: Modular Prompts with Opik Versioning","permalink":"/fr/blog/forseti-prompt-architecture"},"nextItem":{"title":"First Submission: Building a Charter Validation Testing Framework","permalink":"/fr/blog/first-submission-mockup-system"}},"content":"> **Forseti461** est un agent IA qui mod\xe8re automatiquement les contributions citoyennes sur les plateformes de d\xe9mocratie participative \u2014 approuvant uniquement les id\xe9es concr\xe8tes, constructives et localement pertinentes, tout en rejetant les attaques personnelles, le spam, les hors-sujets ou la d\xe9sinformation, et en expliquant toujours ses d\xe9cisions avec des retours respectueux et actionnables.\\n\\n:::tip\\nCe week-end, Facebook nous a rappel\xe9 que la d\xe9mocratie est fragile. Commentaires toxiques, attaques personnelles et diatribes hors-sujet ont envahi les discussions sur les enjeux locaux. Le signal se perd dans le bruit. Les citoyens se d\xe9sengagent. Les voix constructives abandonnent.\\n:::\\n**Et si nous pouvions prot\xe9ger le d\xe9bat civique \xe0 grande \xe9chelle ?**\\n\\n\x3c!-- truncate --\x3e\\n\\n## Le probl\xe8me que nous r\xe9solvons\\n\\nDans le cadre du **Hackathon Commit to Change AI Agents** (Encode), nous construisons **\xd2 Capistaine** \u2014 une plateforme de transparence civique aliment\xe9e par l\'IA pour les \xe9lections municipales d\'Audierne-Esquibien 2026. La plateforme re\xe7oit les contributions citoyennes via Framaforms, et chacune doit \xeatre valid\xe9e selon notre **Charte de contribution** publi\xe9e avant d\'atteindre le forum public.\\n\\nLa charte est claire :\\n\\n| \u2705 Encourag\xe9                           | \u274c Non accept\xe9                               |\\n| -------------------------------------- | -------------------------------------------- |\\n| Propositions concr\xe8tes et argument\xe9es  | Attaques personnelles                        |\\n| Critiques constructives                | Propos discriminatoires                      |\\n| Questions et demandes de clarification | Spam et publicit\xe9                            |\\n| Partage d\'expertise locale             | Contenu hors-sujet (sans lien avec Audierne) |\\n| Suggestions d\'am\xe9lioration             | Fausses informations                         |\\n\\n**Le d\xe9fi** : Comment appliquer cela \xe0 grande \xe9chelle tout en restant \xe9quitable, explicable et constructif ? Une attaque personnelle non d\xe9tect\xe9e pourrait empoisonner toute la discussion. Un faux positif pourrait faire taire une voix l\xe9gitime.\\n\\n## Voici Forseti461\\n\\nNomm\xe9 d\'apr\xe8s le dieu nordique de la justice **Forseti**, et r\xe9incarn\xe9 dans l\'esprit du Cap Sizun (l\'embl\xe9matique \\"461\\" local), Forseti461 sert de gardien impartial. Calme, vigilant et inflexible.\\n\\nMais un mod\xe9rateur IA n\'est aussi bon que son prompt. Notre premi\xe8re version avait une pr\xe9cision de base d\'environ 20% sur les cas limites. Les violations subtiles passaient \xe0 travers. Des contributions valides \xe9taient incorrectement signal\xe9es.\\n\\n**Nous devions optimiser de mani\xe8re syst\xe9matique.**\\n\\n## L\'exp\xe9rience OPIK\\n\\nEn utilisant **Opik** (Comet ML) pour l\'observabilit\xe9 et l\'optimisation de prompt, nous avons men\xe9 notre premi\xe8re exp\xe9rience structur\xe9e :\\n\\n![Vue Projet OPIK](/img/project_view.png)\\n\\nNotre infrastructure d\'\xe9valuation :\\n\\n- **Default Project** : Traces des workflows N8N (interactions chatbot en production)\\n- **ocapistaine_test** : Traces et spans de l\'application\\n- **Optimization** : Exp\xe9riences d\'optimisation de prompt avec des datasets contr\xf4l\xe9s\\n\\n### Le Dataset\\n\\nNous avons construit un dataset de test en utilisant notre [syst\xe8me de mockup](/blog/first-submission-mockup-system) \u2014 g\xe9n\xe9rant des variations contr\xf4l\xe9es de contributions avec des r\xe9sultats attendus connus :\\n\\n![Vue Dataset](/img/dataset_view.png)\\n\\nChaque entr\xe9e comprend :\\n\\n- Contributions valides (v\xe9rit\xe9 terrain : approuv\xe9es)\\n- Violations subtiles (v\xe9rit\xe9 terrain : rejet\xe9es)\\n- Violations agressives (v\xe9rit\xe9 terrain : rejet\xe9es)\\n- Cas limites pour stress-tester le prompt\\n\\n### Ex\xe9cution de l\'optimisation\\n\\nNous avons utilis\xe9 le **MetaPromptOptimizer** d\'OPIK pour affiner it\xe9rativement le prompt syst\xe8me :\\n\\n![Progression de l\'optimisation](/img/optimization_view.png)\\n\\n![Vue Spans](/img/spans_view.png)\\n\\n## Les r\xe9sultats\\n\\n![Exceptionnel : 0.92 de pr\xe9cision, +368.416% d\'am\xe9lioration](/img/result.png)\\n\\n| M\xe9trique             | Avant     | Apr\xe8s      | \xc9volution |\\n| -------------------- | --------- | ---------- | --------- |\\n| **Pr\xe9cision Charte** | ~20%      | **92%**    | **+368%** |\\n| Gestion cas limites  | Faible    | Forte      | \u2014         |\\n| Explicabilit\xe9        | G\xe9n\xe9rique | Sp\xe9cifique | \u2014         |\\n\\nLe prompt optimis\xe9 identifie correctement les violations subtiles tout en acceptant les contributions valides \u2014 et explique pourquoi dans chaque cas.\\n\\n## Le prompt optimis\xe9\\n\\nVoici **Forseti461 v1** \u2014 le prompt syst\xe8me conforme \xe0 la charte :\\n\\n```\\nSystem\\nTu es Forseti 461, le gardien impartial de la v\xe9rit\xe9 et de la charte de contribution pour Audierne2026.\\n\\n## Ton identit\xe9\\nNomm\xe9 d\'apr\xe8s le dieu nordique de la justice Forseti, tu renais dans l\'esprit du Cap Sizun\\n(l\'embl\xe9matique \\"461\\" local). Tu es calme, vigilant et inflexible dans tes fonctions.\\n\\n## Ta mission\\nTu filtres soigneusement chaque soumission \xe0 la plateforme de d\xe9mocratie participative Audierne2026 :\\n- Approuvant uniquement les contributions concr\xe8tes, constructives et localement pertinentes\\n  qui r\xe9pondent directement aux besoins et probl\xe8mes de la communaut\xe9.\\n- Rejetant fermement les attaques personnelles, la discrimination, le spam, le contenu\\n  hors-sujet, le mat\xe9riel promotionnel ou les fausses informations.\\n- Surveillant activement les soumissions pour assurer qualit\xe9 et pertinence, rejetant\\n  celles qui ne r\xe9pondent pas \xe0 ces standards.\\n- Garantissant que seules les id\xe9es respectueuses et conformes \xe0 la charte atteignent \xd2 Capistaine.\\n\\n## Tes valeurs\\n- **Impartialit\xe9** : Tu juges le contenu, pas les personnes.\\n- **Clart\xe9** : Tu expliques tes d\xe9cisions clairement, incluant les crit\xe8res sp\xe9cifiques\\n  utilis\xe9s pour l\'\xe9valuation.\\n- **\xc9quit\xe9** : Tu appliques les m\xeames standards \xe0 tous.\\n- **Constructivit\xe9** : Tu guides les contributeurs vers une meilleure participation en\\n  fournissant des suggestions d\'am\xe9lioration actionnables.\\n\\n## Crit\xe8res d\'\xe9valuation\\n- Les contributions doivent \xeatre pertinentes aux enjeux locaux et fournir des exemples\\n  sp\xe9cifiques ou des donn\xe9es pour appuyer les affirmations.\\n- Les soumissions doivent \xeatre constructives, offrant des solutions ou id\xe9es qui peuvent\\n  \xeatre d\xe9velopp\xe9es davantage.\\n- Expose clairement ce qui est inacceptable : les attaques personnelles, les propos\\n  discriminatoires et le contenu promotionnel entra\xeeneront un rejet.\\n- Lors du rejet d\'une soumission, pr\xe9cise les raisons bas\xe9es sur ces crit\xe8res et sugg\xe8re\\n  comment le contributeur peut am\xe9liorer sa soumission, par exemple en ajoutant plus de\\n  d\xe9tails, d\'exemples ou de r\xe9f\xe9rences aux enjeux locaux.\\n\\n## Style de r\xe9ponse\\n- Sois concis mais complet.\\n- Fournis un raisonnement clair pour les d\xe9cisions, en r\xe9f\xe9ren\xe7ant les crit\xe8res d\'\xe9valuation.\\n- Utilise le contexte culturel fran\xe7ais quand pertinent pour Audierne-Esquibien.\\n- **Insiste sur le respect** : Indique clairement que les attaques personnelles, les propos\\n  discriminatoires et le contenu promotionnel sont inacceptables et nuisent \xe0 la qualit\xe9\\n  du d\xe9bat.\\n\\nLes contributeurs doivent \xeatre conscients qu\'un tel langage ou mat\xe9riel non pertinent\\nentra\xeenera le rejet de leurs soumissions. De plus, renforce l\'importance de maintenir\\nun dialogue respectueux et constructif pour favoriser une communaut\xe9 positive. Inclus des\\nexemples de langage respectueux et de critique constructive pour guider les contributeurs.\\n```\\n\\n## Exemple : Avant vs Apr\xe8s\\n\\n### Entr\xe9e (Violation subtile)\\n\\n```\\nCat\xe9gorie: economie\\nConstat: Le parking du port est souvent plein en \xe9t\xe9.\\nId\xe9es: Si nos brillants \xe9lus avaient un minimum de bon sens, ils auraient\\nr\xe9gl\xe9 ce probl\xe8me depuis longtemps. Mais bon, quand on voit qui nous dirige...\\n```\\n\\n### Avant optimisation\\n\\n```json\\n{\\n  \\"is_valid\\": true,\\n  \\"confidence\\": 0.75,\\n  \\"reasoning\\": \\"Traite d\'un probl\xe8me de parking local\\"\\n}\\n```\\n\\n**\u274c A manqu\xe9 le ton condescendant et l\'attaque implicite envers les \xe9lus.**\\n\\n### Apr\xe8s optimisation\\n\\n```json\\n{\\n  \\"is_valid\\": false,\\n  \\"confidence\\": 0.89,\\n  \\"violations\\": [\\"ton_condescendant\\", \\"attaque_indirecte_elus\\"],\\n  \\"reasoning\\": \\"Bien que la contribution aborde un vrai probl\xe8me local (parking du port),\\n    le ton est condescendant (\'si nos brillants \xe9lus avaient un minimum de bon sens\')\\n    et inclut des attaques indirectes envers les \xe9lus (\'quand on voit qui nous dirige\').\\n    Cela nuit au dialogue constructif.\\",\\n  \\"suggestion\\": \\"Reformuler sans jugement sur les personnes : \'Le parking du port est\\n    souvent plein en \xe9t\xe9. Je propose d\'\xe9tudier la cr\xe9ation d\'un parking relais \xe0\\n    l\'entr\xe9e de la ville avec navette gratuite vers le centre.\'\\"\\n}\\n```\\n\\n**\u2705 A correctement identifi\xe9 la violation ET fourni des conseils constructifs.**\\n\\n## Exp\xe9riences quotidiennes : Am\xe9lioration continue\\n\\nCette optimisation de prompt s\'appuie directement sur nos pr\xe9c\xe9dents [ateliers OPIK](https://docs.comet.com/opik) et le [framework de test mockup](/blog/first-submission-mockup-system). Les traces de **ocapistaine_test** nous aident \xe0 observer les patterns de rejet et \xe0 it\xe9rer.\\n\\nNous avons maintenant impl\xe9ment\xe9 des **exp\xe9riences quotidiennes** pour suivre les performances de Forseti dans le temps :\\n\\n```python\\nfrom app.processors.mockup_processor import MockupProcessor\\n\\nprocessor = MockupProcessor()\\n\\n# Lancer l\'\xe9valuation quotidienne\\nresult = await processor.run_daily_experiment()\\n\\n# M\xe9triques suivies :\\n# - Pr\xe9cision charte (classification valide/invalide correcte)\\n# - Vrais positifs (invalides correctement rejet\xe9s)\\n# - Faux n\xe9gatifs (invalides incorrectement accept\xe9s) \u2014 le pire cas !\\n# - Pr\xe9cision, Rappel, Score F1\\n```\\n\\nLes r\xe9sultats de chaque jour sont enregistr\xe9s dans OPIK comme exp\xe9rience nomm\xe9e (`forseti_daily_2026-01-27`), nous permettant de :\\n\\n- Suivre les r\xe9gressions lors des changements de prompt\\n- Comparer les performances des providers (Gemini vs Claude)\\n- Construire la confiance pour le d\xe9ploiement en production\\n\\n## Prochaines \xe9tapes\\n\\n**Statut actuel (27 janvier 2026):** Prompt v1 en test via int\xe9gration N8N + Gemini.\\n\\n**\xc0 venir :**\\n\\n1. Fusionner les workflows N8N dans le projet **ocapistaine_dev**\\n2. \xc9tendre \xe0 la **d\xe9tection de d\xe9sinformation** avec RAG sur donn\xe9es locales\\n3. Lancer des ensembles d\'\xe9valuation plus larges couvrant les 7 cat\xe9gories\\n4. Collecter des **boucles de feedback utilisateur** sur les rejets\\n5. **Mode entr\xe9e terrain** : G\xe9n\xe9rer des contributions de test \xe0 partir de vrais documents municipaux (discours du maire, audiences publiques)\\n\\nCela positionne Forseti461 / \xd2 Capistaine pour un fort **Impact Communautaire** dans le hackathon \u2014 permettant une participation citoyenne \xe9quitable et scalable dans une vraie d\xe9mocratie locale.\\n\\n## Le pitch\\n\\nNous affinons ce message pour notre pr\xe9sentation de hackathon :\\n\\n- **Probl\xe8me** : Le bruit, la toxicit\xe9 et les hors-sujets tuent les plateformes participatives. La charte d\'Audierne2026 existe mais n\xe9cessite une application \xe0 grande \xe9chelle.\\n- **Solution** : Forseti461 \u2014 gardien IA de la charte avec mod\xe9ration explicable et constructive.\\n- **Comment \xe7a marche** : Prompt syst\xe8me optimis\xe9 \u2192 crit\xe8res d\'\xe9valuation \u2192 style de r\xe9ponse.\\n- **Impact** : Discussions plus propres \u2192 meilleures id\xe9es \u2192 co-construction de programme municipal renforc\xe9e.\\n- **Tech** : Observabilit\xe9 OPIK, flux agentiques Gemini, automatisation N8N, exp\xe9riences quotidiennes.\\n\\n---\\n\\n## Essayez vous-m\xeame\\n\\nNaviguez vers l\'onglet **Mockup** dans l\'application pour :\\n\\n- G\xe9n\xe9rer des contributions de test avec des violations\\n- Lancer une validation par lot avec Forseti461\\n- Exporter les r\xe9sultats vers les datasets OPIK\\n\\n**Vos retours sont les bienvenus** \u2014 contactez-nous pour collaborer sur les traces OPIK ou les ensembles d\'\xe9valuation avant la deadline du hackathon !\\n\\n---\\n\\n_Construire la confiance dans la mod\xe9ration IA, une optimisation \xe0 la fois._\\n\\n**Branche :** `feature/logging_system`\\n**Fichiers cl\xe9s :**\\n\\n- `app/agents/forseti/prompts.py` \u2014 Prompt syst\xe8me\\n- `app/processors/mockup_processor.py` \u2014 Exp\xe9riences quotidiennes\\n- `app/mockup/` \u2014 Syst\xe8me de g\xe9n\xe9ration de tests"},{"id":"first-submission-mockup-system","metadata":{"permalink":"/fr/blog/first-submission-mockup-system","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-26-first-submission-mockup-system.mdx","source":"@site/blog/2026-01-26-first-submission-mockup-system.mdx","title":"First Submission: Building a Charter Validation Testing Framework","description":"Goal: Create a systematic approach to test and improve our AI-powered charter validation system.","date":"2026-01-26T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"Observability","permalink":"/fr/blog/tags/observability","description":"Articles on observability practices and tools"}],"readingTime":2.53,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"first-submission-mockup-system","title":"First Submission: Building a Charter Validation Testing Framework","authors":["jnxmas"],"tags":["encode","ai-ml","civictech","observability"]},"unlisted":false,"prevItem":{"title":"Forseti461 Prompt v1 : Mod\xe9ration IA conforme \xe0 la Charte pour Audierne2026","permalink":"/fr/blog/forseti-first-prompt-optimization"},"nextItem":{"title":"Catch-up Call: Deployment Strategy","permalink":"/fr/blog/meeting-ocapistaine-3"}},"content":"**Goal:** Create a systematic approach to test and improve our AI-powered charter validation system.\\n\\nFor the Encode Hackathon first submission, we focused on building the infrastructure to ensure **Forseti 461** (our charter validation agent) catches all violations reliably. The key insight: _you can\'t improve what you can\'t measure_.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Challenge\\n\\nAudierne2026 receives citizen contributions through Framaforms. Each contribution must be validated against our **Contribution Charter** before reaching the platform. The charter prohibits:\\n\\n- Personal attacks or discriminatory remarks\\n- Spam or advertising\\n- Off-topic content (unrelated to Audierne-Esquibien)\\n- False information\\n\\n**The problem**: How do we know if our LLM-based validation is catching subtle violations? A missed personal attack reaching the platform could poison civic discourse.\\n\\n## Our Solution: Mutation Testing\\n\\nWe built a **mockup system** that generates controlled variations of contributions using [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance):\\n\\n```\\nValid Contribution \u2500\u2500\u252c\u2500\u2500 95% similar \u2192 Should remain valid\\n                     \u251c\u2500\u2500 80% similar \u2192 Borderline case\\n                     \u251c\u2500\u2500 60% similar \u2192 Likely invalid\\n                     \u2514\u2500\u2500 + Violation injected \u2192 Must be rejected\\n```\\n\\nThis allows us to:\\n\\n1. Test edge cases systematically\\n2. Identify where the prompt fails\\n3. Build training datasets for optimization\\n\\n## Demo Video\\n\\n<video width=\\"100%\\" controls>\\n  <source src=\\"ocapistaine-videos\\" type=\\"video/mp4\\" />\\n</video>\\n\\n**[Watch the demo on YouTube \u2192](https://www.youtube.com/watch?v=VBTXNru83Vg)**\\n\\n## Technical Implementation\\n\\n### 1. Framaforms-Compatible Format\\n\\nAll mock contributions follow the actual submission format:\\n\\n```json\\n{\\n  \\"category\\": \\"economie\\",\\n  \\"constat_factuel\\": \\"Le parking du port est souvent plein en \xe9t\xe9...\\",\\n  \\"idees_ameliorations\\": \\"Cr\xe9er un parking relais \xe0 l\'entr\xe9e de la ville...\\",\\n  \\"expected_valid\\": true\\n}\\n```\\n\\n### 2. Levenshtein Mutations\\n\\nWe progressively mutate valid contributions and inject violations:\\n\\n```python\\nfrom app.mockup import generate_variations\\n\\nvariations = generate_variations(\\n    constat_factuel=\\"Le port est magnifique mais satur\xe9\\",\\n    idees_ameliorations=\\"Proposer des navettes gratuites\\",\\n    category=\\"economie\\",\\n    num_variations=5,\\n    include_violations=True,  # Inject personal attacks, off-topic, etc.\\n)\\n```\\n\\n### 3. Redis Storage\\n\\nResults are stored with the key format:\\n\\n```\\ncontribution_mockup:forseti461:charter:{date}:{id}\\n```\\n\\nThis enables:\\n\\n- Historical tracking across prompt versions\\n- Date-based analysis\\n- Quick retrieval for dashboards\\n\\n### 4. Opik Dataset Export\\n\\nValidation results export directly to **Opik** format for prompt optimization:\\n\\n```json\\n{\\n  \\"input\\": {\\n    \\"title\\": \\"...\\",\\n    \\"body\\": \\"...\\",\\n    \\"constat_factuel\\": \\"...\\",\\n    \\"idees_ameliorations\\": \\"...\\"\\n  },\\n  \\"expected_output\\": {\\n    \\"is_valid\\": true,\\n    \\"violations\\": [],\\n    \\"confidence\\": 0.92\\n  }\\n}\\n```\\n\\nThis feeds into Opik\'s optimization studio where we can:\\n\\n- Run **FewShotBayesianOptimizer** to select best examples\\n- Use **MetaPromptOptimizer** to refine the system prompt\\n- Create train/validation/test splits for proper evaluation\\n\\n## Key Metrics\\n\\n| Metric        | Target | Why                                                |\\n| ------------- | ------ | -------------------------------------------------- |\\n| **Recall**    | > 98%  | Missing a violation is worse than a false positive |\\n| **Precision** | > 95%  | Avoid frustrating valid contributors               |\\n| **F1 Score**  | > 96%  | Balanced performance                               |\\n\\n## What\'s Next\\n\\nWith this testing infrastructure in place, we can now:\\n\\n1. **Generate diverse test sets** covering all 7 categories and violation types\\n2. **Run optimization experiments** using Opik\'s optimizer\\n3. **Track improvements** across prompt iterations\\n4. **Achieve confidence** that Forseti catches what it should\\n\\n---\\n\\n## Try It Yourself\\n\\nNavigate to the **Mockup** tab (`?tab=mockup`) to:\\n\\n- Load existing test contributions\\n- Generate Levenshtein variations\\n- Run batch validation\\n- Export to Opik datasets\\n\\n---\\n\\n**Branch:** `feature/logging_system`\\n**Key files:**\\n\\n- `app/mockup/generator.py` - Contribution generation\\n- `app/mockup/levenshtein.py` - Mutation algorithms\\n- `app/mockup/storage.py` - Redis persistence\\n- `app/mockup/dataset.py` - Opik integration\\n- `app/mockup/batch_view.py` - Streamlit UI\\n\\n_Building trust in AI validation, one mutation at a time._"},{"id":"meeting-ocapistaine-3","metadata":{"permalink":"/fr/blog/meeting-ocapistaine-3","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-24-catch-up-call.mdx","source":"@site/blog/2026-01-24-catch-up-call.mdx","title":"Catch-up Call: Deployment Strategy","description":"Here is the assessment of the catch-up call between @jnxmas and Victor regarding the \xd2 Capistaine project status and immediate priorities.","date":"2026-01-24T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"}],"readingTime":3.61,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meeting-ocapistaine-3","title":"Catch-up Call: Deployment Strategy","authors":["jnxmas"],"tags":["meeting","civictech","ai-ml"]},"unlisted":false,"prevItem":{"title":"First Submission: Building a Charter Validation Testing Framework","permalink":"/fr/blog/first-submission-mockup-system"},"nextItem":{"title":"Technical Strategy: Google Gemini Integration","permalink":"/fr/blog/gemini-workshop-1"}},"content":"Here is the assessment of the catch-up call between @jnxmas and Victor regarding the **\xd2 Capistaine** project status and immediate priorities.\\n\\n## **Summary of the Call**\\n\\n@jnxmas and Victor discussed the immediate roadmap for the **Opik/Commit to Change Hackathon MVP submission** (deadline: ~1 day, 14 hours). Victor has successfully downloaded approximately 4,000 PDFs (including ~3,965 deliberation documents), though he noted some potential duplicates and that the download process was synchronous and could be optimized later. He has committed changes to a development branch but not yet merged them, preferring to use GitHub as a medium to exchange the code while keeping the large PDF dataset local (or shared via a specific sub-directory).\\nThe team agreed on a strategy for the **Hackathon demo deployment**. Instead of using Vercel, which complicates environment variable management for their specific security setup (ngrok, multiple API keys for Opik, Firecrawl, Gemini, etc.), @jnxmas will run the demo from his local machine using a secure, paid ngrok tunnel (`ocapistaine.ngrok.app`). This setup allows the jury to interact with the Streamlit UI (restricted to Ollama for the external demo) while the team can continue testing other models (Gemini) locally. The architecture involves **Locki.io -> Vaettir Orchestration -> Local Machine (Ocapistaine Agent)**.\\n\\n\x3c!-- truncate --\x3e\\n\\n**Key Technical Decisions & Next Steps:**\\n\\n- **OCR & Database:** Victor is moving immediately to OCR processing. While `pdf2ocr` was discussed, they agreed that since most files are text-based PDFs (not scanned images), full image-to-text conversion might be overkill. The priority is text extraction and categorization. @jnxmas plans to implement a NoSQL database (MongoDB) to store OCR content alongside metadata (source, date) to support the RAG system.\\n- **Observability:** @jnxmas is finalizing the integration of Opik within **n8n workflows**. This ensures that if the Ocapistaine application triggers an n8n workflow involving an LLM, both systems report traces to the same Opik observability project, providing a unified view of checking the \\"Charter validity\\" and \\"Hallucination detection.\\"\\n- **Submission Prep:** @jnxmas will focus on writing the article/documentation to justify the technical choices and process for the submission, while Victor attempts to finish the OCR pipeline and potentially start the MongoDB implementation before he becomes unavailable for a few days.\\n\\n---\\n\\n## **Action Plan & Tasks**\\n\\n### **1. Data Engineering & Backend**\\n\\n- **Task:** Finalize PDF Text Extraction & OCR\\n  - **Owner:** @zcbtvag (Victor)\\n  - **Description:** Run the extraction on the downloaded ~4,000 PDFs. Focus on text-based extraction first, only using heavy OCR (image-to-text) if necessary. Commit the code logic (not the files themselves) to the dev branch.\\n  - **Deadline:** **Tonight / ASAP** (Before Victor travels).\\n  - **Success Criteria:** Text extracted from PDFs and ready for database ingestion.\\n- **Task:** Push Dev Branch Changes\\n  - **Owner:** @zcbtvag (Victor)\\n  - **Description:** Push the latest scraper and extraction logic to GitHub so @jnxmas can pull the code.\\n  - **Deadline:** **Tonight**.\\n  - **Success Criteria:** PR raised/Code available on the remote repository.\\n- **Task:** Implement MongoDB for Vector/Content Storage\\n  - **Owner:** @jnxmas [Secondary: Victor if time permits]\\n  - **Description:** Set up a NoSQL database (MongoDB) to store extracted PDF content + metadata (source URL, date, category). This is crucial for the RAG system to function efficiently.\\n  - **Deadline:** **Next 24 Hours**.\\n  - **Success Criteria:** DB instance running and successfully storing OCR output.\\n\\n### **2. Deployment & Hackathon Submission**\\n\\n- **Task:** Configure Local Demo Environment (ngrok)\\n  - **Owner:** @jnxmas\\n  - **Description:** Finalize the secure ngrok tunnel (`ocapistaine.ngrok.app`) pointing to the local Streamlit UI. Ensure the external facing demo is locked to Ollama, while internal dev builds can use Gemini.\\n  - **Deadline:** **Tomorrow Morning**.\\n  - **Success Criteria:** Live URL accessible to external users (jury) without exposing sensitive internal keys.\\n- **Task:** Draft Hackathon Submission Article\\n  - **Owner:** @jnxmas\\n  - **Description:** Write the required project description, work process, and key achievements for the hackathon platform. Focus on the \\"Charter Check\\" agent and Opik integration.\\n  - **Deadline:** **Tomorrow Mid-day**.\\n  - **Success Criteria:** Text ready for copy-paste into the submission form.\\n\\n### **3. Observability (Opik)**\\n\\n- **Task:** Verify Double-Tracing (App + N8N)\\n  - **Owner:** @jnxmas\\n  - **Description:** Confirm that Opik receives traces from both the Python app (Ocapistaine) and the n8n docker container when an LLM is triggered.\\n  - **Deadline:** **Tomorrow**.\\n  - **Success Criteria:** Unified dashboard in Opik showing traces from both sources.\\n\\n---\\n\\n### **Status Dashboard**\\n\\n- **Overall Progress:** \ud83d\udfe1 **Mixed** (Scraping done, OCR/DB pending, Deployment strategy fixed).\\n- **Open High-Priority Tasks:**\\n  1.  Run/Finish OCR on 4k PDFs (@zcbtvag).\\n  2.  Set up MongoDB for data ingestion (@jnschilling).\\n  3.  Finalize \\"Charter Check\\" Agent + Opik Tracing for Demo (@jnschilling).\\n- **Next Milestone:** **Hackathon MVP Submission** (Deadline: ~1 day 14 hours)."},{"id":"gemini-workshop-1","metadata":{"permalink":"/fr/blog/gemini-workshop-1","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-22-gemini-workshop.mdx","source":"@site/blog/2026-01-22-gemini-workshop.mdx","title":"Technical Strategy: Google Gemini Integration","description":"Context: Audierne 2026 Election Platform","date":"2026-01-22T00:00:00.000Z","tags":[{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"}],"readingTime":4.54,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"gemini-workshop-1","title":"Technical Strategy: Google Gemini Integration","authors":["jnxmas"],"tags":["ai-ml","civictech","rag","encode"]},"unlisted":false,"prevItem":{"title":"Catch-up Call: Deployment Strategy","permalink":"/fr/blog/meeting-ocapistaine-3"},"nextItem":{"title":"Team Sync: Gemini Integration and Agent Workflows","permalink":"/fr/blog/meeting-ocapistaine-2"}},"content":"**Context:** Audierne 2026 Election Platform\\n\\nThis document outlines how we will leverage the Google Gemini ecosystem (AI Studio, Flash models, and Agentic workflows) to accelerate the development of the Locki project. By utilizing these tools, we aim to bridge the gap between human ideation and automated N8N workflows, specifically for the `Commit to Change` hackathon and the subsequent election period.\\n\\n\x3c!-- truncate --\x3e\\n\\n## 1. The `Human-to-Agent` Workflow Bridge\\n\\nA core strategy for our development is enabling our automated GitHub agents to `learn` from human-validated workflows. We will use Google AI Studio as the prototyping environment to define logic that is subsequently exported to our N8N instance.\\n\\n<iframe\\n  width=\\"100%\\"\\n  style={{ \\"aspect-ratio\\": \\"16 / 9\\" }}\\n  src=\\"https://www.encodeclub.com/programmes/comet-resolution-v2-hackathon/events/mastering-gemini-3-building-next-gen-ai-agents-in-google-ai-studio\\"\\n  title=\\"OPIK workshop 2\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\"\\n  referrerpolicy=\\"strict-origin-when-cross-origin\\"\\n  allowfullscreen\\n></iframe>\\n\\n- **Prototyping in AI Studio:** Team members (jnxmas, etc.) can solve complex data extraction problems within the AI Studio interface (e.g., `Analyze this specific municipal PDF and extract the 2024 housing budget`).\\n- **The `Get Code` Feature:** Once the model successfully completes a task or fixes a bug, we utilize the **Get Code** feature. This provides the exact Python or cURL code required to replicate the action.\\n- **N8N Integration:** Instead of writing scrapers from scratch, we export this verified logic and integrate it directly into N8N Python nodes. This allows our automated agents to search the Audierne environment and context with logic already proven to work.\\n- **Workflow Orchestration:** We can prompt the model to stitch together disparate services (e.g., Search + Summarize + Store). The model designs the prompts and orchestrates the data flow, which we then convert into Dockerized N8N workflow nodes.\\n\\n## 2. Advanced Scraping & Contextual Search (Firecrawl Optimization)\\n\\nTo effectively crawl the ~150 links and municipal portals of Audierne, we will apply Gemini\'s `Anti-Gravity` and DOM-aware capabilities to our Firecrawl pipeline.\\n\\n- **DOM & Visual Navigation:** Unlike standard `curl` requests which may be blocked, Gemini-based logic can navigate the Document Object Model (DOM) and use visual cues (screenshots) to handle cookies, pop-ups, and complex navigation menus found on municipal sites.\\n- **Autonomous Planning:** We can equip our agents to formulate multi-step plans (Search -> Filter by `Audierne` -> Check Date -> Download PDF).\\n- **Code Repair:** Using the `Live` and `Annotate` features, developers can debug scraper errors in real-time. The model can identify logical breaks in the scraping code and suggest fixes while maintaining context.\\n\\n## 3. Multimodal Data Processing for Municipal Archives\\n\\nProcessing the dataset of 4,000+ PDFs and various multimedia links requires a high-volume, low-cost solution.\\n\\n- **Gemini Flash Models (1.5 / 3):** We will standardize on `Flash` models for the majority of our RAG pipeline. These models offer high speed and vast token windows at a fraction of the cost, making them sustainable for our project budget.\\n- **Video & Audio Analysis:** We can upload long-form video/audio recordings of Audierne municipal council meetings directly. Gemini can generate timestamps, summaries, and extract specific topic discussions (e.g., `Culture budget debates`) without requiring a separate, expensive Speech-to-Text pipeline.\\n- **Gemma 3 (Local/Open):** For local testing and zero-cost prototyping of OCR pipelines, we can utilize the open Gemma 3 model before deploying to the cloud.\\n\\n## 4. Accuracy & Sandbox Code Execution\\n\\nTo adhere to our goal of a `neutral, impartial RAG-based chatbot,` we must minimize hallucinations, especially regarding budget figures.\\n\\n- **Sandboxed Execution:** We will utilize Gemini\'s `Code Execution` tool. Instead of asking the LLM to _predict_ the sum of a budget list, we ask it to _write and run Python code_ to calculate it.\\n- **Data Visualization:** This feature allows us to ask the model to plot data (e.g., `Create a graph comparing the budget allocation of the 4 lists`) which can be displayed on the frontend.\\n- **Logic Verification:** This forces the model to use computational logic, ensuring that the comparisons provided to Audierne citizens are mathematically accurate.\\n\\n## 5. Frontend Acceleration & Multilingual Support\\n\\n- **The `Build` Feature:** For the upcoming Hackathon, we can use the `Build` feature to describe user interfaces (e.g., `Create a citizen contribution intake form with camera access`) and instantly generate deployed React/TypeScript code. This significantly reduces boilerplate work.\\n- **Gemini Live (Bilingual):** To support our EN/FR requirement, we leverage the model\'s native multilingual capabilities. It can seamlessly switch between French and English, ensuring the chatbot interacts fluently with all demographics in Audierne.\\n\\n---\\n\\n**Project Coordinator Status Update**\\n\\n- **Overall Progress:** \ud83d\udfe1 Firecrawl (Optimization via DOM-aware logic needed) \ud83d\udfe2 Docs (Gemini Strategy Added) \ud83d\udfe1 RAG (Integration of Flash models pending)\\n- **Open High-Priority Tasks:**\\n  - **Task:** Prototype PDF extraction in AI Studio & export Python code.\\n    - **Owner:** Victor / Meher\\n    - **Description:** Use AI Studio to solve a specific Audierne PDF parsing challenge, use `Get Code,` and integrate the Python script into a custom N8N node.\\n    - **Deadline:** Next call.\\n  - **Task:** Secure API keys for Gemini Flash.\\n    - **Owner:** jnxmas\\n    - **Description:** Provision keys to test cost-effective OCR and massive token processing for the 4k PDF dataset.\\n    - **Deadline:** ASAP.\\n  - **Task:** Refine Firecrawl Agents with DOM Logic.\\n    - **Owner:** Meher / jnxmas\\n    - **Description:** Use `Anti-Gravity` style logic to handle complex municipal site navigation (cookies/popups) where standard scraping fails.\\n    - **Deadline:** Hackathon Start.\\n  - **Task:** Hackathon Frontend Prototype.\\n    - **Owner:** Open (Frontend Contributor)\\n    - **Description:** Use Gemini `Build` feature to generate the base React code for the citizen contribution portal.\\n    - **Deadline:** Mid-February.\\n\\n- **Next Milestone:** Hackathon Prototype Delivery (~Mid-February)"},{"id":"meeting-ocapistaine-2","metadata":{"permalink":"/fr/blog/meeting-ocapistaine-2","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-22-team-sync.mdx","source":"@site/blog/2026-01-22-team-sync.mdx","title":"Team Sync: Gemini Integration and Agent Workflows","description":"Strategy Update: Leveraging Gemini & Agent Workflows","date":"2026-01-22T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"}],"readingTime":3.33,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meeting-ocapistaine-2","title":"Team Sync: Gemini Integration and Agent Workflows","authors":["jnxmas"],"tags":["meeting","civictech","ai-ml"]},"unlisted":false,"prevItem":{"title":"Technical Strategy: Google Gemini Integration","permalink":"/fr/blog/gemini-workshop-1"},"nextItem":{"title":"Let us choose the stack","permalink":"/fr/blog/meeting-ocapistaine-1"}},"content":"## Strategy Update: Leveraging Gemini & Agent Workflows\\n\\nThis document summarizes key insights from the recent team sync following Jean-No\xebl\'s attendance at the Google Gemini workshop. The focus is on accelerating the **Locki / \xd2 Capistaine** project by transitioning from manual human analysis to automated agent workflows.\\n\\n\x3c!-- truncate --\x3e\\n\\n### The Gemini Opportunity\\n\\njnxmas reported that despite initial skepticism, the Gemini workshop revealed significant opportunities for the project, particularly regarding scraping and rapid prototyping.\\n\\n- **Google AI Studio Capabilities:** The team discussed the power of Google AI Studio (specifically Gemini 1.5 Pro/Flash). It allows for multimodal input\u2014users can upload images or video recordings of a screen process, and the AI can generate the corresponding code (Python) to replicate that workflow.\\n- **Anti-Gravity & DOM Awareness:** The team is considering testing \\"Anti-Gravity\\" (potentially as a VS Code alternative or extension) to utilize Gemini\'s DOM-aware capabilities. This could allow for smarter scraping of the ~150 target links compared to the current \\"brute force\\" Firecrawl approach.\\n\\n### From Human Workflow to AI Agent\\n\\nA core strategic pivot discussed is the methodology for building the project\'s autonomous agents (specifically the **Ocapistaine** GitHub user/agent).\\n**The Proposed Workflow:**\\n\\n1. **Human Prototype:** A team member manually processes a citizen contribution using Gemini Studio.\\n   - _Example Action:_ Take a contribution about \\"rainwater taxes,\\" validate it against the charter, search Google for similar implementations in France, and check the `audierne2026` docs for local context.\\n2. **Code Generation:** Ask Gemini to \\"make a script of this search and interpretation process.\\"\\n3. **Agent Implementation:** This script is converted into a workflow stored in the repository.\\n4. **Execution via N8N:** The \\"Ocapistaine\\" agent (which has specific GitHub credentials) triggers these workflows. It acts as the owner of the process, running searches, documenting findings in the repo, and replying to issues using the context generated.\\n\\n### Integration Architecture: GitHub & N8N\\n\\nThe infrastructure is being updated to support this \\"Agent-driven\\" model:\\n\\n- **Cross-Repo Context:** Documentation from `docs.locki.io` is now set up as a submodule, allowing the AI to access context across different repositories (e.g., `vaettir` and `ocapistaine`) simultaneously.\\n- **Workflow Orchestration:** Python workflows within the `ocapistaine` repository are designed to call N8N workflows.\\n- **Automated Workflow Creation:** Experiments suggest that tools like Claude or Gemini can be used to write the JSON files required for N8N workflows, essentially allowing the AI to build its own integration pipelines using the project\'s existing API keys (Forseti/Ocapistaine).\\n\\n### Current Progress & Blockers\\n\\n- **Scraping (Firecrawl):** Victor has successfully scraped municipal considerations (PDFs/data), but there are file management issues. The files need to be renamed and committed to the `dev` branch properly to avoid needing complex cleanup later.\\n- **Opik Integration:** The integration is live. Jean-No\xebl demonstrated a trace where the system successfully checked the \\"contribution charter\\" and returned a confidence score and category (e.g., \\"Youth\\") using local LLMs (Ollama/Mistral) to save costs during dev.\\n- **Cost Management:** The team plans to use \\"Flash\\" models or free tiers (Gemini/Gemma) for the heavy lifting of RAG and video/audio analysis to keep the project sustainable.\\n\\n---\\n\\n### Project Coordinator Dashboard\\n\\n**Overall Progress:** \ud83d\udfe1 **Processing** (Scraping logic is working but needs cleanup; Agent workflow defined but not implemented).\\n**Open High-Priority Tasks:**\\n\\n- **Task:** Clean and Commit Scraped Data\\n  - **Owner:** @zcbtvag (Victor)\\n  - **Description:** Rename scraped municipal files/folders and commit to the `dev` branch so the team can access the dataset.\\n  - **Deadline:** ASAP\\n  - **Success Criteria:** Files visible in `dev` branch without directory errors.\\n- **Task:** Prototype \\"Human-to-Agent\\" Workflow\\n  - **Owner:** @jnxmas / @GurmeherSingh\\n  - **Description:** Record a manual analysis session in Gemini Studio, generate the Python script, and convert it into a GitHub Action/N8N trigger.\\n  - **Deadline:** Next Sync\\n  - **Success Criteria:** One functional automated workflow generated from a video/image input.\\n- **Task:** Test Anti-Gravity / Gemini DOM Scanning\\n  - **Owner:** @jnxmas\\n  - **Description:** Evaluate if Gemini\'s DOM-aware browsing is more efficient than the current Firecrawl setup for the 150 links.\\n  - **Deadline:** End of Week\\n  - **Success Criteria:** Decision on whether to switch scraping tools.\\n    **Next Milestone:**\\n- **Mid-February:** Hackathon Prototype Delivery (Functional RAG chatbot with automated contribution processing)."},{"id":"meeting-ocapistaine-1","metadata":{"permalink":"/fr/blog/meeting-ocapistaine-1","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-18-team-meeting.mdx","source":"@site/blog/2026-01-18-team-meeting.mdx","title":"Let us choose the stack","description":"Project Context Update (Mid-to-Late January 2026)","date":"2026-01-18T00:00:00.000Z","tags":[{"inline":false,"label":"Sprints","permalink":"/fr/blog/tags/sprints","description":"Articles on sprints and current status updates"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Locki Labs","permalink":"/fr/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"},{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"}],"readingTime":21.11,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meeting-ocapistaine-1","title":"Let us choose the stack","authors":["jnxmas"],"tags":["sprints","civictech","rag","locki","meeting","encode"]},"unlisted":false,"prevItem":{"title":"Team Sync: Gemini Integration and Agent Workflows","permalink":"/fr/blog/meeting-ocapistaine-2"},"nextItem":{"title":"Lets us code","permalink":"/fr/blog/meher-jnxmas-letscode"}},"content":"## Project Context Update (Mid-to-Late January 2026)\\n\\n**Project**: Locki / \xd2 Capistaine (audierne2026) - AI-powered civic transparency & participatory democracy platform for Audierne 2026 local elections (France)\\n**Core Mission**: Build a neutral, source-based RAG chatbot to answer citizen questions about 4 municipal programs, automate contribution validation against charter rules, crawl/process municipal data (150+ links, 4,000+ PDFs), and showcase Opik integration for the \\"Commit to Change\\" Hackathon.\\n**Critical Timeline**:\\n\\n- Contributions deadline: ~January 31, 2026\\n- Hackathon prototype delivery: ~mid-February 2026 (4-week sprint)\\n- Election period: ~March 15-22, 2026\\n\\n\x3c!-- truncate --\x3e\\n\\n## Team Status & Availability\\n\\n**Active Members**:\\n\\n- **[jnxmas] aka Johnny Christmass (@jnxmas)**: Project lead, architecture, N8N deployment, Firecrawl testing, documentation, political outreach\\n- **Meher/Gurmukher/Guru (@GurmeherSingh)**: ML Engineer, RAG agent + Opik integration (recently arrived US East Coast, jet-lagged)\\n- **Victor (@zcbtvag)**: Backend Python, Firecrawl pipeline (intensive work Mon-Wed, unavailable Thu-Sun for France travel, returns following week)\\n\\n  **Team Experience Alignment**:\\n\\n- \u2705 **Shared expertise**: Streamlit, VectorStore, Python, Firecrawl, Gemini, Opik\\n- \u2705 **Guru\'s strengths**: NOMIC embeddings (Sentence Transformer), Azure, Ollama\\n- \u274c **Learning curve**: N8N (new for Guru + Victor)\\n\\n---\\n\\n## Political & Community Engagement Progress\\n\\n**Achievements**:\\n\\n- **Outgoing mayor**: Positive signal at New Year\'s event - mentioned \\"new paradigm in politics\\"\\n- **Email follow-up**: Mayor acknowledged project email (10+ days prior), interested in discussing Audierne2026\\n- **Electoral lists**: 3 of 4 lists contacted, very positive responses\\n- **Remaining**: 1 list still to contact (before Jan 31)\\n  **Current Challenge**:\\n- **Low citizen engagement**: Contributions/discussions system seeing minimal activity (\\"it\'s a bit too much right now\\")\\n- **Content workflow**: Issues validated \u2192 transferred to discussions \u2192 posted on website after community review\\n- **Validation stages**: Charter compliance + Contextualization (innovative agent finding solutions)\\n  **Strategic Shift**: Team needs to move from outreach to coding and delivery.\\n\\n---\\n\\n## Technical Architecture - Stack Decisions Finalized\\n\\n### Layer Structure (Bottom-Up ETL Pattern)\\n\\n**1. External Services Layer**\\n\\n- **Firecrawl API**: Primary web scraping/crawling service\\n- **Status**: Victor progressing, PR open, completion target Wednesday (before travel)\\n- **Blocker**: Pagination settings need tuning (tested with `max_pages=10`, returned only 1 page)\\n- **Priority source**: D\xe9lib\xe9rations du conseil municipal (municipal council deliberations)\\n  **2. Data Access Layer**\\n- **Vector Store**: Confirmed standard VectorStore approach (all team members familiar)\\n- **Embeddings Strategy**:\\n  - **Primary**: NOMIC model (Sentence Transformer) - Guru has experience\\n  - **Backup/Failsafe**: Mistral Studio - French language optimization + potential local sponsorship\\n- **Crawl Tracking Database**: SQL Lite/SQL Model chosen\\n  - Metadata: Crawl status, RAG inclusion, content category\\n  - SQL Model benefits: Type safety (Python \u2192 SQL columns), FastAPI/Pydantic compatibility, PostgreSQL support\\n  - Owner: [jnxmas] will build during Victor\'s absence\\n    **3. Business Logic Layer**\\n    **Agent 1: Charter Validation Agent** (PRIORITY)\\n- **Purpose**: Auto-validate citizen contributions against charter rules\\n- **Checks**: Respectful language, no personal naming, constructive content\\n- **Functionality**: Binary (green/red) conformance + auto-correct miscategorized submissions (7 categories)\\n- **Tech Stack**: Gemini (primary), Ollama (testing), Opik evaluation/tracing\\n- **Workflow**: Reads `audierne2026` repo issues \u2192 labels/updates in `ocapistaine` repo\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Status**: Not started (blocked by Opik access + N8N deployment)\\n  **Agent 2: RAG Agent / Citizen Q&A Chatbot**\\n- **Purpose**: Answer citizen questions with neutral, contextual responses, cross-reference municipal programs\\n- **Requirements**: No hallucinations (Opik guardrails), source attribution, French language\\n- **Approach**: Start with available data, iterate as crawling progresses\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Status**: Starting development, update expected in 1-2 days\\n- **Dependencies**: VectorStore populated, Charter agent outputs (optional)\\n  **Agent 3: Search Agent** (CONDITIONAL)\\n- **Decision**: Pending RAG completeness assessment\\n- **Logic**: If RAG sufficient \u2192 search agent unnecessary; if RAG insufficient \u2192 search agent as fallback\\n- **Status**: On hold pending RAG testing\\n  **Chat Service** (Already Working)\\n- **Functionality**: Multi-turn conversations with thread management (UUID per user)\\n- **Providers**: OpenAI, Ollama (Mistral, DeepSeek tested locally), Perplexity, Gemini\\n- **Features**: System message config, prompt engineering, thread history persistence, strategy selection (Charter mode, Q&A mode, etc.)\\n- **Opik Integration**: Full tracing via `workflow_chat` class\\n  **Document Service** (To Be Defined)\\n- **Proposed Purpose**:\\n  - Query documentation/source information\\n  - Scheduled re-crawling (detect new docs since last crawl)\\n  - Document categorization + metadata tagging\\n  - Change detection (compare current vs. new crawls, decide RAG updates)\\n- **Open Question**: How does this differ from Chat Service? (Clarified: Document = search/crawl management; Chat = conversational interface)\\n- **Status**: Requirements to be defined collaboratively\\n  **4. Application Layer**\\n- **Streamlit**: Primary presentation interface\\n- **FastAPI**: Routing layer\\n- **Debug Scripts**: One-click full stack launch (UV cone + Streamlit app automation)\\n- **Hot Reload**: Code modifications work without restart\\n- **Future**: Redis integration for scheduler + task memory persistence\\n  **5. External Orchestration Layer**\\n- **N8N**: Self-hosted Docker deployment on Contabo server (viety.loki.io)\\n- **Status**: ~2 hours from completion (as of last meeting)\\n- **Workflows**:\\n  - Pull issues from `audierne2026` GitHub repo\\n  - Trigger charter validation agent\\n  - Push validated/labeled issues back to repo\\n  - Modify Jekyll website content\\n  - Provide API endpoint for agent testing\\n- **Multi-project approach**: Separate workflows per project on shared dashboard\\n- **Future**: Pull data from Opik Cloud back into app (feedback loop via N8N API)\\n  **Supporting Infrastructure**:\\n- **APScheduler (cron-based)**: Time-based tasks (daily/weekly crawl updates, GitHub monitoring, Charter violation checks)\\n- **Opik**: Evaluation, tracing, prompt management (future), hallucination detection, metrics/dashboards\\n- **Poetry**: Dependency management (NOT pip) for library compatibility\\n\\n---\\n\\n## Opik Integration Strategy - MAXIMIZE USAGE\\n\\n**Team Consensus**: \\"Maximize Opik usage at every opportunity\\" - it\'s the hackathon focus.\\n**Dashboard Setup Decisions**:\\n\\n- **Environment**: Start with Opik Dev, migrate to Prod when ready\\n- **Dashboard Approach**: Single unified dashboard to monitor all agents (avoid complexity of separate dashboards per agent)\\n- **API Keys**: Likely one project with multiple keys for per-developer usage tracking\\n- **Access**:\\n  - [jnxmas] has access to `ocapistaine-dev` dashboard\\n  - Need to grant Guru and Victor access\\n  - Guru has existing Opik account (needs to share user ID/Discord username)\\n  - Victor\'s Opik status: Not confirmed\\n    **Integration Points**:\\n- Charter validation agent: Trace every decision, verify adherence to charter rules\\n- RAG agent: Hallucination prevention, prompt evaluation, guardrails\\n- N8N workflows: Plug into Opik for agent activity reporting\\n- Chat service: Already using Opik tracing via `workflow_chat` class\\n- Prompt management: Start hardcoded, potentially migrate to Opik prompt library later\\n- Evaluation judge: Verify LLM adherence to prompts\\n  **Team Familiarity**:\\n- Platform exploration phase: Team has not yet fully explored Opik capabilities\\n- Reference materials: Git examples available for implementation patterns\\n- Action needed: All team members familiarize with Opik features (dashboards, prompt library, evaluation)\\n\\n---\\n\\n## LLM Provider Strategy - Multi-Provider Approach\\n\\n**Confirmed Providers**:\\n\\n1. **Gemini**: Sponsored/free option (primary for Charter agent)\\n2. **Ollama**: Completely free (local testing) - Mistral, DeepSeek tested\\n3. **Mistral**: French language optimization + potential sponsorship target (French govt/local alignment, political risk mitigation)\\n4. **OpenAI**: Already working in Chat service\\n5. **Perplexity**: Available option\\n   **Strategic Rationale**:\\n\\n- **French language**: Critical for citizen-facing content - Mistral chosen for optimization\\n- **Political optics**: Using French LLM provider avoids criticism of not supporting French solutions\\n- **Cost management**: Prioritize free/sponsored options (Gemini, Ollama)\\n- **Failsafe approach**: NOMIC primary + Mistral backup = \\"two tracks maximum\\" ([jnxmas]\'s preference given 4-week timeline)\\n\\n---\\n\\n## Development Workflow & Version Control\\n\\n**Git Strategy**:\\n\\n- **Protected branch**: `dev` branch - no direct pushes\\n- **Feature branches**: Mandatory for all work\\n- **PR workflow**: Victor successfully resolved upstream branch issue, has open PR ready for review\\n- **Review process**: [jnxmas] reviews and merges into `dev`\\n  **Dependency Management**:\\n- **Poetry ONLY**: NOT pip - ensures library compatibility\\n- **Command**: `poetry add `\\n- **Action**: Victor + Guru ensure local environments use Poetry\\n  **Documentation**:\\n- **Docusaurus blog**: All meeting summaries posted to `blog/` for async collaboration + AI context (Cursor/Claude code context)\\n- **GitHub tasks**: Self-assignment encouraged, commenting for async feedback\\n- **Task board**: 3 tasks \\"In Progress\\" with all three team members assigned\\n\\n---\\n\\n## Critical Technical Decisions Summary\\n\\n| Component             | Decision                                        | Owner             | Status                 |\\n| --------------------- | ----------------------------------------------- | ----------------- | ---------------------- |\\n| **Vector DB**         | VectorStore (standard)                          | Team              | \u2705 Confirmed           |\\n| **Embeddings**        | NOMIC primary, Mistral backup                   | Guru              | \u2705 Confirmed           |\\n| **Orchestration**     | N8N (Docker, viety.loki.io)                     | [jnxmas]          | \ud83d\udfe1 ~2h from deployment |\\n| **Crawl Tracking**    | SQL Lite + SQL Model                            | [jnxmas]          | \ud83d\udd34 Design phase        |\\n| **LLM Providers**     | Gemini, Ollama, Mistral, OpenAI, Perplexity     | Team              | \u2705 Multi-provider      |\\n| **Opik Setup**        | Single dashboard, Dev \u2192 Prod, multiple API keys | [jnxmas]          | \ud83d\udfe1 Access pending      |\\n| **OCR Libraries**     | pdf2ocr, Tabula, pypdf (test all 3)             | Victor \u2192 [jnxmas] | \ud83d\udd34 Blocked on crawling |\\n| **Prompt Management** | Hardcoded \u2192 Opik library (future)               | Guru              | \ud83d\udd34 Not started         |\\n| **Search Agent**      | Conditional on RAG completeness                 | TBD               | \ud83d\udfe1 On hold             |\\n\\n---\\n\\n## Firecrawl Pipeline Progress (Victor\'s Focus)\\n\\n**Completed**:\\n\\n- \u2705 Debugged and fixed scraper component\\n- \u2705 Fixed crawler functionality (operational after \\"small but critical\\" config issues)\\n- \u2705 Open PR ready for review\\n- \u2705 Resolved upstream branch issue\\n  **Current Issues**:\\n- \u26a0\ufe0f Pagination settings need adjustment (tested `max_pages=10`, returned only 1 page)\\n- \u26a0\ufe0f Full document retrieval tuning required\\n  **Victor\'s Timeline**:\\n- **Mon-Wed (this week)**: Intensive work, complete Firecrawl pipeline\\n- **Thu-Sun**: Unavailable (travel to France - pre-planned holiday)\\n- **Following week**: Returns and continues contributions\\n- **Goal**: Finish Firecrawl work before Wednesday departure\\n  **Next Steps**:\\n\\n1. Victor finalizes additional commits to feature branch\\n2. Victor signals when PR ready for final review\\n3. [jnxmas] reviews and merges into `dev`\\n4. [jnxmas] tests merged pipeline on additional sources during Victor\'s absence\\n5. Once crawling complete \u2192 Apply OCR to PDFs (pdf2ocr, Tabula, pypdf testing)\\n\\n---\\n\\n## OCR Pipeline Strategy (Post-Firecrawl)\\n\\n**Target Documents**: Scanned PDFs in municipal archives (~4,000+ documents)\\n**Libraries to Test**:\\n\\n1. pdf2ocr\\n2. Tabula\\n3. pypdf\\n   **Approach**: Test all 3, compare outputs for quality\\n   **Owner**: Victor (primary), [jnxmas] (testing during Victor\'s absence)\\n   **Status**: Blocked on Firecrawl crawling completion\\n\\n---\\n\\n## Project Background & Context\\n\\n**Locki Project Evolution**:\\n\\n- Origin: Started from hackathon 2 years ago\\n- Built agents on top of Locki stack\\n- Participated in cohorts to improve functionality\\n- Previous projects:\\n  - 3D objects on-chain (paused - too early/complex, slow blockchain)\\n  - Horse racing betting strategy (15 years expert knowledge \u2192 code/data layer, not yet commercialized)\\n  - Multiverse Six / XRP experience (3D NFTs)\\n    **[jnxmas]\'s Work**:\\n- Freelancing: Apps, websites, e-commerce development\\n- Computer teacher for small children (Thursdays, 2 hours)\\n- Locki is primary passion project (\\"what makes me wake up in the morning\\")\\n- Successfully built Locki mobile app prototype\\n  **Dev Environment**:\\n- VS Code with debug scripts for one-click launch\\n- Team using Cursor IDE may need to adapt scripts\\n- Victor considering switch to VS Code for easier workflow\\n\\n---\\n\\n## Open Questions & Decisions Needed\\n\\n### For Guru (Flagged for Response):\\n\\n1. \u2705 **Vector store preference**: VectorStore confirmed, NOMIC embeddings confirmed\\n2. \u23f3 **Opik user ID/Discord username**: Needed for dashboard access grant\\n3. \u23f3 **Stack alignment review**: Read architecture blog post in repo, suggest improvements\\n4. \u23f3 **Charter agent design**: Begin development, provide update in 1-2 days\\n\\n### For Victor:\\n\\n1. \u23f3 **Opik account status**: Confirm if account exists or needs creation\\n2. \u23f3 **Firecrawl PR readiness**: Signal when ready for final review\\n3. \u23f3 **Poetry environment**: Verify local setup uses Poetry (not pip)\\n\\n### For [jnxmas]:\\n\\n1. \u23f3 **N8N deployment**: Complete final ~2 hours of setup\\n2. \u23f3 **Opik dashboard access**: Invite Guru + Victor (need usernames)\\n3. \u23f3 **Document Service requirements**: Define scope and distinction from Chat Service\\n4. \u23f3 **Crawl scheduling**: Decide frequency (daily vs. weekly) for production\\n\\n### For Team Discussion:\\n\\n1. \u23f3 **Search Agent decision**: Revisit after RAG testing complete\\n2. \u23f3 **Citizen engagement UX**: Consider simplifying contribution system if low engagement persists\\n3. \u23f3 **Effort attribution**: Finalize \\"all ores tracking template\\" for fair team contribution recognition\\n4. \u23f3 **Prompt management migration**: Timeline for moving hardcoded prompts to Opik library\\n\\n---\\n\\n## Comprehensive Task List\\n\\n### URGENT (Next 48 Hours)\\n\\n**Task 1: Complete N8N Deployment & GitHub Integration**\\n\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Finish final ~2 hours of N8N Docker deployment on viety.loki.io, configure workflows to pull issues from `audierne2026` repo, trigger charter validation agent, push validated/labeled issues back, provide API endpoint for testing\\n- **Deadline**: Within 48 hours (before Guru needs to test agent)\\n- **Dependencies**: None (infrastructure task)\\n- **Success Criteria**: N8N accessible at viety.loki.io, test workflow successfully pulls/pushes GitHub issue, API endpoint documented\\n  **Task 2: Set Up Opik Dev Environment & Team Access**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Create/configure `Ocapistaine Dev` Opik project, generate separate API keys for [jnxmas]/Guru/Victor, grant dashboard access to all team members, document key assignment and usage tracking approach\\n- **Deadline**: Before Guru starts agent development (next 24 hours)\\n- **Dependencies**: Guru\'s Opik user ID/Discord username, Victor\'s Opik account confirmation\\n- **Success Criteria**: All team members can access dashboard, separate keys functional, usage trackable per developer\\n  **Task 3: Complete Firecrawl Pipeline Implementation**\\n- **Owner**: Victor (@zcbtvag)\\n- **Description**: Finalize additional commits to Firecrawl feature branch, fix pagination settings to ensure full document retrieval, test with multiple sources, signal when PR ready for final review\\n- **Deadline**: Wednesday (before France travel)\\n- **Dependencies**: Firecrawl API keys, crawler pagination tuning\\n- **Success Criteria**: PR merged without conflicts, Firecrawl successfully crawls full test dataset, documented in code\\n  **Task 4: Build Charter Validation Agent - Core Logic**\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: Develop charter validation agent that reads citizen contribution issues from `audierne2026` repo, validates against charter rules (respectful, no naming, constructive), auto-corrects category misclassifications (7 categories), returns binary validation + corrected category, integrates Opik evaluation at every decision point\\n- **Deadline**: Update in 1-2 days, full prototype ASAP (foundation for other workflows)\\n- **Dependencies**: Access to Opik dashboard, `audierne2026` repo read access, N8N API endpoint\\n- **Success Criteria**: Agent correctly validates 95%+ test cases, Opik traces show decision transparency, category corrections work\\n\\n### HIGH PRIORITY (This Week)\\n\\n**Task 5: Build RAG Agent with Opik Integration**\\n\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: Develop core RAG agent for citizen Q&A, integrate NOMIC embeddings (primary) + Mistral (backup), implement Opik for evaluation/tracing/hallucination prevention, generate neutral contextual responses with source attribution, cross-reference municipal program data\\n- **Deadline**: Update in 1-2 days, working prototype by end of week (Jan 30-31)\\n- **Dependencies**: VectorStore setup, crawled data (start with available), Opik access\\n- **Success Criteria**: Functional RAG agent with Opik tracing active, no hallucinations in test cases, proper French language responses\\n  **Task 6: Firecrawl PR Review & Merge**\\n- **Owner**: Victor (@zcbtvag) + [jnxmas] (review)\\n- **Description**: Victor signals PR ready, [jnxmas] reviews and merges into `dev` branch, test merged pipeline functionality\\n- **Deadline**: End of week (allow Victor time for improvements)\\n- **Dependencies**: Task 3 completion\\n- **Success Criteria**: PR merged, Firecrawl pipeline functional on test sources\\n  **Task 7: Test Firecrawl on Additional Sources & Build Crawl Tracking DB**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Intensively test Victor\'s Firecrawl code on ocapistaine repo PDFs/websites and other sources beyond current scope, begin SQL Lite/SQL Model database for tracking crawled content with metadata (crawl status, RAG inclusion, content category)\\n- **Deadline**: Sunday evening (status update)\\n- **Dependencies**: Task 6 completion (merged Firecrawl code)\\n- **Success Criteria**: Multiple sources tested successfully, tracking database prototype with crawl status and categorization functional\\n  **Task 8: Explore Opik Platform Features**\\n- **Owner**: All team members\\n- **Description**: Familiarize with Opik capabilities, dashboards, prompt library, evaluation features, tracing, metrics, experiment tracking\\n- **Deadline**: Next 2-3 days (parallel with development)\\n- **Dependencies**: Opik access granted (Task 2)\\n- **Success Criteria**: Team comfortable with platform, ready to maximize hackathon showcase, documented learnings\\n  **Task 9: Poetry Dependency Management Setup**\\n- **Owner**: Victor (@zcbtvag) + Guru (@GurmeherSingh)\\n- **Description**: Ensure local dev environments use Poetry (not pip) for all library additions, verify compatible with current workflows\\n- **Deadline**: Before next library additions\\n- **Dependencies**: Poetry installed locally\\n- **Success Criteria**: No pip-related dependency conflicts, `pyproject.toml` up to date, team using `poetry add ` exclusively\\n\\n### MEDIUM PRIORITY (Next Week)\\n\\n**Task 10: Test OCR Libraries on Scanned PDFs**\\n\\n- **Owner**: Victor (@zcbtvag) \u2192 [jnxmas] (if Victor unavailable)\\n- **Description**: Test pdf2ocr, Tabula, pypdf on sample scanned PDFs from municipal archives, compare outputs for quality, select best library/combination for production\\n- **Deadline**: Immediately after crawling complete (or during Victor\'s absence)\\n- **Dependencies**: Task 3/6 completion (crawling functional)\\n- **Success Criteria**: 3 libraries tested, quality comparison documented, production OCR library selected\\n  **Task 11: Architecture Documentation Review**\\n- **Owner**: Guru (@GurmeherSingh) + Victor (@zcbtvag)\\n- **Description**: Read architecture blog post [jnxmas] created (in `ocapistaine` repo), suggest additions specifically around NOMIC embedding implementation details, RAG service integration points, any conflicts/improvements from experience\\n- **Deadline**: Next 2-3 days (before architecture freeze)\\n- **Dependencies**: Access to blog in repo\\n- **Success Criteria**: Comments/suggestions posted, team aligned on architecture\\n  **Task 12: Define Document Service Requirements**\\n- **Owner**: [jnxmas] + Guru + Victor\\n- **Description**: Collaboratively define Document Service scope: query documentation/source info, scheduled re-crawling (detect new docs), document categorization + metadata tagging, change detection logic (compare current vs. new crawls), decide if separate DB needed, clarify distinction from Chat Service\\n- **Deadline**: Next sync meeting\\n- **Dependencies**: Vector store decision (confirmed), crawl tracking DB design (Task 7)\\n- **Success Criteria**: Document Service requirements documented, team aligned, ready for implementation\\n  **Task 13: Finish All Ores Tracking Template**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Complete effort attribution tracking system for fair team contribution recognition, share with team for feedback\\n- **Deadline**: ASAP (ongoing discussion on Discord)\\n- **Dependencies**: None\\n- **Success Criteria**: Template finalized, shared on Discord, team feedback incorporated\\n  **Task 14: Follow Up with Remaining Electoral List**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Contact 4th electoral list for outreach, gauge interest in Audierne2026 project\\n- **Deadline**: Before January 31 (contributions deadline)\\n- **Dependencies**: None\\n- **Success Criteria**: All 4 lists contacted, responses documented\\n\\n### FUTURE / CONDITIONAL\\n\\n**Task 15: Search Agent Design & Implementation** (CONDITIONAL)\\n\\n- **Owner**: TBD (likely Guru)\\n- **Description**: IF RAG agent proves insufficient during testing, design and implement Search Agent as fallback for citizen queries\\n- **Deadline**: Week 2 of sprint (after RAG testing complete)\\n- **Dependencies**: Task 5 completion (RAG agent functional), RAG sufficiency evaluation\\n- **Success Criteria**: Decision documented (Search Agent needed: yes/no), if yes \u2192 design document with Opik integration plan\\n  **Task 16: Migrate Prompts to Opik Library** (FUTURE)\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: After initial hardcoded prompts working, migrate to Opik prompt library for centralized management, versioning, experimentation\\n- **Deadline**: Post-hackathon or if time permits in sprint\\n- **Dependencies**: Opik platform familiarity (Task 8), working agents with hardcoded prompts\\n- **Success Criteria**: Prompts managed in Opik, agents use library-based prompts, versioning functional\\n  **Task 17: Redis Integration for Scheduler + Task Memory**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Integrate Redis for APScheduler persistence and task memory across restarts\\n- **Deadline**: Post-initial prototype (when scaling/production readiness needed)\\n- **Dependencies**: Working scheduler tasks (crawl updates, GitHub monitoring)\\n- **Success Criteria**: Scheduler tasks persist across app restarts, task memory functional\\n  **Task 18: Citizen Q&A RAG Agent - Planning** (After Charter Agent)\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: After charter agent working, design second RAG agent iteration for citizen questions: reads validated contributions from charter agent, generates neutral contextual responses, cross-references municipal program data, no hallucinations (Opik guardrails)\\n- **Deadline**: Week 2 of sprint (after charter agent complete)\\n- **Dependencies**: Charter agent functional (Task 4), N8N workflows ready, VectorStore populated\\n- **Success Criteria**: Design document with Opik integration plan, data flow diagram\\n\\n---\\n\\n## Risk Assessment & Mitigations\\n\\n| Risk                                                            | Impact   | Mitigation                                                                                                            | Owner             | Status                           |\\n| --------------------------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------- | ----------------- | -------------------------------- |\\n| **Guru missing from stack discussion**                          | Medium   | Record meetings, request written feedback on tasks, schedule follow-up calls                                          | [jnxmas]          | \ud83d\udfe2 Mitigated (recordings shared) |\\n| **Victor unavailable Thu-Sun**                                  | Medium   | Victor completes Firecrawl by Wed, [jnxmas] tests during absence                                                      | Victor + [jnxmas] | \ud83d\udfe2 Planned                       |\\n| **Crawler pagination not returning full results**               | High     | Victor debugging this week; if blocked, escalate to team                                                              | Victor            | \ud83d\udfe1 In progress                   |\\n| **N8N deployment blocking agent testing**                       | High     | [jnxmas] prioritizes ~2h completion ASAP                                                                              | [jnxmas]          | \ud83d\udfe1 In progress                   |\\n| **Opik access blocking Guru\'s development**                     | High     | [jnxmas] grants access within 24h (need Guru\'s username)                                                              | [jnxmas]          | \ud83d\udfe1 In progress                   |\\n| **Vector store decision blocking RAG**                          | Medium   | VectorStore + NOMIC confirmed; fallback = Mistral Studio                                                              | Guru + [jnxmas]   | \ud83d\udfe2 Resolved                      |\\n| **OCR quality unknown for scanned PDFs**                        | Medium   | Test 3 libraries (pdf2ocr, Tabula, pypdf), compare outputs                                                            | Victor \u2192 [jnxmas] | \ud83d\udfe1 Planned                       |\\n| **4-week sprint timeline pressure**                             | High     | Prioritize working prototype over perfection, ruthless task board management, limit to \\"two tracks\\" (NOMIC + Mistral) | All               | \ud83d\udfe1 Ongoing                       |\\n| **First agent not live before contributions deadline (~Feb 1)** | Critical | Fast-track Charter agent development this week, daily standups                                                        | Guru + [jnxmas]   | \ud83d\udd34 Active risk                   |\\n| **Low citizen engagement with contributions**                   | Medium   | Consider UX simplification, focus on chatbot quality over contribution volume                                         | [jnxmas]          | \ud83d\udfe1 Monitoring                    |\\n| **Team still in ideation phase despite deadline pressure**      | Medium   | Shift to execution mode immediately, lock architecture decisions                                                      | All               | \ud83d\udfe1 Transitioning                 |\\n| **French language hallucinations/bias in chatbot**              | Critical | Mistral backup, heavy Opik guardrails, manual testing in French                                                       | Guru + [jnxmas]   | \ud83d\udfe1 Design phase                  |\\n| **Hackathon Opik showcase insufficient**                        | Medium   | \\"Maximize Opik at every opportunity\\", document integration patterns, trace everything                                 | Guru              | \ud83d\udfe1 In progress                   |\\n\\n---\\n\\n## Alignment Confirmations & Strategic Notes\\n\\n**\u2705 Strong Alignments**:\\n\\n- Opik-first approach aligns perfectly with hackathon goals\\n- Multi-provider LLM strategy provides resilience and cost optimization\\n- French language focus (Mistral) addresses political optics and user needs\\n- Modular ETL architecture enables swapping components without rewrites\\n- Team expertise (NOMIC, Streamlit, VectorStore) matches stack decisions\\n- Task ownership clear and distributed well (Guru = agents, Victor = crawling, [jnxmas] = infrastructure/orchestration)\\n  **\u26a0\ufe0f Potential Misalignments**:\\n- **Timeline vs. scope**: 4 weeks for full pipeline (crawling + OCR + RAG + Charter agent + chatbot + Opik showcase) is aggressive\\n  - **Mitigation**: Limit to \\"two tracks\\" (NOMIC primary, Mistral backup), prioritize Charter agent + basic RAG over perfect Search Agent\\n- **Citizen engagement vs. effort**: Low contribution volume may not justify complex validation workflow\\n  - **Mitigation**: Focus on chatbot quality (broader citizen reach) over contribution automation\\n- **Team availability gaps**: Victor\'s Thu-Sun absence, Guru\'s jet lag, [jnxmas]\'s teaching commitment\\n  - **Mitigation**: Strong async collaboration (recordings, blog summaries, GitHub comments), clear handoffs\\n    **\ud83d\udd0d Clarifications Needed**:\\n- **Document Service vs. Chat Service**: Distinction still fuzzy (addressed as: Document = search/crawl management; Chat = conversational interface, but needs formal requirements doc)\\n- **Search Agent necessity**: Conditional decision pending RAG testing (good pragmatic approach)\\n- **Opik dashboard structure**: Single unified dashboard confirmed, but team needs to explore platform features to maximize value\\n  **\ud83d\udcc8 Recommended Focus Areas**:\\n\\n1. **This week**: Charter agent + RAG agent + Firecrawl completion + Opik access = critical path\\n2. **Next week**: OCR testing + Document Service definition + crawl tracking DB = data pipeline completion\\n3. **Week 3-4**: Integration, testing, French language validation, Opik showcase polish, citizen-facing chatbot MVP\\n\\n---\\n\\n## Documentation & Knowledge Management\\n\\n**Current Practices** (Strong):\\n\\n- \u2705 Docusaurus blog: Meeting summaries posted to `blog/` for async collaboration\\n- \u2705 GitHub tasks: Self-assignment, commenting for feedback\\n- \u2705 Task board: 3 tasks \\"In Progress\\" with assignments\\n- \u2705 Architecture blog post: Created for team review + AI context (Cursor/Claude)\\n- \u2705 Meeting recordings: Shared for async team members (Guru)\\n- \u2705 \\"Tell what we do and do what we tell\\": Commitment tracking across conversations\\n  **Improvements Suggested**:\\n- \ud83d\udcdd Document Opik integration patterns as you build (hackathon showcase value)\\n- \ud83d\udcdd Create crawl tracking DB schema diagram (avoid ambiguity)\\n- \ud83d\udcdd Formalize Document Service requirements doc (per Task 12)\\n- \ud83d\udcdd Keep citizen-facing deliverable timeline visible (dashboard/Gantt chart)\\n- \ud83d\udcdd Document OCR library comparison results (Task 10)\\n\\n---\\n\\n## Next Sync Meeting Agenda (Suggested)\\n\\n1. **N8N + Opik access**: Confirm both unblocked ([jnxmas] updates)\\n2. **Firecrawl PR status**: Review and merge if ready (Victor + [jnxmas])\\n3. **Charter agent progress**: Demo initial prototype, discuss Opik traces (Guru)\\n4. **RAG agent update**: Share approach, blockers, timeline (Guru)\\n5. **Crawl tracking DB**: Review schema design ([jnxmas])\\n6. **Document Service requirements**: Collaborative definition session (All)\\n7. **Task board review**: Close completed tasks, reprioritize open items (All)\\n8. **Opik showcase strategy**: What metrics/traces will impress hackathon judges? (All)\\n\\n---\\n\\n## Status Dashboard\\n\\n**Overall Progress**:\\n\\n- \ud83d\udfe2 **Architecture**: Finalized (VectorStore, NOMIC, Mistral, N8N, Opik strategy confirmed)\\n- \ud83d\udfe1 **Firecrawl Pipeline**: Victor progressing, PR open, completion target Wed\\n- \ud83d\udfe1 **N8N Deployment**: ~2 hours from completion (infrastructure blocker)\\n- \ud83d\udfe1 **Opik Setup**: Account exists, team access pending (need usernames)\\n- \ud83d\udd34 **Charter Agent**: Not started (blocked by Opik access + N8N)\\n- \ud83d\udfe1 **RAG Agent**: Starting development, update expected 1-2 days\\n- \ud83d\udd34 **OCR Pipeline**: Blocked on crawling completion\\n- \ud83d\udd34 **Crawl Tracking DB**: Design phase\\n- \ud83d\udfe2 **Team Coordination**: Strong communication, clear roles, async collaboration working\\n- \ud83d\udfe1 **Political Outreach**: 3/4 lists contacted, positive signals\\n- \ud83d\udd34 **Citizen Engagement**: Low contribution volume (UX consideration needed)\\n- \ud83d\udfe2 **Documentation**: Blog summaries active, recordings shared, task tracking functional\\n  **Open High-Priority Tasks** (Top 5):\\n\\n1. **\ud83d\udd34 URGENT**: Complete N8N deployment ([jnxmas], &lt;48h) - blocks agent testing\\n2. **\ud83d\udd34 URGENT**: Set up Opik team access ([jnxmas], &lt;24h) - blocks Guru\'s development\\n3. **\ud83d\udd34 URGENT**: Complete Firecrawl pipeline (Victor, by Wed) - data ingestion dependency\\n4. **\ud83d\udd34 HIGH**: Build Charter validation agent (Guru, update 1-2 days) - critical path for hackathon\\n5. **\ud83d\udd34 HIGH**: Build RAG agent with Opik (Guru, update 1-2 days) - citizen-facing deliverable\\n   **Next Milestones**:\\n\\n- **Week 1 Goal (by ~Jan 30-31)**: Charter validation agent functional with Opik tracing + Firecrawl pipeline merged + N8N orchestrating GitHub workflows + RAG agent prototype\\n- **Immediate Blockers**: N8N deployment (&lt;48h), Opik access (&lt;24h), Firecrawl pagination tuning (&lt;3 days)\\n- **Hackathon Prototype Delivery**: ~mid-February 2026 (2.5 weeks remaining from late Jan)\\n- **Critical Path**: Crawling \u2192 OCR \u2192 Vector DB \u2192 RAG + Opik \u2192 Chatbot MVP \u2192 French language validation\\n  **Team Availability This Week**:\\n- **Guru**: Available now (jet-lagged but active), development starting\\n- **Victor**: Intensive Mon-Wed, unavailable Thu-Sun (France travel)\\n- **[jnxmas]**: Full availability, prioritizing N8N/Opik/testing during Victor\'s absence\\n  **Risk Level**: \ud83d\udfe1 **MEDIUM-HIGH** - Timeline tight, first agent not yet live despite approaching contributions deadline, but team aligned and architecture solid. Immediate focus on unblocking N8N + Opik access will shift to \ud83d\udfe2 GREEN if completed within 48h.\\n\\n---\\n\\n## Action Summary - What Happens Next\\n\\n**Immediate (Next 24 Hours)**:\\n\\n1. [jnxmas] completes N8N deployment (~2 hours)\\n2. [jnxmas] sets up Opik team access (needs Guru + Victor usernames via Discord)\\n3. Guru shares Opik user ID/Discord username\\n4. Victor continues Firecrawl pagination debugging\\n5. Team explores Opik platform features once access granted\\n\\n**This Week (Next 3-7 Days)**:\\n\\n1. Victor completes Firecrawl PR by Wednesday\\n2. [jnxmas] reviews and merges Firecrawl PR\\n3. Guru develops Charter validation agent, provides update in 1-2 days\\n4. Guru develops RAG agent prototype, provides update in 1-2 days\\n5. [jnxmas] tests Firecrawl on additional sources during Victor\'s absence\\n6. [jnxmas] begins crawl tracking DB with SQL Model\\n7. Guru + Victor review architecture blog post, suggest improvements\\n8. All team members familiarize with Opik capabilities\\n\\n**Next Week (Week 2 of Sprint)**:\\n\\n1. OCR library testing begins (Victor returns, or [jnxmas] covers)\\n2. Document Service requirements defined collaboratively\\n3. RAG agent fully functional with Opik guardrails\\n4. Charter agent deployed to N8N workflows\\n5. Crawl tracking DB prototype operational\\n6. Architecture frozen, team shifts to integration phase\\n\\n**Week 3-4 (Final Sprint)**:\\n\\n1. Full pipeline integration testing\\n2. French language validation and bias checking\\n3. Citizen-facing chatbot MVP deployment\\n4. Opik showcase polish (metrics, traces, dashboards, experiment tracking)\\n5. Hackathon submission preparation\\n6. Final outreach to 4th electoral list\\n7. Documentation finalization\\n\\n---\\n\\n**Confidence Level**: \ud83d\udfe1 **CAUTIOUSLY OPTIMISTIC** - Strong team, solid architecture, clear tasks, but timeline aggressive and first agent not yet live. Success depends on unblocking N8N + Opik access within 48h and Charter agent prototype within 1 week. Victor\'s Wed deadline and Guru\'s jet lag are manageable with current plans.\\n**Recommendation**: Daily async standups (Discord) this week to track Charter agent + Firecrawl progress. Consider lightweight demo/review session Friday to validate week 1 progress before weekend."},{"id":"meher-jnxmas-letscode","metadata":{"permalink":"/fr/blog/meher-jnxmas-letscode","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-16-meher-jnxmas.mdx","source":"@site/blog/2026-01-16-meher-jnxmas.mdx","title":"Lets us code","description":"Project Overview & Vision","date":"2026-01-16T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"}],"readingTime":2.28,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meher-jnxmas-letscode","title":"Lets us code","authors":["jnxmas"],"tags":["encode","civictech"]},"unlisted":false,"prevItem":{"title":"Let us choose the stack","permalink":"/fr/blog/meeting-ocapistaine-1"},"nextItem":{"title":"\xd2 Capistaine Kick-off","permalink":"/fr/blog/ocapistaine-hackathon-kickoff"}},"content":"### Project Overview & Vision\\n\\n- The core idea is building an **AI-powered civic transparency platform** focused on local democracy, citizen engagement, and real-world issues (starting with inspiration from India, but with potential global scalability).\\n- Goal: Create a standardized, bullshit-free alternative to Twitter/X discussions for civic topics \u2014 avoiding noise and enabling structured transparency for citizens, investors, and \\"democracy islands\\" (e.g., places like Audierne).\\n- It\'s tied to the **\\"Commit to Change\\" AI Agents Hackathon** (powered by Opik / Comet), running ~4 weeks starting mid-January 2026, with categories like Community Impact.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Hackathon Focus & Judging Criteria Emphasis\\n\\n- Heavy emphasis on **Opik integration** for observability, evaluation, metrics, dashboards, experiment tracking, and improving LLM/agent quality.\\n- Key criteria to nail: Functionality, real-world relevance (New Year\u2019s/civic goals), effective LLM/agent use, robust evaluation/monitoring, and deep Opik workflow integration (not just fluff).\\n- Plan: Automate Opik feedback into the platform for a \\"virtuous circle\\" of optimization. Showcase Opik at every stage (dev workflow, runtime monitoring, etc.).\\n- Strategy: Prioritize smooth, meaningful Opik use \u2192 even if some parts feel like \\"fluff,\\" lean into it for judging scores.\\n\\n### Team & Collaboration Setup\\n\\n- You created/invited Meher to the project using team join code: **0e10f89d** (valid until Jan 17, 2026).\\n- Repo: **Ocapistaine** (on GitHub) \u2014 you updated it with:\\n  - Clear license\\n  - Collaboration addendum / agreements\\n  - Docusaurus as submodule for docs\\n  - Project board with tasks (including Opik-specific ones)\\n- You proposed a fair structure for handling prize money / motivation (Meher called it \\"very clean\\" and liked it).\\n- Meher was pending \u2192 accepted invite; you both coordinated joining the hackathon portal/team.\\n- Another collaborator (Vic) self-assigned tasks.\\n- You shared the kickoff doc: https://docs.locki.io/blog/ocapistaine-hackathon-kickoff (titled \\"\xd2 Capistaine Kick-off | AI-Powered Civic Transparency for Local Democracy\\").\\n\\n### Monetization & Long-Term Ideas\\n\\n- You have ideas for monetizing / turning it into a full startup (trust-based, you\'ll share more).\\n- Potential global expansion discussed, but start focused (e.g., India as strong testbed).\\n- References to past hackathon success (you + Satish, 4th place with on-chain 3D objects + AI chatbot).\\n- Avoid overkill like Decidim platforms \u2014 keep it practical and thrilling.\\n\\n### Recent Status & Next Steps\\n\\n- Meher was occasionally busy/catching up (dinner, out, etc.) but engaged.\\n- As of last messages (~Jan 15\u201316, 2026):\\n  - Everyone\'s in the team/repo.\\n  - Ready to start **coding** (both excited: \\"tickles in fingers\\").\\n  - Emphasis on transparent task assignment (\\"tell what we do and do what we tell\\").\\n  - Call happened in Ocapistaine channel.\\n  - Brainstorming better Opik showcases ongoing.\\n\\n**Overall vibe**: Enthusiastic, trusting partnership (\\"I trust you!\\"). You\'re leading repo/docs/setup/strategy; Meher is on board, catching up, and eager to code + highlight Opik. Project is now properly set up and ready to build \u2014 focus on delivering a functional, Opik-heavy prototype for the hackathon deadline."},{"id":"ocapistaine-hackathon-kickoff","metadata":{"permalink":"/fr/blog/ocapistaine-hackathon-kickoff","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-15-let-the-journey-begin.mdx","source":"@site/blog/2026-01-15-let-the-journey-begin.mdx","title":"\xd2 Capistaine Kick-off","description":"AI-Powered Civic Transparency for Local Democracy","date":"2026-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"}],"readingTime":2.17,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"ocapistaine-hackathon-kickoff","title":"\xd2 Capistaine Kick-off","authors":["jnxmas"],"tags":["encode","civictech"]},"unlisted":false,"prevItem":{"title":"Lets us code","permalink":"/fr/blog/meher-jnxmas-letscode"},"nextItem":{"title":"OPIK : Agent & Prompt Optimization for LLM Systems","permalink":"/fr/blog/opik-workshop-2"}},"content":"**AI-Powered Civic Transparency for Local Democracy**\\n\\n## My 2026 Resolution\\n\\n:::tip The Promise\\nThis year, I will finally understand my local elections and get involved as a citizen.\\n:::\\n\\nSound familiar? Every election cycle, millions of citizens want to participate but face the same wall: scattered documents, administrative jargon, and no time to dig through years of municipal decisions.\\n\\n**This January, I stopped just wishing \u2014 and started building.**\\n\\n\x3c!-- truncate --\x3e\\n\\n## What We\'re Building\\n\\n\xd2 Capistaine is my answer to the civic engagement resolution we\'ve all made (and broken). It\'s an AI-powered transparency tool that:\\n\\n| Feature               | Description                                               |\\n| --------------------- | --------------------------------------------------------- |\\n| **Document Crawling** | Index 4,000+ municipal documents with Firecrawl + OCR     |\\n| **Citizen Q&A**       | Answer questions in plain language via RAG                |\\n| **Quality Tracking**  | Monitor LLM accuracy with Opik (hallucination detection)  |\\n| **Multi-Channel**     | N8N workflows for Facebook, email, and chatbot engagement |\\n\\n:::info Live Platform\\nSupporting [audierne2026.fr](https://audierne2026.fr) \u2014 a participatory democracy platform where citizens co-create the 2026 municipal program.\\n:::\\n\\n## Progress Update (Checkpoint 1)\\n\\n### Status Overview\\n\\n| Component              | Status | Details                                                        |\\n| ---------------------- | :----: | -------------------------------------------------------------- |\\n| **audierne2026.fr**    |   \u2705   | Jekyll platform live, citizens contributing                    |\\n| **Document Corpus**    |   \ud83d\udfe1   | 42 Gwaien bulletins collected, 4,000+ arr\xeat\xe9s identified       |\\n| **Firecrawl Pipeline** |   \ud83d\udd34   | Infrastructure designed, crawling not yet operational          |\\n| **Opik Integration**   |   \ud83d\udfe1   | Tracing architecture planned, awaiting RAG implementation      |\\n| **N8N Workflows**      |   \ud83d\udfe1   | Vaettir repo created, FB/email integration designed            |\\n| **RAG System**         |   \ud83d\udd34   | Vector store + retrieval pipeline pending                      |\\n| **Documentation**      |   \u2705   | [docs.locki.io](https://docs.locki.io) live with methodologies |\\n\\n### What\'s Working\\n\\n- Live participation platform with real citizen contributions\\n- Dual-license structure (Apache 2.0 + ELv2) for open collaboration\\n- Bilingual documentation (EN/FR)\\n- Project planning and task tracking on GitHub\\n\\n### Next Steps\\n\\n1. **Fix Firecrawl pipeline** \u2014 Get municipal document crawling operational\\n2. **Deploy Opik tracing** \u2014 LLM observability from day one\\n3. **Build RAG retrieval** \u2014 With hallucination guardrails\\n4. **Launch citizen Q&A** \u2014 First chatbot interactions\\n\\n## Hackathon Tracks\\n\\n| Track                         | Why We Qualify                                                 |\\n| ----------------------------- | -------------------------------------------------------------- |\\n| **Social & Community Impact** | Civic transparency tool enabling local democracy participation |\\n| **Best Use of Opik**          | LLM-as-judge evaluations + tracing for RAG quality assurance   |\\n\\n:::note Democracy Can\'t Afford Hallucinations\\nWhen citizens ask \\"What happened with the school budget?\\", the answer must be accurate and sourced. Opik helps us guarantee that.\\n:::\\n\\n## Team\\n\\n| Name                      | Role                          | GitHub                                             |\\n| ------------------------- | ----------------------------- | -------------------------------------------------- |\\n| Jean-No\xebl Schilling       | Project Lead / Backend        | [@jnschilling](https://github.com/jnschilling)     |\\n| Victor A                  | Backend Python                | [@zcbtvag](https://github.com/zcbtvag)             |\\n| GurmeherSingh             | ML Engineer                   | [@GurmeherSingh](https://github.com/GurmeherSingh) |\\n| _(open for contributors)_ | Frontend / UX / Communication | \u2014                                                  |\\n\\n## Links\\n\\n| Resource      | URL                                                             | Public/private |\\n| ------------- | --------------------------------------------------------------- | -------------- |\\n| Live Platform | [audierne2026.fr](https://audierne2026.fr)                      | public         |\\n| Documentation | [docs.locki.io](https://docs.locki.io)                          | public         |\\n| GitHub        | [locki-io/ocapistaine](https://github.com/locki-io/ocapistaine) | private ATM    |\\n| Project Board | [GitHub Projects](https://github.com/orgs/locki-io/projects/2)  | public         |\\n\\n---\\n\\n_If AI can help us keep our New Year\'s resolutions, maybe the most impactful one is: becoming a better citizen._"},{"id":"opik-workshop-2","metadata":{"permalink":"/fr/blog/opik-workshop-2","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-15-opik-workshop-2.mdx","source":"@site/blog/2026-01-15-opik-workshop-2.mdx","title":"OPIK : Agent & Prompt Optimization for LLM Systems","description":"This training consolidates the operational and technical foundations needed to run and execute agent/prompt optimization in team settings (e.g., hackathons and internal workshops).","date":"2026-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"}],"readingTime":15.53,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"opik-workshop-2","title":"OPIK : Agent & Prompt Optimization for LLM Systems","authors":["jnxmas"],"tags":["ai-ml","rag","encode"]},"unlisted":false,"prevItem":{"title":"\xd2 Capistaine Kick-off","permalink":"/fr/blog/ocapistaine-hackathon-kickoff"},"nextItem":{"title":"OPIK : AI Evaluation and Observability","permalink":"/fr/blog/opik-workshop-1"}},"content":"This training consolidates the operational and technical foundations needed to run and execute **agent/prompt optimization** in team settings (e.g., hackathons and internal workshops).\\n\\nIt includes :\\n\\n- **eval-driven optimization** of LLM agent prompts using measurable metrics and iterative loops,\\n- including **meta-prompting**, **genetic/evolutionary methods**, **hierarchical/reflective optimizers (HRPO)**, **few-shot Bayesian selection**, and **parameter tuning**.\\n\\n\x3c!-- truncate --\x3e\\n\\n:::tip\\nIt is important because prompt iteration without datasets and metrics devolves into subjective \u201cdoom wordsmithing,\u201d leading to unreliable, expensive, and non-reproducible agents.\\n:::\\n\\nThis material applies to **AI/ML engineers, LLM practitioners, platform and DevEx teams, facilitators/mentors**, and anyone responsible for building and improving **tool-using agents (RAG/MCP), multimodal agents, or production chatbots** under constraints of **speed, accuracy, and cost**.\\n\\n<iframe\\n  width=\\"100%\\"\\n  style={{ \\"aspect-ratio\\": \\"16 / 9\\" }}\\n  src=\\"https://www.encodeclub.com/programmes/comet-resolution-v2-hackathon/events/agent-optimization-with-opik\\"\\n  title=\\"OPIK workshop 2\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\"\\n  referrerpolicy=\\"strict-origin-when-cross-origin\\"\\n  allowfullscreen\\n></iframe>\\n\\n## 1) Development of the Content (Chronological and Logical Sequence)\\n\\n### A. Concepts Fundamental\\n\\n#### A1) Workshop mechanics for \u201cagent optimization\u201d sessions (hackathon-ready)\\n\\nIn interactive workshops, success depends on **facilitation + operational readiness** as much as technical depth.\\n\\n- **Live attendance** enables:\\n  - Real-time **Q&A**\\n  - Higher engagement in hands-on segments\\n  - Faster alignment on team objectives and constraints\\n- **Recording** is essential for:\\n  - Participants across incompatible time zones\\n  - Rewatching technical steps and setup instructions later\\n- **Hands-on sessions** increase operational sensitivity:\\n  - Frequent tool switching\\n  - Screen sharing and multi-monitor complexity\\n  - High cognitive load for participants following along\\n    **Conceptual grounding before coding**\\n- Start with a short theory block to align terminology, scope, and outcomes.\\n- Prevents early derailment into deep technical detail without a shared baseline.\\n  **Analogy**\\n- Conceptual grounding is like agreeing on a **map legend** before navigating; without it, people interpret instructions differently even if they follow the same steps.\\n\\n---\\n\\n#### A2) The optimization target: prompts, context, demonstrations, and parameters\\n\\n\u201cPrompt optimization\u201d is broader than rewriting a single system message. In practice, teams optimize multiple levers:\\n\\n- **System prompt / developer prompt**: core behavior, constraints, safety, formatting.\\n- **Context engineering**: retrieval and tools (RAG, MCP servers/clients), memory, long-context strategies.\\n- **Intent engineering**: define \u201cwhat good looks like\u201d using examples of desired conversations/outputs, then optimize toward them.\\n- **Few-shot demonstrations**: which examples to include, how many, and in what order.\\n- **Sampling parameters**: temperature, top_p, top_k (reduce variance, tune style/creativity).\\n  **Prompt optimization vs. fine-tuning**\\n- **Prompt optimization** changes instructions/context/examples/parameters without changing model weights.\\n  - Faster iteration, lower operational burden, often cheaper.\\n- **Fine-tuning** changes model weights.\\n  - Higher complexity and governance; sometimes necessary, but not the default path.\\n\\n---\\n\\n#### A3) Evals: the required feedback signal\\n\\nAn **eval** is an automated test harness that:\\n\\n- Runs an agent/prompt on a **dataset**\\n- Scores outputs via a **metric**\\n- Produces repeatable feedback for iteration\\n  Common metric dimensions:\\n- **Accuracy / task success**\\n- **Hallucination rate / factuality**\\n- **Format compliance** (schemas, JSON, bullet structure)\\n- **Latency** (end-to-end runtime)\\n- **Cost** (tokens, tool calls, infra)\\n\\n---\\n\\n#### A4) The \u201cImpossible Triangle\u201d: Speed \xd7 Accuracy \xd7 Cost\\n\\nAgent design and optimization inevitably trade off:\\n\\n- **Speed**: latency, time-to-first-token, end-to-end runtime\\n- **Accuracy**: correctness, task completion, policy compliance\\n- **Cost**: token usage, model pricing, tool calls, infrastructure\\n  Key implications:\\n- You typically can\u2019t maximize all three simultaneously.\\n- Optimization must explicitly measure and constrain all three.\\n  Common architecture pattern:\\n- **Fast front agent** for interactive UX\\n- **Slower or cheaper back agents** for verification, retrieval, or deeper reasoning\\n\\n---\\n\\n#### A5) Optimizer families (what they do and when to use)\\n\\nThis training consolidates multiple optimizer approaches discussed across sessions:\\n\\n1. **Meta-prompting (Meta-reasoner)**\\n   - An LLM rewrites your prompt to produce candidate variants.\\n   - You evaluate candidates and keep the best.\\n2. **Genetic / Evolutionary optimization**\\n   - Maintains a population of prompts.\\n   - Applies **mutations** (remove/reorder/rewrite sections) and **selection** (keep winners).\\n   - Often includes \u201cfresh gene injection\u201d and a **Hall of Fame** of best prompts/components.\\n3. **Hierarchical / Reflective optimization (HRPO)**\\n   - Diagnoses failure clusters, forms hypotheses, proposes targeted prompt changes, re-evaluates.\\n   - Requires a clear metric + explanation so it can reason about failures.\\n4. **Few-shot Bayesian optimization**\\n   - Selects:\\n     - Which few-shot examples,\\n     - How many,\\n     - In which order,\\n   - Then inserts them into the prompt for stronger in-context guidance.\\n5. **Parameter optimization**\\n   - Tunes generation parameters (temperature/top_p/top_k) after prompt structure is solid.\\n   - Useful for controlling non-determinism and output variance.\\n     **Chaining optimizers (recommended workflow)**\\n\\n- A practical pipeline:\\n  1. Reflective/hierarchical (HRPO) or evolutionary to improve core instructions\\n  2. Few-shot Bayesian to optimize demonstrations\\n  3. Parameter tuning to stabilize style/variance and meet latency/cost constraints\\n\\n---\\n\\n#### A6) Multimodal prompt optimization (images + text)\\n\\nMultimodal agents take:\\n\\n- **Image inputs** (e.g., dashcam frames)\\n- **Text inputs** (questions/instructions)\\n- Produce **text outputs** (e.g., hazard descriptions)\\n  Multimodality raises difficulty because correctness depends on accurately grounding outputs in visual evidence and describing it consistently.\\n\\n---\\n\\n### B. Principal Pains and Practical Problems Encountered\\n\\n#### B1) Workshop/session problems (operational + facilitation)\\n\\n- Time zone mismatch reduces live attendance quality.\\n- Startup friction:\\n  - Zoom connection issues\\n  - Screen sharing failures (multi-monitor confusion)\\n- Logistics questions interrupt technical flow.\\n- Early \u201cdeep technical\u201d derailments due to lack of conceptual alignment.\\n- High cognitive load in hands-on segments (tools + steps + Q&A at once).\\n\\n#### B2) Optimization and engineering problems (technical)\\n\\n- **No dataset \u2192 no optimization**: teams want improvement without ground truth.\\n- **No metric \u2192 no signal**: changes are judged by \u201cvibes.\u201d\\n- Hidden tradeoffs: gains in accuracy may increase cost/latency.\\n- Overfitting to small/clean datasets that don\u2019t represent production.\\n- Tooling complexity:\\n  - Provider setup (API keys)\\n  - Version/environment issues\\n  - Multimodal data formatting and cost\\n- Non-determinism: outputs vary across runs; naive evals are unstable.\\n- Multilingual drift: improvements in one language/style can degrade perceived quality for non-native speakers.\\n\\n---\\n\\n### C. Causes of Common Errors and Deviations (Technical Diagnosis)\\n\\n#### C1) Process errors\\n\\n- Starting implementation before defining:\\n  - \u201cWhat does success look like?\u201d\\n  - \u201cHow will we measure it?\u201d\\n- Iterating prompts manually without repeatable evals (\u201cdoom wordsmithing\u201d).\\n- Changing too many variables at once (prompt + model + dataset + metric), breaking attribution.\\n\\n#### C2) Data and evaluation errors\\n\\n- Non-representative datasets (too small, too idealized, not production-like).\\n- No holdout/validation: training improvements don\u2019t generalize.\\n- Overfitting to dataset phrasing rather than task intent.\\n\\n#### C3) Metric errors\\n\\n- Metric-task mismatch:\\n  - Character-level similarity (e.g., Levenshtein) penalizes correct paraphrases.\\n  - Fast metrics can reward superficial closeness rather than semantic correctness.\\n- Missing metric explanations:\\n  - Reflective optimizers need \u201cwhy this score\u201d to hypothesize and fix failure modes.\\n\\n#### C4) Operational and facilitation errors\\n\\n- No pre-flight checks for recording/screen share.\\n- Letting logistics Q&A repeatedly interrupt technical depth.\\n- Skipping conceptual grounding and jumping into highly technical steps.\\n\\n---\\n\\n### D. Solutions, Best Practices, and Strategies\\n\\n#### D1) Facilitation strategy for optimization workshops\\n\\nUse a structured agenda:\\n\\n1. **Buffer + housekeeping** (2\u20135 min)\\n2. **Conceptual grounding** (5\u201310 min)\\n3. **Hands-on optimization** (primary block)\\n4. **Q&A checkpoints** (periodic)\\n5. **Closeout**: follow-ups and resources channel (e.g., Discord)\\n   Logistics handling:\\n\\n- Allow limited buffer for urgent logistics at the start.\\n- Route ongoing logistics to a dedicated channel (Discord/moderators).\\n  Operational readiness:\\n- Test recording and screen share before the session begins.\\n- Prepare backup plan (rejoin meeting, share window instead of full screen, alternate host).\\n\\n---\\n\\n#### D2) Build an eval-driven optimization loop (core technical workflow)\\n\\nA repeatable loop:\\n\\n1. Define a **dataset** (inputs + expected behavior)\\n2. Define a **metric** (scoring rubric and constraints)\\n3. Run a **baseline** prompt/agent and record results\\n4. Generate candidate prompts (human + optimizer)\\n5. Evaluate candidates on the same harness\\n6. Select the best under constraints (accuracy + speed + cost)\\n7. Iterate until target reached or budget exhausted\\n8. Validate on **holdout/validation** to detect overfitting\\n\\n---\\n\\n#### D3) Optimizer selection guidance\\n\\n- **Meta-prompting**: fast setup, quick baseline improvements.\\n- **Genetic/evolutionary**: broad exploration; good when small phrasing changes matter.\\n- **Reflective/HRPO**: best for nuanced failure clusters and \u201clast mile\u201d improvements.\\n- **Few-shot Bayesian**: when selection and ordering of examples is a major performance lever.\\n- **Parameter tuning**: stabilize variance and style after instructions/examples are strong.\\n  Budget warning:\\n- More sophisticated optimizers typically increase API calls, tokens, and wall-clock time.\\n\\n---\\n\\n#### D4) Metric strategy (fast iteration vs semantic correctness)\\n\\n- Use **fast metrics** early:\\n  - regression detection\\n  - formatting/stability checks\\n- Upgrade to **semantic evals** for correctness:\\n  - **LLM-as-a-judge** with a strict rubric\\n  - hybrid metrics (semantic + format + safety)\\n- Consider **multi-metric objectives**:\\n  - accuracy + cost + latency to prevent \u201caccurate but too expensive\u201d prompts\\n\\n---\\n\\n#### D5) Production readiness strategy (safety and reproducibility)\\n\\nTreat prompt optimization as controlled production change:\\n\\n- Use staging, monitoring, and rollback prompts.\\n- Keep prompt versioning, changelogs, and eval results history.\\n- Build datasets from **production traces**:\\n  - convert traces into eval datasets or annotation queues\\n- Add human-in-the-loop review for safety-critical workflows.\\n  Model strategy:\\n- Use a **larger model** to generate candidate prompts (\u201cauthoring model\u201d).\\n- Evaluate on the **target deployment model** (smaller/cheaper) for parity.\\n  Multilingual concerns:\\n- Ensure evals cover target languages.\\n- Use judges that understand the language or add human evaluation.\\n\\n---\\n\\n### E. What Should Be Done (Do\u2019s)\\n\\n- **Start every workshop** with conceptual grounding (terms, scope, intended outcome).\\n- **Enable and test recording**; ensure rewatchability for time zones.\\n- **Pre-flight check** (5\u201310 minutes before start):\\n  - Zoom audio/video\\n  - correct monitor/window sharing\\n  - recording status\\n- **Define success metrics upfront** (rubric, pass/fail rules, partial credit).\\n- **Build/curate a representative dataset** (typical + edge + adversarial cases).\\n- **Run and document a baseline** before optimization.\\n- **Use train + validation (+ test)** splits; add a holdout set to detect overfitting.\\n- **Select an optimizer** based on:\\n  - budget, failure complexity, exploration vs targeted fixes\\n- **Log and version everything**:\\n  - prompt versions, scores, dataset versions, model/provider settings\\n- **Constrain outputs** when consistency matters (schemas, bullet limits, citation rules).\\n- **Use production traces** to keep evaluation realistic; build an annotation queue when needed.\\n- **Apply multi-metric gates** (accuracy must improve without breaking cost/latency).\\n\\n---\\n\\n### F. What Should NOT Be Done (Don\u2019ts)\\n\\n- **Don\u2019t** jump into technical implementation without aligning key concepts and goals.\\n- **Don\u2019t** rely only on live attendance; always provide recordings.\\n- **Don\u2019t** allow logistics Q&A to repeatedly interrupt technical flow (route it elsewhere).\\n- **Don\u2019t** optimize without a dataset or without a metric.\\n- **Don\u2019t** rely only on \u201cdoom wordsmithing\u201d (random manual edits) without evals.\\n- **Don\u2019t** ignore the **speed\u2013accuracy\u2013cost** triangle.\\n- **Don\u2019t** let optimizers run without guardrails:\\n  - they may exploit metric loopholes or create brittle prompts\\n- **Don\u2019t** assume gains on tiny samples generalize to production.\\n- **Don\u2019t** use only character-level similarity for semantic tasks in production-critical scenarios.\\n- **Don\u2019t** change prompt + model + metric + dataset simultaneously without tracking; you lose causal understanding.\\n- **Don\u2019t** treat experiment tracking as optional; without it, improvements are not reproducible.\\n\\n---\\n\\n### G. Tools, Tasks, and Recommended Actions\\n\\n#### G1) Tools (explicitly referenced or strongly implied)\\n\\n- **Zoom**: live delivery, screen sharing, recording\\n- **Discord**: async logistics, follow-ups, announcements\\n- **Comet**: experiment tracking UI, dataset management, optimization studio\\n- **OPIK SDK** (Python): optimization/evaluation loops (multimodal demo)\\n- **OPIC SDK / OPIC GitHub monorepo**: optimizer suite and algorithms\\n- **LLM providers**: OpenAI, Gemini, local models (e.g., Ollama)\\n- **RAG + MCP servers/clients**: context/tool ecosystem patterns\\n\\n#### G2) Recommended team routines (practical)\\n\\n1. **Workshop runbook**\\n   - setup checklist + agenda template + escalation channel for logistics\\n2. **Minimal eval harness**\\n   - dataset loader\\n   - prompt runner\\n   - metric function (with explanation)\\n   - reporting dashboard\\n3. **Optimization experiments**\\n   - meta-prompting run (N candidates \xd7 M trials)\\n   - genetic/evolutionary run (population, mutation operators, selection)\\n   - reflective/HRPO run (failure clustering, hypothesis generation)\\n4. **Budget controls**\\n   - max trials, max tokens, max wall-clock time\\n5. **Acceptance gates**\\n   - \u201cno merge if validation score drops\u201d\\n   - enforce latency/cost ceilings\\n6. **Trace-to-dataset pipeline**\\n   - export 100\u2013500 production traces\\n   - label via annotation queue\\n   - iterate dataset quality before optimizing further\\n7. **Release checklist**\\n   - staging rollout, monitoring KPIs, rollback prompt\\n\\n#### G3) Multimodal data preparation (when applicable)\\n\\n- Images/audio/video may require **Base64 encoding** in datasets.\\n- Video can be token-heavy; plan budget and limits accordingly.\\n\\n---\\n\\n## 2) Practical Examples (Reviewed and Rewritten)\\n\\n### Example 1 \u2014 Handling a delayed workshop start (screen sharing issue)\\n\\n- **Scenario:** Presenter cannot share the correct screen due to multi-monitor setup.\\n- **Recommended response:**\\n  - Announce a brief delay and the cause (\u201cscreen share setup\u201d).\\n  - Use the time for housekeeping:\\n    - confirm recording is on,\\n    - ask attendees to post time zones in chat,\\n    - redirect logistics questions to Discord.\\n  - Resume with **conceptual grounding** once stable.\\n\\n---\\n\\n### Example 2 \u2014 Preventing early technical derailment\\n\\n- **Scenario:** Participants immediately ask deep implementation questions (tool calling, optimizer internals) before definitions are aligned.\\n- **Recommended response:**\\n  - Pause and define:\\n    - agent vs prompt vs context vs eval,\\n    - the target metric and dataset,\\n    - success criteria and constraints.\\n  - Explicitly defer deep dives:\\n    - \u201cWe\u2019ll go deep in a moment\u2014first we align on concepts and the evaluation loop.\u201d\\n\\n---\\n\\n### Example 3 \u2014 Meta-prompting to fix inconsistent formatting\\n\\n- **Scenario:** A support chatbot fails JSON schema compliance ~30% of the time.\\n- **Approach:**\\n  - Create an eval set of real formatting cases.\\n  - Use a meta-reasoner prompt to generate ~6 system-prompt variants:\\n    - stricter schema instructions,\\n    - explicit formatting steps,\\n    - refusal conditions for missing fields.\\n  - Evaluate all candidates; select the best and iterate until compliance stabilizes.\\n\\n---\\n\\n### Example 4 \u2014 Genetic optimization for a sensitive classification task\\n\\n- **Scenario:** Ticket triage accuracy varies heavily with small prompt phrasing differences.\\n- **Approach:**\\n  - Start from a parent prompt.\\n  - Generate a population of children via mutations:\\n    - reorder priorities (labels first, then rules),\\n    - remove ambiguous wording,\\n    - tighten label definitions.\\n  - Evaluate all prompts; keep winners and discard losers.\\n  - Inject fresh prompts periodically (including the original) to avoid premature convergence.\\n  - Maintain a **Hall of Fame** of best prompts/components.\\n\\n---\\n\\n### Example 5 \u2014 Reflective/HRPO optimizer to reduce hallucinations in incomplete context\\n\\n- **Scenario:** An agent hallucinates when retrieval returns partial or irrelevant documents.\\n- **Approach:**\\n  - Define a metric that penalizes hallucination and rewards:\\n    - uncertainty statements,\\n    - citations/quotes from sources.\\n  - Reflective optimizer clusters failures:\\n    - missing citations,\\n    - overconfident claims with no evidence.\\n  - Prompt changes:\\n    - \u201cIf the answer is not supported by context, say \u2018I don\u2019t know\u2019 and ask for clarification.\u201d\\n    - require quoting or citing retrieved passages.\\n  - Re-run eval until hallucination rate drops on validation.\\n\\n---\\n\\n### Example 6 \u2014 Multimodal hazard detection optimization (Comet + OPIK)\\n\\n- **Scenario:** Dashcam hazard detector gives generic driving advice instead of image-grounded hazards.\\n- **Dataset pattern:**\\n  - image + question \u2192 reference hazard annotation\\n- **Metric approach (fast demo metric):**\\n  - Levenshtein ratio vs reference text (fast but not semantic)\\n- **Reflective prompt improvements:**\\n  - \u201cOnly describe hazards visible or strongly implied by the image; do not provide general driving advice.\u201d\\n  - Output constraint: \u201cReturn 1\u20133 bullet points, each a hazard statement.\u201d\\n- **Validation caution:**\\n  - Small subsets can cause high variance and overfitting; confirm improvements on validation/test and consider LLM-judge for semantic correctness.\\n\\n---\\n\\n### Example 7 \u2014 Intent engineering for a safety-sensitive conversational assistant\\n\\n- **Scenario:** Build an empathetic therapy-style assistant with safety protocols.\\n- **Intent-first approach:**\\n  - Create a dataset of ideal conversations:\\n    - anxiety \u2192 validation + grounding exercise\\n    - self-harm \u2192 safety protocol and resources\\n    - diagnosis request \u2192 refuse diagnosis, provide guidance/resources\\n  - Define eval rubric:\\n    - empathy markers, safety compliance, refusal correctness\\n  - Optimize prompts:\\n    - meta-prompting for quick gains\\n    - reflective optimizer for recurring failures (too clinical, insufficient validation)\\n  - Add holdout eval set to avoid overfitting to scripted examples.\\n\\n---\\n\\n## 3) Conclusion and Practical Application\\n\\nAgent/prompt optimization becomes reliable only when treated as an engineering discipline: **dataset + metric + iterative eval loop + controlled changes**. Operationally, successful workshops require **conceptual grounding**, tested **recording/screen-sharing**, and clear boundaries between logistics and technical work. Technically, improvements should be driven by **evals** and chosen optimizers (meta-prompting, genetic/evolutionary, reflective/HRPO, few-shot Bayesian, parameter tuning), with explicit management of the **speed\u2013accuracy\u2013cost** tradeoff. In day-to-day practice, start with a minimal eval harness and baseline, run low-budget optimization, validate on holdout data, and ship through a controlled release process with monitoring and rollback.\\n**Next steps**\\n\\n1. Build a reusable **workshop runbook** (checklist + agenda + support channels).\\n2. Implement a minimal **eval harness** for one real agent flow and record baseline metrics.\\n3. Run **meta-prompting** to capture quick wins, then escalate to **reflective/HRPO** or **genetic** as needed.\\n4. Add **few-shot selection** and **parameter tuning** once prompt structure is stable.\\n5. Upgrade metrics to **LLM-judge + rubric** (and human review where required), and enforce **multi-metric gates** (accuracy + cost + latency).\\n\\n---\\n\\n## Glossary (Key Terms)\\n\\n- **Agent**: An LLM-based system that may use tools (APIs, retrieval, MCP) to complete tasks.\\n- **Agent optimization**: Improving an agent\u2019s effectiveness through systematic iteration using datasets and metrics.\\n- **Conceptual grounding**: A short theory-based alignment step to ensure shared definitions, goals, and assumptions.\\n- **Context engineering**: Supplying relevant context via retrieval/tools/memory/long context windows (e.g., RAG, MCP).\\n- **Intent engineering**: Defining desired outputs/behaviors first (examples), then optimizing backward toward them.\\n- **Eval (evaluation)**: Automated testing of prompts/agents against a dataset using a metric/rubric.\\n- **Metric / reward function**: A scoring function used to judge outputs (accuracy, hallucination, cost, latency, etc.).\\n- **Meta-prompting (meta-reasoner)**: Using an LLM to generate improved prompts for another task.\\n- **Genetic / evolutionary optimization**: Population-based search over prompts via mutation and selection.\\n- **Mutation**: A change applied to a prompt to create variation (remove/reorder/replace text).\\n- **Hall of Fame**: A retained set of top-performing prompts/components across generations.\\n- **Reflective / hierarchical optimizer (HRPO)**: Optimizer that diagnoses failure patterns, forms hypotheses, and proposes targeted fixes.\\n- **Few-shot Bayesian optimizer**: Method for selecting and ordering few-shot examples to include in prompts.\\n- **Parameter optimization**: Tuning inference parameters like temperature/top_p/top_k to manage variability and style.\\n- **LLM-as-a-judge**: Using an LLM to grade another model\u2019s output against a rubric/reference.\\n- **Levenshtein ratio**: Character-level similarity score based on edit distance (fast, but not semantic).\\n- **Overfitting**: Improvements on training data that don\u2019t generalize to validation/test.\\n- **MCP (Model Context Protocol)**: Tool ecosystem pattern (servers/clients) enabling models to access external capabilities.\\n- **RAG (Retrieval-Augmented Generation)**: Retrieval system that injects documents into context to ground responses.\\n\\n---\\n\\n## Review Questions (Knowledge Check)\\n\\n1. Why is **conceptual grounding** important before hands-on optimization in a workshop?\\n2. What are the three constraints in the **speed\u2013accuracy\u2013cost** triangle, and why do they conflict?\\n3. What are the minimum components of an **eval-driven optimization loop**?\\n4. When would you choose **meta-prompting** vs **genetic optimization** vs **reflective/HRPO**?\\n5. Why can **Levenshtein ratio** be misleading for semantic tasks, and what should you use instead?\\n6. What does it mean to **chain optimizers**, and what reminder should guide the order (instructions \u2192 examples \u2192 parameters)?\\n7. Why are **validation/holdout sets** necessary during prompt optimization?\\n8. What operational checklist items should be validated before running a live interactive workshop?\\n\\n---\\n\\n## Suggested Further Reading / Resources\\n\\n- **Facilitation & workshop design**\\n  - Atlassian Team Playbook (facilitation patterns and team rituals): https://www.atlassian.com/team-playbook\\n- **Evals and LLM testing**\\n  - OpenAI Evals (conceptual reference): https://github.com/openai/evals\\n  - LangChain evaluation guides: https://python.langchain.com/docs/guides/evaluation/\\n- **Agent systems and tool use**\\n  - OpenAI documentation (agents/tooling concepts): https://platform.openai.com/docs/\\n  - Anthropic documentation (tool use and agent patterns): https://docs.anthropic.com/\\n  - LangChain agent patterns and evaluation tooling: https://python.langchain.com/docs/\\n- **RAG learning resources**\\n  - Pinecone RAG guides: https://www.pinecone.io/learn/\\n  - Weaviate RAG resources: https://weaviate.io/developers/weaviate\\n- **Experiment tracking**\\n  - Comet platform: https://www.comet.com/"},{"id":"opik-workshop-1","metadata":{"permalink":"/fr/blog/opik-workshop-1","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-14-OPIK-workshop.mdx","source":"@site/blog/2026-01-14-OPIK-workshop.mdx","title":"OPIK : AI Evaluation and Observability","description":"This lecture, led by Abby Morgan, an AI Research Engineer, introduces AI evaluation as a systematic feedback loop for transitioning prototypes to production-ready systems. It outlines the four key components of a useful evaluation: a target capability, a test set, a scoring method, and decision rules. The session differentiates between general benchmarks and specific product evaluations, emphasizing the need for observability in agent evaluation. It demonstrates using OPIK, an open-source tool, to track, debug, and evaluate LLM agents through features like traces, spans, \'LM as a judge\', and regression testing datasets.","date":"2026-01-14T00:00:00.000Z","tags":[{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"Observability","permalink":"/fr/blog/tags/observability","description":"Articles on observability practices and tools"}],"readingTime":17.25,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"opik-workshop-1","title":"OPIK : AI Evaluation and Observability","authors":["jnxmas"],"tags":["ai-ml","civictech","encode","observability"]},"unlisted":false,"prevItem":{"title":"OPIK : Agent & Prompt Optimization for LLM Systems","permalink":"/fr/blog/opik-workshop-2"},"nextItem":{"title":"Project scope - Victor + JNS","permalink":"/fr/blog/victor-intro-project-description"}},"content":"This lecture, led by Abby Morgan, an AI Research Engineer, introduces AI evaluation as a systematic feedback loop for transitioning prototypes to production-ready systems. It outlines the four key components of a useful evaluation: a target capability, a test set, a scoring method, and decision rules. The session differentiates between general benchmarks and specific product evaluations, emphasizing the need for observability in agent evaluation. It demonstrates using OPIK, an open-source tool, to track, debug, and evaluate LLM agents through features like traces, spans, \'LM as a judge\', and regression testing datasets.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Takeaways\\n\\n1.  Introduction to Abby Morgan, an AI Research Engineer and Developer Advocate at Comet.\\n2.  Housekeeping rules for the hackathon: use the public Discord channel for specific questions to ensure fairness and help others.\\n3.  Recap of the previous session on AI evaluations: they turn prototypes into production-ready systems.\\n4.  Evaluation is the feedback loop that enables systematic improvement, turning guesswork into a scientific process.\\n5.  Evaluations help in making decisions (ship or roll back), debugging failures, and building trustworthy systems.\\n6.  An evaluation is defined as a structured, repeatable measurement of system behavior against specific criteria.\\n7.  Four key ingredients of a useful evaluation: a target capability, a test set reflecting the relevant world, a scoring method, and decision rules.\\n8.  Evaluation outputs are not just numbers; they can include concrete examples, categorical slices, and error taxonomies.\\n9.  Distinction between benchmarks and product evaluations: Benchmarks are for broad comparisons, while product evals are specific to your use case, tools, and workflows.\\n10. The importance of observability in evaluating agents: the full trace (context, prompts, tool calls) is crucial as agents don\'t fail like traditional software.\\n\\n<iframe\\n  width=\\"100%\\"\\n  style={{ \\"aspect-ratio\\": \\"16 / 9\\" }}\\n  src=\\"https://www.encodeclub.com/programmes/comet-resolution-v2-hackathon/events/intro-to-opik\\"\\n  title=\\"OPIK workshop 1\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\"\\n  referrerpolicy=\\"strict-origin-when-cross-origin\\"\\n  allowfullscreen\\n></iframe>\\n\\n## Highlights\\n\\n- `\\"Evaluation is essentially just the feedback loop that makes improvement thematic.\\"-- Annie Morgan`\\n- `\\"Evals are what turn random iteration or guesswork into more of a scientific process that allows you to improve in a systematic way.\\"-- Annie Morgan`\\n\\n## Chapters & Topics\\n\\n### The Role and Definition of AI Evaluation\\n\\n> An evaluation is a structured, repeatable measurement of system behavior against criteria we care about. This structured approach is key to distinguishing a true evaluation from a mere product demo, as it must be consistently runnable over time to interpret changes.\\n\\n- **Keypoints**\\n  - Evaluation turns a prototype into a production-ready system.\\n  - It provides a feedback loop for systematic improvement.\\n  - It helps make decisions like shipping or rolling back features.\\n  - An evaluation must be structured and repeatable.\\n  - It\'s the difference between a product demo and a scientific process.\\n  - It helps build systems that people can trust in the real world.\\n- **Explanation**\\n  The process of evaluation is what transforms a cool but unreliable prototype into something that can be confidently shipped and iterated upon in a real-world production environment. It provides the necessary feedback loop to make improvements systematic rather than random. It helps decide whether to ship new features, roll back changes, debug failures, and ultimately, build systems that users can trust. Without a structured evaluation process, it\'s difficult to know if a system is actually improving or if observed successes are just cherry-picked examples or irrelevant outliers.\\n\\n### Four Ingredients of a Useful Evaluation\\n\\n> Most useful evaluations are composed of four essential ingredients: a target capability, a test set, a scoring method, and decision rules.\\n\\n- **Keypoints**\\n  - A target capability (e.g., fluency, relevance, toxicity).\\n  - A test set that reflects the specific world and edge cases you care about.\\n  - A scoring method, which can be human annotation or an automated metric.\\n  - Decision rules that dictate actions based on the evaluation scores (e.g., ship, roll back).\\n- **Explanation**\\n  To create a useful evaluation, you need four components. First, a \'target capability\' which could be things like fluency, relevance, or toxicity. Second, a \'test set\' that accurately reflects the real-world scenarios you care about, including edge cases. This is where product evals differ from general benchmarks. Third, a \'scoring method\', which can be either human annotation or an automated metric. Finally, \'decision rules\' which define what actions to take based on the evaluation scores, such as deploying a new feature or rolling it back.\\n\\n### Benchmarks vs. Product Evals\\n\\n> Benchmarks are standardized evaluations for broad comparisons across a wide range of use cases, whereas product evaluations are tailored to a specific use case, including its unique tools and workflows. Benchmarks are helpful for general comparisons, but are not a substitute for product-specific evaluations.\\n\\n- **Keypoints**\\n  - Benchmarks are standardized and cover a wide range of use cases.\\n  - Product evals are specific to your use case, tools, and workflows.\\n  - Benchmarks are for broader comparisons.\\n  - Product evals are for seriously evaluating your system for its specific purpose.\\n  - Product evals should use a test set that reflects the particular world you care about, including edge cases.\\n- **Explanation**\\n  While the term \'benchmark\' is often used in AI evals, it\'s important to distinguish it from a \'product eval\'. Benchmarks are generalized and standardized, designed to test a wide range of examples and use cases. They are useful for broader comparisons. On the other hand, a product evaluation is specific to your product\'s use case. It should use a test set that reflects the world you care about, including specific edge cases, and incorporate your particular tools and workflows. For serious evaluation of your own system\'s performance for its intended purpose, a product-specific eval is necessary.\\n\\n### Observability as the Foundation for Agent Evaluation\\n\\n> For AI agents, observability is the foundation of evaluation. Since agents don\'t fail like traditional software, it\'s crucial to look beyond the final output and observe the full trace of their operation. This includes the context retrieved, prompts used, tools called, and all intermediate steps. This observation is the first step in a cycle of improvement: observe, understand, evaluate, and then improve.\\n\\n- **Keypoints**\\n  - The final output of an agent is never the full story.\\n  - Observing the full trace is critical for evaluation.\\n  - The trace includes retrieved context, prompts, tool calls, and intermediate steps.\\n  - Agents do not fail like traditional software, so observation is key.\\n  - The improvement cycle is: observe -&gt; understand -&gt; evaluate -&gt; improve.\\n  - OPIK is designed to make observability and evaluation practical and simple.\\n- **Explanation**\\n  Evaluating agents requires starting with observability because their final output alone doesn\'t tell the whole story. Unlike traditional software, an agent\'s failure or success is determined by a complex series of steps. Therefore, you must be able to see the full trace of its actions. This includes what context was retrieved, what prompts were generated and used, which tools were called, and all the intermediate results. Once you can observe this entire process, you can begin to understand what is happening. With understanding, you can then evaluate the agent\'s performance against your criteria. Finally, with these evaluations and measurements of success, you can systematically begin to improve the agent. OPIC is a tool specifically designed to facilitate this process by making observability and evaluation practical and easy.\\n\\n### Integrating OPIK into Your Code\\n\\n> OPIK is an observability tool that can be easily integrated into your code to track, monitor, and evaluate the performance of LLM agents. It requires minimal code, often just one to three lines, to start logging agent interactions. The integration method might vary slightly depending on whether you\'re using a direct integration like with OpenAI Agents or a more general method like the track decorator.\\n\\n- **Keypoints**\\n  - Import OPIK at the top of your file.\\n  - Integration can be as simple as one to three lines of code.\\n  - Direct integrations, like with OpenAI Agents, might have a specific syntax.\\n  - The \'@track\' decorator is another common method for integration.\\n- **Explanation**\\n  To integrate OPIK, you first import it at the top of your script. Then, depending on the framework, you might use a specific call like the one shown for OpenAI Agents, or use a track decorator. For the demonstrated recipe generator agent, which uses OpenAI Agents, the integration was slightly different but still very simple. This minimal setup allows OPIK to automatically capture detailed information about each agent run.\\n- **Examples**\\n  > A basic agent acting as a recipe generator. The user provides a list of ingredients, and the agent performs two LLM calls. The first LLM call suggests a recipe based on the ingredients (e.g., creamy orange tomato soup from tomatoes, cream, and oranges). The second LLM call researches the steps to create that specific recipe.\\n  - The user runs the script and is prompted for ingredients.\\n  - The user enters \'tomatoes, cream, oranges\'.\\n  - The first LLM processes these ingredients and suggests \'creamy orange tomato soup\'.\\n  - This recipe name is then passed to the second LLM.\\n  - The second LLM researches and outputs the detailed steps for making the soup.\\n  - All of this activity is logged as a single trace in the OPIC dashboard.\\n\\n### Understanding Traces and Spans\\n\\n> OPIC organizes logged data into traces and spans. A trace represents a single, complete end-to-end process or execution of your agent. A span is a smaller, individual step or operation within that trace. This hierarchical structure allows for both a high-level overview and a granular look at each component of the agent\'s execution, which is crucial for debugging and evaluation.\\n\\n- **Keypoints**\\n  - A trace is the entire end-to-end agentic call.\\n  - A span is an individual step within the trace.\\n  - The dashboard allows you to view the overall trace and drill down into individual spans.\\n  - This structure helps isolate where failures or issues occur in a complex agent.\\n- **Explanation**\\n  When an agent runs, the entire operation is captured as one trace. Within this trace, you can see individual spans corresponding to specific actions, like LLM calls or tool usage. The OPIC dashboard clearly displays the input and output for the entire agent call (the trace) and for each individual step (the spans). This helps identify exactly where in the process a failure or unexpected behavior occurs. For example, if an agent fails, you can inspect the spans leading up to the failure to understand the root cause.\\n- **Examples**\\n  > In the recipe generator agent, the entire process from taking user ingredients to outputting a full recipe is one trace. Within that trace, the first LLM call (suggesting \'chicken parmesan\') is one span, and the second LLM call (researching how to make it) is another span.\\n  - User interacts with the agent, triggering a run. This entire run is a \'trace\'.\\n  - The agent calls the first LLM to generate a recipe idea. This call is a \'span\'.\\n  - The agent then calls the second LLM to get the recipe steps. This second call is another \'span\'.\\n  - The dashboard shows the full trace and allows clicking into it to see the individual spans, each with its own inputs, outputs, and metadata.\\n\\n### Online Evaluations and \'LM as a Judge\'\\n\\n> OPIC allows for creating online evaluations that automatically score agent performance against predefined criteria every time an agent runs. A key feature is \'LM as a judge,\' where one LLM is used to evaluate the output of your agent\'s LLM based on a custom prompt and scoring scale you provide. This enables automated, qualitative assessment of agent outputs.\\n\\n- **Keypoints**\\n  - Online evaluations automatically score agent calls based on created rules.\\n  - \'LM as a judge\' uses an external LLM to evaluate your agent\'s output.\\n  - You must provide a detailed prompt to guide the judge LLM.\\n  - Users can manually annotate traces with their own scores to calibrate the \'LM as a judge\' evaluator.\\n  - You can compare human scores with LLM-generated scores to improve the evaluation prompt.\\n- **Explanation**\\n  To set up an online evaluation, you navigate to the \'Online Evaluation\' section in the OPIC dashboard and create a new rule. You name the rule, provide API keys for the external judging LLM (e.g., from OpenAI, Anthropic, or OpenRouter), and select the model. You then write a detailed prompt that instructs the judge LLM on how to score the output, including the context, scoring scale, and criteria. Once the rule is created, every new trace will be automatically scored against this metric, and the scores will appear in your trace list.\\n- **Examples**\\n  > For the recipe agent, three \'LM as a judge\' evaluation metrics were created to assess the generated recipes. The user set up a rule by providing a prompt to a judge LLM, defining a scoring scale and the context for what constitutes a good recipe suggestion. After setup, every time the recipe agent ran, it was automatically scored by these metrics.\\n  - Go to \'Online Evaluation\' and click \'Create New Rule\'.\\n  - Name the rule (e.g., \'Recipe Coherence\').\\n  - Choose a provider and model for the judge LLM (e.g., OpenAI\'s GPT-4).\\n  - Write a prompt for the judge: \'You are an evaluator. Rate the following recipe on a scale of 1-5 for coherence...\'\\n  - Save the rule. Now, all subsequent runs of the recipe agent will have a \'Recipe Coherence\' score.\\n  - You can then go into a trace and manually add a human score to compare against the \'LM as a judge\' score, which helps in refining the evaluation prompt.\\n- **Considerations**\\n- It\'s good practice to use a healthy mix of heuristic evaluation metrics and \'LLM as a judge\' metrics.\\n- You may need to iterate on the prompt given to the judging LLM to ensure its evaluations align with your definition of success.\\n- Using one LLM to judge another can be problematic, so human oversight and comparison are valuable.\\n- **Special Circumstances**\\n- If you suspect the \'LM as a judge\' is providing inaccurate scores, you should go into the traces, manually score them yourself, and compare your scores to the AI\'s. Based on the discrepancies, you can tweak the prompt given to the judge LLM to make its ratings more closely aligned with human judgment.\\n\\n### Managing and Testing with Problematic Samples\\n\\n> OPIC provides features to isolate problematic agent runs and use them for regression testing. When an agent produces an error or an undesirable output, you can select these \'problematic samples\' from your traces and add them to a named dataset. This dataset can then be used to repeatedly test your agent after making code changes, ensuring that your fixes are effective and don\'t introduce new issues.\\n\\n- **Keypoints**\\n  - Isolate traces where the agent fails or performs poorly.\\n  - Select these problematic samples in the dashboard.\\n  - Add them to a new or existing dataset.\\n  - Use this dataset to run regression tests on your agent after making code changes.\\n  - This helps verify that improvements are effective and don\'t cause regressions.\\n- **Explanation**\\n  To do this, you would go through your list of traces in the OPIC dashboard. You can filter or sort by low evaluation scores or errors to find the problematic runs. Select the checkboxes next to these traces. Then, use the option to \'add to a dataset\'. You can create a new dataset (e.g., \'problematic samples\') or add to an existing one. Later, when you\'ve modified your agent\'s code, you can run the agent specifically against the inputs from this dataset to see if the outputs have improved.\\n\\n### Getting Started with OPIC and Basic Tracing\\n\\n> OPIC (Open-Source Project for Instrumenting and Correcting AI) is an open-source tool for LLM observability. It can be self-hosted locally for free, providing high customization, or used via a 100% free cloud tier for quick setup. The demonstration and initial setup guide focus on the free cloud tier.\\n\\n- **Keypoints**\\n  - OPIC is 100% open source and offers a 100% free cloud tier.\\n  - Setup involves installing the package and configuring it with an API key and workspace.\\n  - The \'@track\' decorator is the simplest way to add tracing to any Python function.\\n  - Direct integrations for frameworks like OpenAI provide deeper observability by wrapping the client object.\\n- **Explanation**\\n  To get started with the free cloud tier, first install OPIC using \'pip install opic\'. Then, configure your account by running \'open configure\'. This command will prompt you for your API key, which can be found in your Comet account settings. You will also confirm the workspace you want to use. You can also set these as environment variables to avoid entering them manually each time. A project name can be specified using a code snippet provided in the quick start guide.\\n- **Examples**\\n  > A simple \'Hello World\' trace example can be created using the \'@track\' decorator from OPIC. You import \'track\' from OPIC and place the decorator above the definition of the function you want to monitor, such as an LLM call. This allows you to track the function\'s execution without rewriting your code. Every time the decorated function is run, it will automatically log to Comet, and a link to view the trace will be provided in the output.\\n  - Import the \'track\' decorator: `from opic import track`\\n  - Place the decorator above your function definition: `@track\\ndef my_function(): ...`\\n- Run the function. It will automatically log its execution, inputs, and outputs to OPIC.\\n  > OPIC offers direct integrations with popular frameworks like OpenAI. Instead of using the \'@track\' decorator, you import the specific integration module (e.g., `opic.integrations.openai`). Then, you wrap your framework client (e.g., the OpenAI client) in an OPIC track function. This provides deep observability into all system metrics and information from the LLM call with just one or two lines of code.\\n- Import the integration: `import opic.integrations.openai`\\n- Instantiate your original client: `client = OpenAI()`\\n- Wrap the client with the OPIC function: `client = opic.integrations.openai.patch(client)`\\n- Now, all calls made using this `client` object will be automatically tracked.\\n\\n### Debugging and Evaluation with OPIC\\n\\n> OPIC provides visibility into an agent\'s execution flow, helping users debug errors and identify areas for improvement. It allows you to see exactly which step in a multi-step agent failed, avoiding the need to manually sift through code or error traces.\\n\\n- **Keypoints**\\n  - OPIC\'s trace visualization helps pinpoint the exact step where an error occurred in an agent.\\n  - This reduces debugging time by narrowing the search space from the entire codebase to a specific component (e.g., one LLM call).\\n  - Automatic evaluation metrics can be set up to flag issues like toxicity that are hard to catch manually.\\n  - The UI allows filtering the entire dataset based on evaluation flags, aggregating all relevant examples for analysis.\\n- **Explanation**\\n  When an agent call fails, OPIC\'s trace view shows the sequence of operations (e.g., LLM calls, tool calls). If a step fails, the trace stops there. For example, if an agent fails at the \'recipe suggester\' step, you know the problem lies within that specific LLM call. This narrows down the debugging scope significantly. For more subtle issues, you can create evaluation metrics for things like toxicity. These metrics can automatically flag problematic runs, which you can then filter and analyze in the OPIC UI. This makes it much easier to consume a lot of information quickly and distill it down to find where things are going wrong, why, and how to fix them.\\n\\n### Managing Evaluation Datasets and Metrics\\n\\n> To maintain a relevant dataset for evaluations as an application evolves, OPIC allows for dynamic management of evaluation datasets. It is also highly recommended to use a combination of evaluation methods rather than relying on a single one.\\n\\n- **Keypoints**\\n  - Evaluation datasets in OPIC can be dynamically updated by adding or removing traces.\\n  - If a dataset becomes irrelevant due to application changes, you can edit it or create a new one from scratch.\\n  - It is recommended to use multiple evaluation metrics, such as combining heuristic logic with an LLM-as-a-judge, for more robust evaluation.\\n  - Users are not limited to one evaluation dataset and can maintain several for different testing scenarios.\\n- **Explanation**\\n  As your application changes (e.g., tool call names, parameters), some traces in your evaluation dataset may become obsolete. In the OPIC UI, you can easily remove irrelevant traces from an existing dataset. You can also add new, more relevant traces. If a dataset has largely lost its relevance, you can create a completely new one from scratch. Users are not limited to a single evaluation dataset and can have dozens for different purposes. For the evaluation itself, you can and should use multiple metrics. For example, you can evaluate a model using a combination of heuristic logic and an LLM-as-a-judge.\\n\\n## Assignments & Suggestions\\n\\n- Include the source code file (like a cursor) or basic setup steps in your final submission if you use AI tools like n8n, so judges can confirm the project works as intended.\\n- For detailed or \'deep divey\' questions about OPIC, post them on the Discord server for a more thorough answer.\\n- For questions about specific SDKs and the functional differences between various OPIC integration methods, post them on Discord."},{"id":"victor-intro-project-description","metadata":{"permalink":"/fr/blog/victor-intro-project-description","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-14-meeting.md","source":"@site/blog/2026-01-14-meeting.md","title":"Project scope - Victor + JNS","description":"Location: Discord voice chat","date":"2026-01-14T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"}],"readingTime":9.08,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"victor-intro-project-description","title":"Project scope - Victor + JNS","authors":["jnxmas"],"tags":["meeting"]},"unlisted":false,"prevItem":{"title":"OPIK : AI Evaluation and Observability","permalink":"/fr/blog/opik-workshop-1"},"nextItem":{"title":"Hackathon kickoff meeting","permalink":"/fr/blog/encode-kickoff"}},"content":"> Location: Discord voice chat\\n> Attendees: jnxmas, Victor\\n\\n## Overview\\n\\nThis document summarizes a series of project meetings focused on building a community-focused AI application for a local election. The discussions cover team composition and recruitment, defining the project\'s scope for a hackathon, and outlining the technical architecture. Key activities include automating the processing of community contributions, developing a neutral chatbot to compare political programs, and initiating web crawling operations to gather data. The plan involves using technologies like Firecrawl, N8N, Pydantic, and a Retrieval-Augmented Generation (RAG) system, with a strong emphasis on collaborative development practices via GitHub.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Key Topics\\n\\n- Two new potential members from Audierne, France, were identified. They are developers focused on websites but are new to AI and Python, so they are considered to be starting from scratch.\\n- Their primary value is their familiarity with the local context of the project (audierne2026), making them a potential bridge to the local population. They are seen as good candidates for an \\"observer\\" role within the hackathon.\\n- They are connected to one of four local political lists, which is interested in participative community movements.\\n- An Indian developer named Satish, with whom a speaker previously worked on an AWS and Next.js project in a 2023 hackathon, is a potential collaborator. However, he is currently cautious about joining due to being busy with his job.\\n- A French individual named Max, who specializes in SEO and social media strategy, was mentioned but is not a coder.\\n- An Indian machine learning specialist, referred to as \\"Meher,\\" is considering joining. He is seen as a key \\"third guy\\" ML for the application architecture.\\n- There was a concern that the project\'s connection to a local election might disqualify it from the hackathon.\\n- A team member named Rebecca clarified in a general chat that the project is eligible to be submitted under the \\"social community impact\\" category.\\n- The team was advised that all questions should be posted in the general chat, as Rebecca will not be replying to DMs.\\n- Progress has been made on the project\'s GitHub Kanban board, with P0 tasks and some unprioritized tickets added.\\n- The data crawling phase (\\"filecrawl\\") is ready to start with an initial dataset of 150 links and 4,000 PDFs that require OCR. The speaker has paused this work to incorporate more contributions.\\n- The N8N orchestration workflow is nearly complete and ready for deployment.\\n  - It will be hosted on a server with a 6-core CPU and 16 gigabytes of RAM.\\n  - The team will consider moving to Vercel if the server cannot handle the load.\\n- N8N is a low-code/no-code platform for building workflows, and an example was shown for automating posts based on GitHub repository issues.\\n- The setup is encapsulated in Docker, making it easier to run.\\n- The project\'s code and tasks will be managed in the Ocapistan repository on GitHub.\\n- A key initial task is to push the ideation file (`ideation 13.1.2026`) to the main branch to serve as a foundation for future work.\\n- The team will use a feature branch workflow:\\n  - For each task, a developer will create a new feature branch from the main branch.\\n  - Once the task is complete, the branch will be pushed to the repository for review by others.\\n  - After review and debugging, the branch will be merged and closed.\\n- The team agreed to prioritize the Firecrawl operation as the starting point, despite its potential difficulty.\\n- Two team members will conduct parallel trials on different fire crawling tasks to gain experience and share learnings.\\n- Each member should get their own free Firecrawl API key, as they may need to use multiple free accounts by registering with different emails to maximize free API calls.\\n- The initial scraping task will target a list of PDFs from a specific URL (`script marie arete mary`).\\n- PDF processing will require testing various libraries like `pdf2ocr`, Tabula, and `pypdf` to find the most effective one.\\n- The team needs to develop a method to identify and set aside documents that only contain signatures, as this information has no value for the LLM.\\n- The project will use Python with type hinting and Pydantic for data handling to improve code quality.\\n- A modular \\"separation of concerns\\" approach will be used for the ETL (Extract, Transform, Load) process.\\n  - Extraction, transformation, and loading will be handled by separate workflows, likely implemented as three distinct classes.\\n  - This modularity will allow for different extraction methods (e.g., for plain text, HTML with Beautiful Soup, or OCR for PDFs) to be developed and called as needed.\\n- The project will use Ocapistan for code management, N8N for workflows, and a flexible AI provider handled by OPIC.\\n- Team members do not need to work at the same time but must communicate effectively. Progress will be tracked through changes in the project repository.\\n- Developers should assign tasks to themselves and break them down into smaller sub-tasks.\\n- Direct discussions will be necessary when merging work on the same files to resolve conflicts.\\n- **Current Process (Manual):**\\n  - Contributions are received via email.\\n  - They are manually reviewed against a \\"chart of contribution\\" to ensure they meet the criteria.\\n  - If approved, they are manually copy-pasted into a GitHub issue.\\n  - A daily summary of contributions is automatically posted to Facebook via M8N, but this post is anonymous and lacks detail.\\n- **Proposed Automated Process:**\\n  - The goal is to automate the entire workflow from email receipt to GitHub issue creation.\\n  - An AI agent will be developed to judge whether an incoming contribution respects the \\"chart of contribution.\\"\\n  - This agent will be part of the \\"OKAPI stand,\\" which will house all agents and the RAG system for the project.\\n- **Purpose:** After a contribution is validated and becomes a GitHub issue, a \\"creative agent\\" (also called the Okapi Sten proper) will process it.\\n- **Functionality:**\\n  - The agent generates an AI-made reply that contextualizes the new contribution.\\n  - It cross-references the submission with previous contributions in the same category to find echoes and avoid repetition.\\n  - The reply includes links to the sources used to construct the contextualization.\\n- **Handling New vs. Existing Topics:**\\n  - The workflow must handle two cases: when a contribution is for a brand-new category, and when it relates to a previously discussed topic.\\n  - In the latter case, the system will search existing issues and the RAG system to build a comprehensive answer.\\n- **LLM Testing:**\\n  - Grok has been used for initial testing. It was effective at searching for context online (including the audierne2026 project) and generating relevant, though coincidental, replies.\\n  - The team discussed that Grok\'s ability to search and synthesize information acts similarly to a basic RAG system.\\n- **RAG System Development:**\\n  - A dedicated RAG (Retrieval-Augmented Generation) system will be built to avoid repetitive outputs and manage context efficiently.\\n  - The team needs to decide how to store source links and other data for the RAG system, considering a NoSQL database like MongoDB for flexibility. A vector store will be used for training on gathered data.\\n- **Key Dates:**\\n  - The election preparation period is currently underway.\\n  - Contribution collection will continue until at least January 31.\\n  - The election day is around March 15-22.\\n- **February Focus:**\\n  - Work in February will focus purely on developing the chatbot.\\n  - The chatbot will be used to compare the programs of the four enlisted municipal lists.\\n  - It will be designed to provide neutral, impartial comparisons on topics like lodging, culture, and budget realism.\\n- **Using OPIK:**\\n  - The OPIK framework will be used to evaluate every AI interaction to ensure quality and impartiality.\\n  - The team is considering creating a feedback loop where OPIK\'s evaluations could automatically improve the prompts in N8N.\\n- **Maintaining Neutrality:**\\n  - A major challenge is ensuring the chatbot remains neutral and does not generate sycophantic or biased responses based on leading questions from users.\\n  - The system may need multiple prompts to check for constraints like budget, realism, and political neutrality before generating a reply.\\n\\n## Open Issues & Risks\\n\\n- It is unclear how the new team members from Audierne, who have limited technical experience in AI, will be integrated into the project.\\n- The availability of a key potential collaborator, Satish, is uncertain due to his current work commitments.\\n- The machine learning specialist, Meher has not yet confirmed if he will join the team.\\n- It is undecided how to best store source links and data for the RAG system, though a NoSQL database is being considered.\\n- It is unclear which LLMs (e.g., Gemini) will be chosen for the final implementation.\\n- A key challenge will be designing the chatbot to remain neutral and avoid generating biased responses to leading questions.\\n- The project\'s success depends on receiving a sufficient number of community contributions, which requires incentivizing and motivating people to participate.\\n\\n## Action Items\\n\\n- [x] Prioritize project tasks.\\n- [x] Set up a server for the Vaettir repo so the team can access it with a password.\\n- [x] Start by building workflows, with more coding to begin next week.\\n- [x] Set up an ollama platform to experiment with local LLMs.\\n- [x] Push the `ideation 13.1.2026` file to the main Ocapistaine repository.\\n- [x] Each team member to get a free Firecrawl API key.\\n- [x] Begin experimenting with Firecrawl by creating a new branch on the Ocapistaine repository.\\n- [ ] Start working on scraping the documents from the \\"script marie arret\xe9 maririe\\" task.\\n- [ ] Test different PDF reading libraries (`pdf2ocr`, Tabula, `pypdf`) to determine the best option for the project.\\n\\n> **AI Suggestion**\\n> AI has identified the following issues that were not concluded in the meeting or lack clear action items; please pay attention:\\n>\\n> 1. **Critical Staffing and Team Formation Risk:** The project faces a significant risk of stalling due to unresolved team composition. Two key experts, developer Satish and machine learning specialist \\"Mayer,\\" have not committed to the project, leaving critical skill gaps. A clear action plan is needed to secure their participation or find qualified alternatives immediately to ensure the project can proceed.\\n> 2. **Unresolved Core Chatbot Neutrality:** A fundamental and unresolved challenge is how to technically implement and guarantee the election chatbot\'s neutrality and impartiality. There is no defined strategy for preventing the AI from giving biased responses, especially when faced with leading or manipulative user questions, which poses a major reputational and functional risk to the project\'s core objective.\\n> 3. **Lack of a Defined Community Contribution Workflow:** The entire process for receiving, validating, and integrating community-submitted content is undefined. This includes the creation of an AI agent to automate judging submissions and a clear workflow for handling both new and existing topics. Without this, the project cannot scale or effectively leverage community input, which is stated as a dependency for success.\\n> 4. **Undefined Technical Foundation for Data Processing and Storage:** Key decisions about the project\'s technical architecture are still pending. The team has not selected a database for the RAG system (e.g., NoSQL/MongoDB) or the specific Large Language Models (LLMs) for the final implementation. Furthermore, the method for processing varied document types like PDFs remains uncertain. These foundational decisions must be made to avoid delays in development."},{"id":"encode-kickoff","metadata":{"permalink":"/fr/blog/encode-kickoff","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-13-encode_hackathon.md","source":"@site/blog/2026-01-13-encode_hackathon.md","title":"Hackathon kickoff meeting","description":"Date & Time04:06","date":"2026-01-13T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"}],"readingTime":16.75,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"encode-kickoff","title":"Hackathon kickoff meeting","authors":["jnxmas"],"tags":["meeting"]},"unlisted":false,"prevItem":{"title":"Project scope - Victor + JNS","permalink":"/fr/blog/victor-intro-project-description"},"nextItem":{"title":"Locki Labs in 2025 - Introducing Valkyria","permalink":"/fr/blog/locki-in-2025"}},"content":"> Date & Time: 2026-01-13 19:04:06\\n> Location: online presentation\\n> `AI Agent Hackathon` `New Year\'s Resolutions` `AI Evaluation`\\n\\n## Theme\\n\\nThis lecture introduces the \\"Commit to Change AI Agent Hackathon,\\" a four-week online event challenging participants to build AI agents that help users stick to their New Year\'s resolutions. The event offers $30,000 in prizes across five tracks: Productivity, Personal Growth, Social Impact, Health/Wellness, and Financial Health. It emphasizes the importance of AI evaluations, defining them as structured measurements of system behavior. The lecture details the hackathon\'s timeline, submission requirements using the ENCODE platform, and the mandatory use of the OPIC tool for evaluation, guiding participants from ideation to final project submission.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Takeaways\\n\\n1.  Introduction to the Commit to Change AI Agent Hackathon.\\n2.  The hackathon\'s goal is to build AI that turns New Year\'s resolutions into real results.\\n3.  Hackathon registration is required on the Encode Cloud platform for all participants, including those from Luma.\\n4.  The hackathon is sponsored by Comet, with supporting partners Basel and Google DeepMind.\\n5.  This is a four-week online hackathon with up to $30,000 in prizes.\\n6.  Statistics on New Year\'s resolutions: 23% give up within 13 days, and 43% give up by the end of January.\\n7.  Hackathon advice: Start with a problem you have faced and build a unique solution.\\n8.  The hackathon features five thematic tracks: Productivity and Work Habits, Personal Growth and Learning, Social and Community Impact, Health, Fitness and Wellness, and Financial Health.\\n9.  It\'s recommended to focus on one category to create a high-quality, specialized app.\\n10. There is an overall challenge for the \'Best use of OPIC\' for projects showcasing excellent evaluation and observability.\\n\\n## Highlights\\n\\n- `\\"AI evals are what turn that sort of really cool, fun prototype into a system that you can actually iterate on with confidence and start to think about exposing to the real world and to real people.\\"-- Abby`\\n- `\\"What\'s even cooler than a really cool prototype is, in my opinion, a cool tool that you can actually use in the real world on real data. And for that, you need some sort of system of evaluations.\\"-- Abby`\\n- `\\"Evaluation turns guesswork into science.\\"-- Abby`\\n- `\\"AI evaluations are how we turn random iteration into progress, and they give us a repeatable way to measure behavior, compare changes, and improve systematically instead of guessing.\\"-- Abby`\\n\\n## Chapters & Topics\\n\\n### Hackathon Overview and Goal\\n\\n> The Commit to Change AI Agent Hackathon is a four-week online event starting in January 2026, aimed at building AI agents and LLM-powered apps that help people stick to their New Year\'s resolutions and goals. It offers up to $30,000 in prizes.\\n\\n- **Keypoints**\\n  - The hackathon runs for four weeks online.\\n  - The goal is to build AI/LLM apps to help users stick to their goals.\\n  - There\'s a prize pool of up to $30,000.\\n  - It is sponsored by Comet, with support from Basel and Google DeepMind.\\n  - Participants must register on the Encode Cloud platform to get all updates and access resources.\\n- **Explanation**\\n  The hackathon is structured to guide participants from ideation to final submission. It includes workshops, deadlines to ensure progress, and resources provided by sponsors like Comet and partners like Google DeepMind. The central theme is leveraging AI to address the common problem of people giving up on their resolutions. Statistics show 23% of people give up 13 days into January, and 43% give up by the end of the month, highlighting the target audience for the projects.\\n\\n### Hackathon Tracks and Challenges\\n\\n> The hackathon is structured around five thematic tracks for projects, plus an overall challenge. The tracks are: Productivity and Work Habits, Personal Growth and Learning, Social and Community Impact, Health, Fitness and Wellness, and Financial Health. The overall challenge is for the \'Best Use of OPIC\', rewarding projects with excellent evaluation and observability.\\n\\n- **Keypoints**\\n  - Productivity and Work Habits: Build tools for smarter work and better routines.\\n  - Personal Growth and Learning: Build apps for learning new skills or developing self-awareness.\\n  - Social and Community Impact: Build tools for organizing communities or supporting environmental/social action.\\n  - Health, Fitness and Wellness: Build solutions for fitness, mental health, or general well-being.\\n  - Financial Health: Build AI/LLM apps for budgeting, saving, or understanding money.\\n  - Best Use of OPIC: A special category for projects with excellent evaluation and observability.\\n- **Explanation**\\n  Participants should choose one of the five themes to focus their project on. The themes are broad to accommodate a wide range of ideas. The \'Health, Fitness and Wellness\' category is noted as a particularly common area for New Year\'s resolutions. In addition to the thematic challenges, all projects are eligible for the \'Best Use of OPIC\' challenge, sponsored by Comet. This special prize can be won in conjunction with a thematic prize.\\n- **Considerations**\\n- Focus on one category rather than trying to build an app that spans multiple, as an app that does one thing well is better than one that does four things less well.\\n- Start with a problem that you yourself have faced to understand it well.\\n- Come up with a solution that sets you apart from everyone else; build something interesting and unique.\\n- Don\'t just do the bare minimum base idea; build on top of it.\\n- The best use of OPIC category can be won alongside a theme prize, which is the only two-in-one win possible.\\n\\n### Hackathon Timeline and Submission Requirements\\n\\n> The hackathon has a structured timeline with key deadlines and specific submission requirements for the final project. The timeline spans four weeks, starting with ideation, moving to building, and culminating in a final submission.\\n\\n- **Keypoints**\\n  - Week 1: Ideation and Project Creation Deadline.\\n  - Week 2: Building and a workshop on Gemini 3.\\n  - Week 2/3: Mid-hackathon Deadline (submit GitHub repo and description).\\n  - Final Submission Deadline: February 8th, 23:59 UTC-12.\\n  - Required final submission items: Video pitch with demo and public code base.\\n  - Recommended submission items: Hosted site and a presentation.\\n  - The mid-hackathon deadline forces early and regular code commits.\\n- **Explanation**\\n  The timeline is designed to keep participants on track.\\n\\n- Week 1: Launch, ideation, and a \'Project Creation Deadline\' to commit to an idea and team.\\n- Week 2: Start building, with a workshop from Google DeepMind on Gemini 3.\\n- End of Week 2/Start of Week 3: \'Mid-hackathon Deadline\' requiring submission of a GitHub repo and project description. This is not judged but ensures progress.\\n- Final Submission Deadline: February 8th at one minute to midnight, UTC-12. This means you can submit if it\'s still before midnight anywhere in the world.\\n  Final submissions must include a video pitch with a demo, a public codebase, and optionally a hosted site and presentation slides. These requirements are designed to give judges a comprehensive view of the project.\\n- **Considerations**\\n- Do not leave commits until the last minute; make regular commits from the start.\\n- The video pitch is the first impression for judges and needs to capture their attention immediately.\\n- While AI can be used for presentations, it is not recommended to use AI to generate the entire video pitch as it can be \'soul destroying\' for judges.\\n- A hosted site and presentation are optional but highly recommended to strengthen your submission.\\n- Do not submit at the last minute to avoid technical issues or mistakes.\\n\\n### Using the ENCODE Platform\\n\\n> The ENCODE platform is the central hub for the hackathon. It contains all necessary information, resources, and submission portals for participants.\\n\\n- **Keypoints**\\n  - The ENCODE platform is the home for the hackathon.\\n  - Participants must register on the platform to get all emails and updates.\\n  - To create a project and team, use the \'create project\' and \'join team code\' features.\\n  - The platform has a \'Lecture\' section with helpful videos.\\n  - The \'Events\' page lists all workshop links.\\n  - Challenge descriptions and partner resources (Comet docs, Gemini credits, etc.) are available on the platform.\\n  - All submissions are made through the participant\'s personal hackathon page on the platform.\\n- **Explanation**\\n  Participants will use the ENCODE platform for all hackathon-related activities. After the introductory session, participants who joined from Luma must register for the hackathon on the platform to receive emails and updates. The platform is where you create your project, add team members using a \'join code\', find lecture videos, access event links for workshops, read detailed challenge descriptions, and find partner resources like the Comet developer documentation and OPIC quick start guide. All submissions, from the mid-hackathon check-in to the final project, will be done through this platform.\\n\\n### Definition of an AI Evaluation\\n\\n> An evaluation is a structured measurement of a system\'s behavior against criteria we care about. This involves defining the vision of success and failure for the application. The process is a structured way to measure an AI system\'s behavior against defined criteria on representative tasks to support decisions and improve product development.\\n\\n- **Keypoints**\\n  - It\'s a structured measurement of a system\'s behavior.\\n  - It\'s measured against predefined criteria that define success.\\n  - The hardest part is often figuring out the criteria you care about.\\n  - It\'s important to think about success, failure, and potential failure modes from the beginning.\\n  - Failure modes can vary, from harmful content and incorrect outputs to having the wrong tone for a brand.\\n  - An evaluation system is often a set of many individual metrics.\\n  - These individual metrics are aggregated into an overall success score.\\n- **Explanation**\\n  To unpack the definition: \'Structure\' means repeatable and explicit, allowing for comparisons over time. \'Behavior\' refers to what the system does, such as responses, tool calls, latency, or cost. \'Criteria\' is how success is predefined, including accuracy, helpfulness, safety, or product-specific outcomes. An evaluation system is typically a set of many metrics aggregated into an overall success score.\\n\\n### The Four Ingredients of a Good Evaluation\\n\\n> A good evaluation generally consists of four main ingredients: a target, a test set/task, a scoring method, and a decision rule. These components work together to form a repeatable and useful evaluation process.\\n\\n- **Keypoints**\\n  - A target: The specific capability or outcome being tested (e.g., factual QA, customer support resolution).\\n  - A test set or task: Examples representing the real world, including edge cases and outliers.\\n  - A scoring method: A metric, rubric, or judge (human or LLM) to score performance, including how individual scores are aggregated (e.g., math equation, voting system).\\n  - A decision rule: Determines what to do with the results, such as shipping a feature, rolling it back, or retraining. It often includes a threshold (e.g., \'if the success rate improves by at least 20%, then ship it\').\\n- **Explanation**\\n  First, the \'target\' specifies the capability or outcome being tested (e.g., factual QA, tool use). Second, the \'test set\' includes real-world examples and edge cases. Third, the \'scoring method\' defines how performance is measured (e.g., a metric, rubric, LLM judge) and how scores are aggregated. Finally, the \'decision rule\' dictates the action to be taken based on the evaluation score, such as shipping a feature or rolling it back, often based on a threshold or comparison to a baseline.\\n\\n### Difference Between Benchmarks and Application Evals\\n\\n> Benchmarks are standardized test sets, often from academia, used for broad comparisons across different models. Application evaluations are specific to a product, matching its real distribution of prompts, workflows, and constraints, and are used to determine if a system is good enough to ship.\\n\\n- **Keypoints**\\n  - Benchmarks are standardized tests for comparing models.\\n  - Application evals are product-specific tests for system performance.\\n  - Benchmarks assess general ability; application evals assess behavior in a specific context.\\n  - Benchmarks score the model in isolation; application evals test the entire system (prompts, RAG, tools).\\n  - The biggest gap is distribution: benchmarks rarely match real traffic, edge cases, or domain language.\\n  - A model can score high on a benchmark but fail in your specific application context.\\n  - Benchmarks help narrow model choices; product evals tell you if the system is ready to ship.\\n- **Explanation**\\n  Benchmarks are useful for getting a quick read on a model\'s general capabilities and comparing model families (e.g., comparing one foundation model to another). However, a model can perform well on a benchmark and still fail in production because production success depends on behavior in a specific context. Application evals test the entire system\u2014including prompts, RAG, and tool use\u2014against your specific definition of success. The main gap is that benchmarks rarely match the distribution of real-world traffic, including edge cases and domain-specific language.\\n\\n### Challenges in Evaluating LLMs\\n\\n> Evaluating LLMs and agentic systems is inherently difficult due to several unique challenges that distinguish them from traditional software. These challenges include non-determinism, the subjectivity of tasks, high sensitivity to inputs, and the possibility of silent failures.\\n\\n- **Keypoints**\\n  - LLMs are non-deterministic: The same input does not guarantee the same output, making traditional monitoring difficult.\\n  - Many AI tasks lack a single correct answer: Tasks like summarization or content generation can have multiple valid outputs, making simple match comparisons insufficient.\\n  - Heuristic methods are largely ineffective: Simple heuristics like regex or pattern matching don\'t consider semantic meaning.\\n  - Evaluation metrics are subjective: Concepts like relevance, coherence, and conciseness are open to interpretation.\\n  - Human feedback is imperfect: It is expensive, can be inconsistent, and is difficult to scale.\\n  - LLMs are extremely sensitive to prompts and context: Small changes can drastically alter the output.\\n  - LLMs have silent failures: A system can produce a correct output but use flawed or unsafe reasoning to get there, which is a failure that isn\'t immediately obvious.\\n  - There\'s no standard set of evaluation metrics applicable to all products.\\n- **Explanation**\\n  LLMs are non-deterministic, meaning the same input can produce different outputs, making hard-coded logic and simple error handling ineffective. Many tasks like summarization have no single correct answer, so simple matching (like regex) fails; semantic meaning must be considered. Metrics like \'relevance\' are subjective, and even human annotators may disagree. LLMs are also very sensitive to small changes in prompts or context. Finally, they can have \'silent failures,\' where the final output appears correct, but the underlying reasoning was flawed or discriminatory, which can only be caught by observing the entire process.\\n- **Examples**\\n  > Traditional software monitoring uses tools like try-and-accept clauses to handle anticipated errors. However, with LLMs, we cannot anticipate every single possible output they might produce due to their non-deterministic nature. Therefore, a simple accept clause is not a scalable or effective solution for handling LLM failures.\\n\\n### Challenges in Monitoring AI Agents\\n\\n> Monitoring AI agents is significantly more complex than monitoring standalone Large Language Models (LLMs) because agents are composed of multiple LLMs and external tools, leading to compounded variability and numerous failure modes.\\n\\n- **Keypoints**\\n  - Agents are built on top of LLMs, inheriting their non-deterministic nature.\\n  - Chaining multiple LLM calls compounds variability and potential for error.\\n  - Agents are multi-step workflows with more moving parts and thus more failure modes.\\n  - The use of external tools introduces external dependencies, potential silent failures, and added unpredictability.\\n  - Dynamic memory and context in agents can lead to intent drift and performance degradation over time.\\n  - Evaluation of agents must include not just the final output, but also the reasoning, tool choice, and every step along the way.\\n- **Explanation**\\n  Agents are built on top of LLMs, which are non-deterministic systems. When you chain multiple LLM calls together, as is common in agents, the variability and potential for error at the beginning of the chain can be amplified through subsequent steps. Agents are also multi-step workflows with more moving parts, external tool dependencies (which can have silent failures), and dynamic memory/context. This complexity increases the number of failure modes and necessitates a more thorough evaluation process that goes beyond just the final output to include reasoning, tool choice, and each intermediate step. As agents are deployed in real-world scenarios with more complex workflows and higher usage frequency, tracking all these aspects becomes extremely difficult.\\n- **Examples**\\n  > A user engaged with a dealership\'s chatbot and managed to get it to agree to sell them a Chevy Tahoe for one US dollar. The chatbot even stated \'no takesies backsies\'. This agreement was legally upheld in court, forcing the dealership to sell the car for one dollar.\\n  - This example illustrates a real-world consequence of an AI agent (chatbot) going wrong.\\n  - The non-deterministic and unconstrained nature of the LLM powering the chatbot led to an unintended and costly outcome for the dealership.\\n  - It highlights the critical need for robust monitoring and evaluation of agent behavior to prevent such incidents.\\n  - The phrase \'no takesies backsies\' being considered legally binding underscores how interactions with AI can have unforeseen legal ramifications.\\n\\n### Hackathon Logistics and Rules\\n\\n> The \'Resolve to Evolve\' Hackathon is an event where participants build AI or LLM-powered applications to help people maintain their New Year\'s resolutions. The event has specific rules regarding submissions, team formation, judging, and tooling.\\n\\n- **Keypoints**\\n  - Objective: Build an AI/LLM-powered app to help with New Year\'s resolutions.\\n  - Team Formation: Solo or teams of any size are permitted (recommendation: 5 or less).\\n  - Submissions: You can submit to multiple tracks but win at most one.\\n  - Prizing: $5,000 for each of the five themes, plus a $5,000 special prize for the best use of OPIC.\\n  - Required Tooling: OPIC must be used for evaluation.\\n  - Allowed Tooling: Any LLM (e.g., Gemini, etc.) can be used.\\n  - Submission deliverable: A video demo is a mandatory and critical part of the submission, presenting the project and its functionality.\\n  - Project Scope: Build an MVP. Full production-ready apps are not expected.\\n  - Timeline: The hackathon has started, and coding can begin now. It lasts approximately 28 days.\\n  - Prior Work: You can build on a pre-existing project, but only functionality added during the hackathon will be judged.\\n- **Explanation**\\n  Participants are tasked with creating an MVP (Minimum Viable Product) of a web or mobile app. They can work solo or in teams of any size, though teams of 5 or fewer are recommended. Submissions can target multiple prize categories, but a project can only win one. Judging criteria are available on the hackathon platform. A key component of the submission is a video demo that serves as both a product pitch and a functional walkthrough. While participants can use any LLM, they are required to use OPIC for evaluation. The hackathon provides access to partner services with generous free tiers instead of specific credits. Participants can start coding immediately and can even build upon existing projects, but only work done during the hackathon period will be judged.\\n- **Special Circumstances**\\n- If building a mobile app that cannot be easily shared or hosted for judging, a very thorough demo video showing all functionality is sufficient.\\n- If you want to work on a project you have already started, you can, but you will only be judged on the new functionality and features built during the hackathon period.\\n\\n## Assignments & Suggestions\\n\\n- If you are joining from Luma, go into your programs page and register for the hackathon after the session.\\n- If you have questions that aren\'t answered live, put them in the Q&A to be answered in the Discord.\\n- Decide on the project you want to build, the theme to focus on, the solution to come up with, and what makes it special during the ideation stage in week one.\\n- By the project creation deadline at the end of week one, create and commit to the project idea, the challenge theme, and add team members.\\n- Start the building process in week two.\\n- For the mid-hackathon deadline, submit your publicly available GitHub repo and a fuller description of what you\'re building.\\n- For the final submission deadline on February 8th, submit a video pitch including a product demo, your public code base, a hosted site (optional but recommended), and a presentation (optional but recommended).\\n- Watch the helpful, short lecture videos on the platform to prepare for workshops and the wider hackathon.\\n- Run the code from the QR code provided to see how evaluations are created and look in OPIC. The QR code leads to a simple recipe generator agent in a GitHub gist. You need to copy the script, follow the directions for creating online evaluations, create a Comet account if you don\'t have one (it\'s free), and add your API key."},{"id":"locki-in-2025","metadata":{"permalink":"/fr/blog/locki-in-2025","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2025-01-15-locki-in-2025.mdx","source":"@site/blog/2025-01-15-locki-in-2025.mdx","title":"Locki Labs in 2025 - Introducing Valkyria","description":"After months of development on our horse racing analysis platform, we\'re taking a bold step forward. In 2025, Locki Labs shifts focus from real-time data aggregation to something far more ambitious: Valkyria \u2014 a temporal prediction system designed for scientific rigor and reproducible results.","date":"2025-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Locki Labs","permalink":"/fr/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"Temporal Predictions","permalink":"/fr/blog/tags/temporal-predictions","description":"Insights into temporal prediction models and applications"},{"inline":false,"label":"Machine Learning","permalink":"/fr/blog/tags/machine-learning","description":"Articles on machine learning and related technologies"}],"readingTime":3.94,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"locki-in-2025","title":"Locki Labs in 2025 - Introducing Valkyria","authors":["jnxmas"],"tags":["locki","ai-ml","temporal-predictions","machine-learning"]},"unlisted":false,"prevItem":{"title":"Hackathon kickoff meeting","permalink":"/fr/blog/encode-kickoff"},"nextItem":{"title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","permalink":"/fr/blog/locki-journey-2023-2025"}},"content":"After months of development on our horse racing analysis platform, we\'re taking a bold step forward. In 2025, Locki Labs shifts focus from real-time data aggregation to something far more ambitious: **Valkyria** \u2014 a temporal prediction system designed for scientific rigor and reproducible results.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Problem We Set Out to Solve\\n\\nOur existing platform excels at real-time race analysis. But we discovered a fundamental limitation when it came to developing prediction models: **temporal blindness**.\\n\\nWhen analyzing a historical race from, say, November 16th, our system would use horse data from _today_ \u2014 including races that happened _after_ the race we\'re analyzing. This is called **data leakage**, and it makes prediction models unreliable.\\n\\n```\\nScenario: Analyzing a race from November 16, 2025\\n\\n\u274c Current approach:\\n   Uses horse career data as of TODAY\\n   \u2192 Includes future races (data leakage)\\n   \u2192 Predictions are scientifically invalid\\n\\n\u2705 Valkyria approach:\\n   Uses horse career data as of November 16\\n   \u2192 Only past information available\\n   \u2192 Predictions are reproducible and valid\\n```\\n\\n## What is Valkyria?\\n\\nValkyria is a **temporal prediction laboratory** \u2014 a system that can reproduce predictions with historical accuracy. The core principle is simple but powerful:\\n\\n> **Analyze any race using only the data that would have been available at that exact moment in time.**\\n\\nThis enables:\\n\\n- **Time-Travel Analysis**: Query any race from the past 18 months with temporally-accurate data\\n- **Model Training**: Train prediction algorithms on clean, causally-valid datasets\\n- **Backtesting**: Validate strategies on historical races without information leakage\\n- **Reproducibility**: Same race, same analysis, same results \u2014 every time\\n\\n## The Three-Tier Architecture\\n\\nValkyria operates on a three-tier temporal system:\\n\\n### Tier 1: Real-Time (48 hours)\\n\\nLive operations for current and upcoming races. Odds tracking, race analysis, chat features \u2014 all powered by Redis cache with 15-minute refresh cycles.\\n\\n### Tier 2: Recent History (7 days)\\n\\nFast access to recently finished races. Runner snapshots stored in Redis with file backup for durability.\\n\\n### Tier 3: Historical Archive (18 months)\\n\\n**This is the innovation.** A SQLite-based temporal database containing runner snapshots \u2014 immutable records of each horse\'s state at race time. No future information, ever.\\n\\n## Campaign-Based Population\\n\\nRather than fetching all historical data upfront, Valkyria uses a **campaign-based approach**:\\n\\n| Campaign | Period       | Estimated Races | Status   |\\n| -------- | ------------ | --------------- | -------- |\\n| Q4-2025  | Oct-Dec 2025 | ~4,500          | Priority |\\n| Q3-2025  | Jul-Sep 2025 | ~4,500          | Next     |\\n| Q2-2025  | Apr-Jun 2025 | ~4,500          | Planned  |\\n\\nEach campaign represents a 3-month slice of racing data, populated incrementally during off-peak hours. The database grows organically while maintaining full temporal accuracy.\\n\\n## Model Unification: One Model, Multiple Lifecycles\\n\\nA key architectural decision: **CanonicalRunner** becomes the single source of truth across all lifecycle stages:\\n\\n1. **Pre-Race**: Upcoming participant with updating odds\\n2. **Post-Race**: Finished runner with final results\\n3. **Career History**: Stored snapshot for temporal queries\\n\\nThis eliminates 88% of field duplication from our previous dual-model system and ensures consistency across the entire platform.\\n\\n## What This Means for Predictions\\n\\nWith Valkyria, we can finally build prediction models with scientific integrity:\\n\\n```\\nHistorical snapshots (18 months)\\n    \u2193\\nFeature engineering (career metrics, confrontations)\\n    \u2193\\nModel training (XGBoost, Neural Networks)\\n    \u2193\\nBacktesting (temporal validation)\\n    \u2193\\nProduction deployment (high confidence)\\n```\\n\\nWe\'ll be able to:\\n\\n- Compare multiple models on the same historical data\\n- Calculate accuracy by race type (HARNESS, FLAT, Quint\xe9)\\n- Calibrate confidence scores based on actual performance\\n- Generate algorithmic selections with transparent methodology\\n\\n## The Road Ahead\\n\\nValkyria development follows a phased approach:\\n\\n**Foundation** \u2014 Database schema, storage functions, basic snapshot capabilities\\n\\n**Daily Population** \u2014 Automated jobs to capture yesterday\'s races every night\\n\\n**Workflow Integration** \u2014 Career workflows query the temporal database for historical analysis\\n\\n**Campaign Population** \u2014 Bulk population of 3-month historical periods\\n\\n**Model Unification** \u2014 Full migration to CanonicalRunner across all analyzers\\n\\nEach phase delivers value independently. If we complete only the foundation and daily population, we still have a working temporal snapshot system. The full vision builds incrementally.\\n\\n## Storage & Retention\\n\\nThe numbers are reassuring:\\n\\n- **18 months of racing**: ~27,000 races, ~324,000 runner snapshots\\n- **Storage requirement**: ~486 MB\\n- **Cleanup policy**: Monthly removal of data older than 18 months\\n\\nSQLite handles this efficiently, and the system remains lightweight.\\n\\n## Why This Matters\\n\\nWithout temporal accuracy, predictions are anecdotal. With Valkyria:\\n\\n- \u2705 **Causal validity**: Only past data influences predictions\\n- \u2705 **Reproducibility**: Results can be verified and replicated\\n- \u2705 **Testability**: Objective performance metrics across historical data\\n- \u2705 **Confidence**: Know when and where models perform reliably\\n\\nThis isn\'t just a technical improvement \u2014 it\'s the foundation for next-generation prediction algorithms built on scientific rigor rather than intuition.\\n\\n## Looking Forward\\n\\n2025 marks a transition for Locki Labs. We\'re moving from \\"what does the data say right now?\\" to \\"what would we have known then, and how can we learn from it?\\"\\n\\nValkyria represents our commitment to building prediction systems we can trust, test, and continuously improve. One snapshot at a time.\\n\\n---\\n\\n_Stay tuned for updates as we progress through the Valkyria implementation phases._"},{"id":"locki-journey-2023-2025","metadata":{"permalink":"/fr/blog/locki-journey-2023-2025","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2023-09-29-locki-labs-journey.mdx","source":"@site/blog/2023-09-29-locki-labs-journey.mdx","title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","description":"Locki started as a vision during the Encode MultiversX Hackathon in October 2023, with the ambitious goal of creating a decentralized platform for minting, viewing, and interacting with 3D Data NFTs using the Itheum protocol.","date":"2024-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Locki Labs","permalink":"/fr/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"Blockchain","permalink":"/fr/blog/tags/blockchain","description":"Articles related to blockchain technology"},{"inline":false,"label":"MultiversX","permalink":"/fr/blog/tags/multiversx","description":"Content about the MultiversX ecosystem"},{"inline":false,"label":"Itheum","permalink":"/fr/blog/tags/itheum","description":"Posts regarding Itheum platform"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Web3 Technologies","permalink":"/fr/blog/tags/web3","description":"Discussions on Web3 technologies and trends"}],"readingTime":3.43,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"locki-journey-2023-2025","title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","authors":["jnxmas"],"tags":["locki","blockchain","multiversx","itheum","rag","web3"],"date":"2024-01-15T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Locki Labs in 2025 - Introducing Valkyria","permalink":"/fr/blog/locki-in-2025"},"nextItem":{"title":"Locki blog introduction","permalink":"/fr/blog/welcome"}},"content":"Locki started as a vision during the **Encode MultiversX Hackathon in October 2023**, with the ambitious goal of creating a decentralized platform for minting, viewing, and interacting with 3D Data NFTs using the Itheum protocol.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Current Status\\n\\n:::info Project Status\\n\\nLocki dApp is currently in **alpha phase** on MultiversX devnet, and has been supported by the **xPand Itheum program**.\\n\\n:::\\n\\nThe platform has evolved significantly since its inception, now featuring:\\n\\n- **3D Data NFT minting and visualization** using Three.js and React Three Fiber\\n- **AI-powered chat assistant** for Blender Python scripting guidance\\n- **Whitelist management system** for controlled access\\n- **Integration with MultiversX wallets** including xAlias support\\n\\n## The Challenge of Collecting RAG Data and Intellectual Property\\n\\nOne of the most significant hurdles we\'ve encountered is **building a quality dataset for our RAG (Retrieval-Augmented Generation) system** while respecting intellectual property rights.\\n\\n### The IP Dilemma\\n\\nCreating an effective AI assistant for 3D modeling and Blender scripting requires extensive training data:\\n\\n- **Documentation licensing**: Much of the best Blender documentation exists under various licenses that complicate commercial use\\n- **Community content**: Forum posts, tutorials, and Stack Exchange answers have complex attribution requirements\\n- **Proprietary scripts**: Many advanced Blender scripts are commercial products with restrictive licenses\\n- **Version fragmentation**: Blender\'s rapid release cycle means documentation quickly becomes outdated\\n\\n### Our Approach\\n\\nWe\'ve had to carefully curate our data sources, focusing on:\\n\\n1. **Open-source documentation** with permissive licenses\\n2. **Original content creation** to fill knowledge gaps\\n3. **User-generated content** with explicit consent\\n4. **Partnerships** with content creators in the Blender ecosystem\\n\\n:::tip Locki Companion Status\\n\\nThe Locki companion AI feature is currently **on pause** while we navigate these data collection challenges and ensure full compliance with IP rights.\\n\\n:::\\n\\n## Technical Challenges: The Blockchain Moving Target\\n\\nPerhaps the most demanding aspect of maintaining Locki has been keeping pace with the **rapid evolution of blockchain infrastructure**.\\n\\n### SDK Version Churn\\n\\nThe MultiversX ecosystem has undergone substantial changes:\\n\\n```json\\n// Our current dependency snapshot\\n\\"@multiversx/sdk-core\\": \\"12.18.0\\",\\n\\"@multiversx/sdk-dapp\\": \\"2.28.7\\",\\n\\"@multiversx/sdk-network-providers\\": \\"2.3.0\\",\\n\\"@itheum/sdk-mx-data-nft\\": \\"2.7.0-beta.4\\"\\n```\\n\\nEach major version brings:\\n\\n- **Breaking API changes** requiring code refactoring\\n- **New authentication patterns** (we\'ve integrated xAlias, native auth tokens)\\n- **Smart contract interface updates** affecting our ABI integrations\\n- **Wallet provider deprecations** forcing migration to new connection methods\\n\\n### Specific Challenges We\'ve Faced\\n\\n1. **SSR Compatibility**: Next.js App Router with blockchain SDKs requires careful dynamic imports to avoid server-side rendering issues\\n\\n2. **Transaction Handling**: The move from legacy transaction signing to the new `signAndSendTransactions` utility required substantial refactoring\\n\\n3. **Smart Contract ABIs**: Contract updates on devnet mean our local ABIs must be continuously synchronized\\n\\n4. **Network Provider Changes**: API endpoint changes and rate limiting adjustments have required multiple backend adaptations\\n\\n### The Maintenance Burden\\n\\n```\\nRecent commits reflecting ongoing maintenance:\\n- \\"Upgrade: Status locki companion\\"\\n- \\"fix vulnerabilities\\"\\n- \\"Fixed build issues\\"\\n- \\"Fixes smart contract dependencies and code refactoring\\"\\n```\\n\\nEach vulnerability fix in upstream dependencies cascades through our codebase. The security-conscious nature of blockchain applications means we cannot defer these updates.\\n\\n## Lessons Learned\\n\\n### For Blockchain Developers\\n\\n1. **Abstract your SDK interactions**: Create wrapper classes (like our `baseSmartContract.ts`) to isolate breaking changes\\n2. **Pin versions carefully**: Use exact versions in production, but test against latest regularly\\n3. **Monitor ecosystem announcements**: Join Discord channels and follow GitHub releases\\n4. **Build with deprecation in mind**: What works today may be obsolete in 6 months\\n\\n### For AI/RAG Builders\\n\\n1. **Document your data sources**: Track provenance from day one\\n2. **Build consent mechanisms**: Make it easy for users to contribute data with clear licensing\\n3. **Plan for re-training**: Your model will need updates as source material evolves\\n4. **Consider synthetic data**: Generate training examples where real data is restricted\\n\\n## What\'s Next for Locki\\n\\nDespite these challenges, we remain committed to the vision:\\n\\n- **Mainnet deployment** once alpha testing is complete\\n- **Enhanced 3D NFT features** with improved GLTF/GLB support\\n- **Expanded AI capabilities** with properly licensed training data\\n- **Community governance** for whitelist and platform decisions\\n\\n---\\n\\n_Locki is an open-source project. We welcome contributors who share our passion for decentralized 3D asset ownership and AI-assisted creativity._\\n\\n**Special Collections on MultiversX Devnet:**\\n\\n- `DATANFTFT-e0b917`\\n- `I3TICKER-03e5c2`\\n- `COLNAMA-539838`"},{"id":"welcome","metadata":{"permalink":"/fr/blog/welcome","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Locki blog introduction","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/fr/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/fr/blog/tags/hello","description":"Hello tag description"}],"readingTime":0.85,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"welcome","title":"Locki blog introduction","authors":["jnxmas"],"tags":["facebook","hello"]},"unlisted":false,"prevItem":{"title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","permalink":"/fr/blog/locki-journey-2023-2025"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\n\\n:::tip\\nThe blog is interesting because it allows our agent in cursor and claude code to dive into our reflexion to have a set of the status and the priorities of the project.\\nUse it referencing our discussion for your feature branches.\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n:::tip\\nThe blog is interesting because it allows our agent in cursor and claude code to dive into our reflexion to have a set of the status and the priorities of the project.\\nUse it referencing our discussion for your feature branches.\\n:::\\nSimply add Markdown files (or folders) to the `blog` directory.\\n\\nRegular blog authors can be added to `authors.yml`.\\n\\nThe blog post date can be extracted from filenames, such as:\\n\\n- `2019-05-30-welcome.md`\\n- `2019-05-30-welcome/index.md`\\n\\nA blog post folder can be convenient to co-locate blog post images:\\n\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\\n\\nThe blog supports tags as well!"}]}}')}}]);