"use strict";(globalThis.webpackChunkdocs_locki_io=globalThis.webpackChunkdocs_locki_io||[]).push([[1865],{6444(e,n,r){r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"app/opik/CONTINUOUS_IMPROVEMENT","title":"Continuous Improvement of AI Agent Features","description":"A methodology for systematically improving LLM-powered agent features through automated evaluation, cleanup, and optimization loops.","source":"@site/docs/app/opik/CONTINUOUS_IMPROVEMENT.md","sourceDirName":"app/opik","slug":"/app/opik/CONTINUOUS_IMPROVEMENT","permalink":"/fr/docs/app/opik/CONTINUOUS_IMPROVEMENT","draft":false,"unlisted":false,"editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/docs/app/opik/CONTINUOUS_IMPROVEMENT.md","tags":[],"version":"current","frontMatter":{}}');var t=r(4848),s=r(8453);const l={},d="Continuous Improvement of AI Agent Features",o={},a=[{value:"Overview",id:"overview",level:2},{value:"The Problem",id:"the-problem",level:2},{value:"Methodology",id:"methodology",level:2},{value:"Step 1: Trace Everything",id:"step-1-trace-everything",level:3},{value:"Step 2: Define the Ideal Output",id:"step-2-define-the-ideal-output",level:3},{value:"Step 3: Cleanup Before Optimization",id:"step-3-cleanup-before-optimization",level:3},{value:"Step 4: Evaluate with Custom Metrics",id:"step-4-evaluate-with-custom-metrics",level:3},{value:"Step 5: Automate with Scheduled Tasks",id:"step-5-automate-with-scheduled-tasks",level:3},{value:"Step 6: Iterate on Prompts",id:"step-6-iterate-on-prompts",level:3},{value:"Implementation",id:"implementation",level:2},{value:"Register Feature for Optimization",id:"register-feature-for-optimization",level:3},{value:"Run Experiment",id:"run-experiment",level:3},{value:"View Results in Opik",id:"view-results-in-opik",level:3},{value:"Metrics Deep Dive",id:"metrics-deep-dive",level:2},{value:"Output Format Metric",id:"output-format-metric",level:3},{value:"Interpreting Scores",id:"interpreting-scores",level:3},{value:"Workflow Integration",id:"workflow-integration",level:2},{value:"Admin Dashboard",id:"admin-dashboard",level:3},{value:"Scheduled Automation",id:"scheduled-automation",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Start with Observability",id:"1-start-with-observability",level:3},{value:"2. Define Success Criteria",id:"2-define-success-criteria",level:3},{value:"3. Clean Before Measuring",id:"3-clean-before-measuring",level:3},{value:"4. Track Provider Performance",id:"4-track-provider-performance",level:3},{value:"5. Iterate Incrementally",id:"5-iterate-incrementally",level:3},{value:"Files Reference",id:"files-reference",level:2},{value:"See Also",id:"see-also",level:2}];function c(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"continuous-improvement-of-ai-agent-features",children:"Continuous Improvement of AI Agent Features"})}),"\n",(0,t.jsx)(n.p,{children:"A methodology for systematically improving LLM-powered agent features through automated evaluation, cleanup, and optimization loops."}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsxs)(n.p,{children:["AI agents like Forseti require continuous monitoring and improvement. Raw LLM outputs can drift, accumulate errors, and diverge from expected formats. This document describes OCapistaine's approach to ",(0,t.jsx)(n.strong,{children:"continuous improvement"})," through:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Observability"})," - Trace all agent operations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cleanup"})," - Remove error traces before optimization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Evaluation"})," - Measure output quality with custom metrics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Iteration"})," - Scheduled tasks for ongoing improvement"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     CONTINUOUS IMPROVEMENT LOOP                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502    \u2502  TRACE   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  CLEAN   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502 EVALUATE \u2502\u2500\u2500\u2500\u2500\u25b6\u2502 OPTIMIZE PROMPT  \u2502  \u2502\n\u2502    \u2502  (Opik)  \u2502     \u2502 (Errors) \u2502     \u2502 (Metrics)\u2502     \u2502 (Iterate)        \u2502  \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502         \u25b2                                                      \u2502            \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.h2,{id:"the-problem",children:"The Problem"}),"\n",(0,t.jsx)(n.p,{children:"LLM-powered features face several challenges:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Challenge"}),(0,t.jsx)(n.th,{children:"Impact"}),(0,t.jsx)(n.th,{children:"Solution"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Error accumulation"})}),(0,t.jsx)(n.td,{children:"Bad traces pollute datasets"}),(0,t.jsx)(n.td,{children:"Pre-experiment cleanup"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Format drift"})}),(0,t.jsx)(n.td,{children:"Outputs diverge from schema"}),(0,t.jsx)(n.td,{children:"Output format metric"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Confidence variance"})}),(0,t.jsx)(n.td,{children:"Inconsistent quality"}),(0,t.jsx)(n.td,{children:"Confidence threshold metric"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Provider differences"})}),(0,t.jsx)(n.td,{children:"Results vary by LLM"}),(0,t.jsx)(n.td,{children:"Provider/model tracking"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Async ingestion"})}),(0,t.jsx)(n.td,{children:"Spans delayed ~3 minutes"}),(0,t.jsx)(n.td,{children:"Scheduled evaluation task"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"methodology",children:"Methodology"}),"\n",(0,t.jsx)(n.h3,{id:"step-1-trace-everything",children:"Step 1: Trace Everything"}),"\n",(0,t.jsx)(n.p,{children:"Every agent feature should create Opik spans with:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# In agent feature\nwith tracer.span("charter_validation", input=input_data) as span:\n    result = await self._validate(...)\n    span.update(\n        output=result.model_dump(),\n        metadata={\n            "confidence": result.confidence,\n            "is_valid": result.is_valid,\n            "provider": self._provider.name,    # Track LLM\n            "model": self._provider.model,       # Track model\n            "added_to_dataset": False,\n        },\n    )\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Key metadata fields:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"provider"})," / ",(0,t.jsx)(n.code,{children:"model"})," - Which LLM produced this output"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"confidence"})," - Agent's self-assessed confidence"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"added_to_dataset"})," - Prevent duplicate processing"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-2-define-the-ideal-output",children:"Step 2: Define the Ideal Output"}),"\n",(0,t.jsx)(n.p,{children:"Document the expected output format for each feature:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Ideal charter validation output\nIDEAL_CHARTER_OUTPUT = {\n    "is_valid": True,\n    "violations": [],\n    "encouraged_aspects": [\n        "Concrete and argued proposals",\n        "Constructive criticism",\n        "Questions and requests for clarification",\n    ],\n    "reasoning": "Clear explanation of validation decision...",\n    "confidence": 0.95,\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["This becomes the ",(0,t.jsx)(n.strong,{children:"target"})," for the output format metric."]}),"\n",(0,t.jsx)(n.h3,{id:"step-3-cleanup-before-optimization",children:"Step 3: Cleanup Before Optimization"}),"\n",(0,t.jsx)(n.p,{children:"Error traces pollute optimization. Remove them first:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from app.processors.workflows.workflow_experiment import cleanup_error_traces\n\n# Before any experiment\nresult = cleanup_error_traces()\nprint(f\"Deleted {result['deleted']} error traces\")\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Error patterns detected:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:'"Validation error: Gemini retries exhausted"'})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:'"rate limit"'}),", ",(0,t.jsx)(n.code,{children:'"timeout"'}),", ",(0,t.jsx)(n.code,{children:'"failed"'})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-4-evaluate-with-custom-metrics",children:"Step 4: Evaluate with Custom Metrics"}),"\n",(0,t.jsx)(n.p,{children:"Use metrics that measure alignment with the ideal format:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Metric"}),(0,t.jsx)(n.th,{children:"What it measures"}),(0,t.jsx)(n.th,{children:"Score range"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"output_format"})}),(0,t.jsx)(n.td,{children:"Schema compliance"}),(0,t.jsx)(n.td,{children:"0.0 - 1.0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"confidence"})}),(0,t.jsx)(n.td,{children:"Confidence level"}),(0,t.jsx)(n.td,{children:"0.0 - 1.0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"charter_compliance"})}),(0,t.jsx)(n.td,{children:"is_valid accuracy"}),(0,t.jsx)(n.td,{children:"0.0 or 1.0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"hallucination"})}),(0,t.jsx)(n.td,{children:"False information"}),(0,t.jsx)(n.td,{children:"0.0 - 1.0"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Output Format Scoring:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"+0.2 per required field with correct type (5 fields max)\n-0.5 if reasoning contains error messages\n-0.2 if reasoning is empty\n-0.1 if confidence out of range\n-0.1 if valid but no encouraged_aspects\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-5-automate-with-scheduled-tasks",children:"Step 5: Automate with Scheduled Tasks"}),"\n",(0,t.jsx)(n.p,{children:"Run evaluation periodically to catch issues early:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Cron: Every 30 minutes, 7 AM - 10 PM\nOPIK_EVALUATE_CRON = "*/30 7-22 * * *"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"task_opik_evaluate"})," task:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Cleans error traces"}),"\n",(0,t.jsx)(n.li,{children:"Finds new spans not yet evaluated"}),"\n",(0,t.jsx)(n.li,{children:"Creates dataset from spans"}),"\n",(0,t.jsx)(n.li,{children:"Runs Opik evaluate()"}),"\n",(0,t.jsx)(n.li,{children:"Reports results"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-6-iterate-on-prompts",children:"Step 6: Iterate on Prompts"}),"\n",(0,t.jsx)(n.p,{children:"Use evaluation results to improve prompts:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Low output_format score (< 0.7)\n    \u2192 Review prompt structure\n    \u2192 Add format examples to prompt\n    \u2192 Specify required fields explicitly\n\nLow confidence scores\n    \u2192 Simplify task complexity\n    \u2192 Provide more context\n    \u2192 Consider model upgrade\n\nHigh hallucination rate\n    \u2192 Add grounding instructions\n    \u2192 Include source citations\n    \u2192 Reduce temperature\n"})}),"\n",(0,t.jsx)(n.h2,{id:"implementation",children:"Implementation"}),"\n",(0,t.jsx)(n.h3,{id:"register-feature-for-optimization",children:"Register Feature for Optimization"}),"\n",(0,t.jsxs)(n.p,{children:["Add to ",(0,t.jsx)(n.code,{children:"AGENT_FEATURE_REGISTRY"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'AGENT_FEATURE_REGISTRY = {\n    "charter_optimization": {\n        "agent": "forseti",\n        "feature": "charter_validation",  # Span name\n        "prompt_key": "forseti.charter_validation",\n        "dataset_prefix": "charter-optimization",\n        "description": "Charter validation accuracy",\n    },\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"run-experiment",children:"Run Experiment"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from app.processors.workflows import OpikExperimentConfig, run_opik_experiment\n\nconfig = OpikExperimentConfig(\n    experiment_name="charter-improvement-20260204",\n    dataset_name="charter-optimization-20260204",\n    experiment_type="charter_optimization",\n    metrics=["hallucination", "output_format", "confidence"],\n    task_provider="gemini",\n    cleanup_errors=True,  # Clean before experiment\n)\n\nresults = run_opik_experiment(config)\nprint(f"Average output_format: {results[\'eval_results\'][\'average_scores\']}")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"view-results-in-opik",children:"View Results in Opik"}),"\n",(0,t.jsx)(n.p,{children:"Results are logged to Opik platform with:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Per-item scores"}),"\n",(0,t.jsx)(n.li,{children:"Aggregate statistics"}),"\n",(0,t.jsx)(n.li,{children:"Experiment configuration (provider, model, metrics)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"metrics-deep-dive",children:"Metrics Deep Dive"}),"\n",(0,t.jsx)(n.h3,{id:"output-format-metric",children:"Output Format Metric"}),"\n",(0,t.jsx)(n.p,{children:"Measures structural compliance with ideal output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from app.processors.workflows.workflow_experiment import create_output_format_metric\n\nmetric = create_output_format_metric()\n\n# Test with sample output\nresult = metric.score(\n    expected_output={\n        "is_valid": True,\n        "violations": [],\n        "encouraged_aspects": ["Good proposals"],\n        "reasoning": "Valid contribution with concrete ideas",\n        "confidence": 0.9,\n    }\n)\nprint(f"Score: {result.value}")  # 1.0 for ideal format\n'})}),"\n",(0,t.jsx)(n.h3,{id:"interpreting-scores",children:"Interpreting Scores"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Score"}),(0,t.jsx)(n.th,{children:"Interpretation"}),(0,t.jsx)(n.th,{children:"Action"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"0.9 - 1.0"}),(0,t.jsx)(n.td,{children:"Excellent"}),(0,t.jsx)(n.td,{children:"Maintain current prompt"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"0.7 - 0.9"}),(0,t.jsx)(n.td,{children:"Good"}),(0,t.jsx)(n.td,{children:"Minor refinements"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"0.5 - 0.7"}),(0,t.jsx)(n.td,{children:"Needs work"}),(0,t.jsx)(n.td,{children:"Review prompt structure"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"< 0.5"}),(0,t.jsx)(n.td,{children:"Poor"}),(0,t.jsx)(n.td,{children:"Major prompt revision needed"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"workflow-integration",children:"Workflow Integration"}),"\n",(0,t.jsx)(n.h3,{id:"admin-dashboard",children:"Admin Dashboard"}),"\n",(0,t.jsx)(n.p,{children:"The Admin tab provides:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Manual experiment triggers"}),"\n",(0,t.jsx)(n.li,{children:"Metric selection"}),"\n",(0,t.jsx)(n.li,{children:"Provider configuration"}),"\n",(0,t.jsx)(n.li,{children:"Result visualization"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"scheduled-automation",children:"Scheduled Automation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Daily Schedule                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  06:00  task_contributions_analysis (GitHub/Mockup)          \u2502\n\u2502         \u2514\u2500\u25b6 Creates new spans with Correctness feedback      \u2502\n\u2502                                                              \u2502\n\u2502  07:00  task_opik_evaluate (every 30 min until 22:00)        \u2502\n\u2502    \u2502    \u2514\u2500\u25b6 Cleanup \u2192 Dataset \u2192 Evaluate \u2192 Report            \u2502\n\u2502    \u2502                                                         \u2502\n\u2502  07:30  task_opik_evaluate                                   \u2502\n\u2502    \u2502                                                         \u2502\n\u2502  ...    (repeats every 30 minutes)                           \u2502\n\u2502                                                              \u2502\n\u2502  22:00  Last task_opik_evaluate                              \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(n.h3,{id:"1-start-with-observability",children:"1. Start with Observability"}),"\n",(0,t.jsx)(n.p,{children:"Before optimizing, ensure you have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Spans for all agent features"}),"\n",(0,t.jsx)(n.li,{children:"Provider/model metadata"}),"\n",(0,t.jsx)(n.li,{children:"Confidence scores"}),"\n",(0,t.jsx)(n.li,{children:"Correctness feedback"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-define-success-criteria",children:"2. Define Success Criteria"}),"\n",(0,t.jsx)(n.p,{children:"Set target metrics before optimization:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"output_format >= 0.85"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"confidence >= 0.8"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"hallucination <= 0.1"})}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-clean-before-measuring",children:"3. Clean Before Measuring"}),"\n",(0,t.jsx)(n.p,{children:"Always run cleanup before experiments:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"cleanup_error_traces()  # Remove noise first\n"})}),"\n",(0,t.jsx)(n.h3,{id:"4-track-provider-performance",children:"4. Track Provider Performance"}),"\n",(0,t.jsx)(n.p,{children:"Compare metrics across providers:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Group results by provider in Opik dashboard\nexperiment_config = {\n    "task_provider": "gemini",\n    "task_model": "gemini-2.5-flash",\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"5-iterate-incrementally",children:"5. Iterate Incrementally"}),"\n",(0,t.jsx)(n.p,{children:"Make one change at a time:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Run baseline experiment"}),"\n",(0,t.jsx)(n.li,{children:"Modify prompt"}),"\n",(0,t.jsx)(n.li,{children:"Run comparison experiment"}),"\n",(0,t.jsx)(n.li,{children:"Measure improvement"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"files-reference",children:"Files Reference"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"File"}),(0,t.jsx)(n.th,{children:"Purpose"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"app/processors/workflows/workflow_experiment.py"})}),(0,t.jsx)(n.td,{children:"Cleanup, metrics, experiments"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"app/services/tasks/task_opik_evaluate.py"})}),(0,t.jsx)(n.td,{children:"Scheduled evaluation"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"app/services/tasks/__init__.py"})}),(0,t.jsx)(n.td,{children:"Feature registry"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"app/agents/forseti/agent.py"})}),(0,t.jsx)(n.td,{children:"Agent with tracing"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/fr/docs/app/opik/EXPERIMENT_WORKFLOW",children:"Experiment Workflow"})," - Technical details"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/fr/docs/app/scheduler/tasks/TASK_OPIK_EVALUATE",children:"Task: Opik Evaluate"})," - Scheduled task"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/fr/docs/agents/forseti/ARCHITECTURE",children:"Forseti Agent"})," - Agent implementation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/fr/docs/app/core/prompts",children:"Prompt Management"})," - Prompt optimization"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"This methodology enables systematic improvement of AI agent features through automated evaluation loops, ensuring quality and consistency over time."})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453(e,n,r){r.d(n,{R:()=>l,x:()=>d});var i=r(6540);const t={},s=i.createContext(t);function l(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);