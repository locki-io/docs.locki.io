"use strict";(globalThis.webpackChunkdocs_locki_io=globalThis.webpackChunkdocs_locki_io||[]).push([[6114],{8502(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"meeting-ocapistaine-1","metadata":{"permalink":"/fr/blog/meeting-ocapistaine-1","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-18-team-meeting.mdx","source":"@site/blog/2026-01-18-team-meeting.mdx","title":"Let us choose the stack","description":"Project Context Update (Mid-to-Late January 2026)","date":"2026-01-18T00:00:00.000Z","tags":[{"inline":false,"label":"Sprints","permalink":"/fr/blog/tags/sprints","description":"Articles on sprints and current status updates"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Locki Labs","permalink":"/fr/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"},{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"}],"readingTime":21.11,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meeting-ocapistaine-1","title":"Let us choose the stack","authors":["jnxmas"],"tags":["sprints","civictech","rag","locki","meeting","encode"]},"unlisted":false,"nextItem":{"title":"Lets us code","permalink":"/fr/blog/meher-jnxmas-letscode"}},"content":"## Project Context Update (Mid-to-Late January 2026)\\n\\n**Project**: Locki / \xd2 Capistaine (audierne2026) - AI-powered civic transparency & participatory democracy platform for Audierne 2026 local elections (France)\\n**Core Mission**: Build a neutral, source-based RAG chatbot to answer citizen questions about 4 municipal programs, automate contribution validation against charter rules, crawl/process municipal data (150+ links, 4,000+ PDFs), and showcase Opik integration for the \\"Commit to Change\\" Hackathon.\\n**Critical Timeline**:\\n\\n- Contributions deadline: ~January 31, 2026\\n- Hackathon prototype delivery: ~mid-February 2026 (4-week sprint)\\n- Election period: ~March 15-22, 2026\\n\\n\x3c!-- truncate --\x3e\\n\\n## Team Status & Availability\\n\\n**Active Members**:\\n\\n- **[jnxmas] aka Johnny Christmass (@jnxmas)**: Project lead, architecture, N8N deployment, Firecrawl testing, documentation, political outreach\\n- **Meher/Gurmukher/Guru (@GurmeherSingh)**: ML Engineer, RAG agent + Opik integration (recently arrived US East Coast, jet-lagged)\\n- **Victor (@zcbtvag)**: Backend Python, Firecrawl pipeline (intensive work Mon-Wed, unavailable Thu-Sun for France travel, returns following week)\\n\\n  **Team Experience Alignment**:\\n\\n- \u2705 **Shared expertise**: Streamlit, VectorStore, Python, Firecrawl, Gemini, Opik\\n- \u2705 **Guru\'s strengths**: NOMIC embeddings (Sentence Transformer), Azure, Ollama\\n- \u274c **Learning curve**: N8N (new for Guru + Victor)\\n\\n---\\n\\n## Political & Community Engagement Progress\\n\\n**Achievements**:\\n\\n- **Outgoing mayor**: Positive signal at New Year\'s event - mentioned \\"new paradigm in politics\\"\\n- **Email follow-up**: Mayor acknowledged project email (10+ days prior), interested in discussing Audierne2026\\n- **Electoral lists**: 3 of 4 lists contacted, very positive responses\\n- **Remaining**: 1 list still to contact (before Jan 31)\\n  **Current Challenge**:\\n- **Low citizen engagement**: Contributions/discussions system seeing minimal activity (\\"it\'s a bit too much right now\\")\\n- **Content workflow**: Issues validated \u2192 transferred to discussions \u2192 posted on website after community review\\n- **Validation stages**: Charter compliance + Contextualization (innovative agent finding solutions)\\n  **Strategic Shift**: Team needs to move from outreach to coding and delivery.\\n\\n---\\n\\n## Technical Architecture - Stack Decisions Finalized\\n\\n### Layer Structure (Bottom-Up ETL Pattern)\\n\\n**1. External Services Layer**\\n\\n- **Firecrawl API**: Primary web scraping/crawling service\\n- **Status**: Victor progressing, PR open, completion target Wednesday (before travel)\\n- **Blocker**: Pagination settings need tuning (tested with `max_pages=10`, returned only 1 page)\\n- **Priority source**: D\xe9lib\xe9rations du conseil municipal (municipal council deliberations)\\n  **2. Data Access Layer**\\n- **Vector Store**: Confirmed standard VectorStore approach (all team members familiar)\\n- **Embeddings Strategy**:\\n  - **Primary**: NOMIC model (Sentence Transformer) - Guru has experience\\n  - **Backup/Failsafe**: Mistral Studio - French language optimization + potential local sponsorship\\n- **Crawl Tracking Database**: SQL Lite/SQL Model chosen\\n  - Metadata: Crawl status, RAG inclusion, content category\\n  - SQL Model benefits: Type safety (Python \u2192 SQL columns), FastAPI/Pydantic compatibility, PostgreSQL support\\n  - Owner: [jnxmas] will build during Victor\'s absence\\n    **3. Business Logic Layer**\\n    **Agent 1: Charter Validation Agent** (PRIORITY)\\n- **Purpose**: Auto-validate citizen contributions against charter rules\\n- **Checks**: Respectful language, no personal naming, constructive content\\n- **Functionality**: Binary (green/red) conformance + auto-correct miscategorized submissions (7 categories)\\n- **Tech Stack**: Gemini (primary), Ollama (testing), Opik evaluation/tracing\\n- **Workflow**: Reads `audierne2026` repo issues \u2192 labels/updates in `ocapistaine` repo\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Status**: Not started (blocked by Opik access + N8N deployment)\\n  **Agent 2: RAG Agent / Citizen Q&A Chatbot**\\n- **Purpose**: Answer citizen questions with neutral, contextual responses, cross-reference municipal programs\\n- **Requirements**: No hallucinations (Opik guardrails), source attribution, French language\\n- **Approach**: Start with available data, iterate as crawling progresses\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Status**: Starting development, update expected in 1-2 days\\n- **Dependencies**: VectorStore populated, Charter agent outputs (optional)\\n  **Agent 3: Search Agent** (CONDITIONAL)\\n- **Decision**: Pending RAG completeness assessment\\n- **Logic**: If RAG sufficient \u2192 search agent unnecessary; if RAG insufficient \u2192 search agent as fallback\\n- **Status**: On hold pending RAG testing\\n  **Chat Service** (Already Working)\\n- **Functionality**: Multi-turn conversations with thread management (UUID per user)\\n- **Providers**: OpenAI, Ollama (Mistral, DeepSeek tested locally), Perplexity, Gemini\\n- **Features**: System message config, prompt engineering, thread history persistence, strategy selection (Charter mode, Q&A mode, etc.)\\n- **Opik Integration**: Full tracing via `workflow_chat` class\\n  **Document Service** (To Be Defined)\\n- **Proposed Purpose**:\\n  - Query documentation/source information\\n  - Scheduled re-crawling (detect new docs since last crawl)\\n  - Document categorization + metadata tagging\\n  - Change detection (compare current vs. new crawls, decide RAG updates)\\n- **Open Question**: How does this differ from Chat Service? (Clarified: Document = search/crawl management; Chat = conversational interface)\\n- **Status**: Requirements to be defined collaboratively\\n  **4. Application Layer**\\n- **Streamlit**: Primary presentation interface\\n- **FastAPI**: Routing layer\\n- **Debug Scripts**: One-click full stack launch (UV cone + Streamlit app automation)\\n- **Hot Reload**: Code modifications work without restart\\n- **Future**: Redis integration for scheduler + task memory persistence\\n  **5. External Orchestration Layer**\\n- **N8N**: Self-hosted Docker deployment on Contabo server (viety.loki.io)\\n- **Status**: ~2 hours from completion (as of last meeting)\\n- **Workflows**:\\n  - Pull issues from `audierne2026` GitHub repo\\n  - Trigger charter validation agent\\n  - Push validated/labeled issues back to repo\\n  - Modify Jekyll website content\\n  - Provide API endpoint for agent testing\\n- **Multi-project approach**: Separate workflows per project on shared dashboard\\n- **Future**: Pull data from Opik Cloud back into app (feedback loop via N8N API)\\n  **Supporting Infrastructure**:\\n- **APScheduler (cron-based)**: Time-based tasks (daily/weekly crawl updates, GitHub monitoring, Charter violation checks)\\n- **Opik**: Evaluation, tracing, prompt management (future), hallucination detection, metrics/dashboards\\n- **Poetry**: Dependency management (NOT pip) for library compatibility\\n\\n---\\n\\n## Opik Integration Strategy - MAXIMIZE USAGE\\n\\n**Team Consensus**: \\"Maximize Opik usage at every opportunity\\" - it\'s the hackathon focus.\\n**Dashboard Setup Decisions**:\\n\\n- **Environment**: Start with Opik Dev, migrate to Prod when ready\\n- **Dashboard Approach**: Single unified dashboard to monitor all agents (avoid complexity of separate dashboards per agent)\\n- **API Keys**: Likely one project with multiple keys for per-developer usage tracking\\n- **Access**:\\n  - [jnxmas] has access to `ocapistaine-dev` dashboard\\n  - Need to grant Guru and Victor access\\n  - Guru has existing Opik account (needs to share user ID/Discord username)\\n  - Victor\'s Opik status: Not confirmed\\n    **Integration Points**:\\n- Charter validation agent: Trace every decision, verify adherence to charter rules\\n- RAG agent: Hallucination prevention, prompt evaluation, guardrails\\n- N8N workflows: Plug into Opik for agent activity reporting\\n- Chat service: Already using Opik tracing via `workflow_chat` class\\n- Prompt management: Start hardcoded, potentially migrate to Opik prompt library later\\n- Evaluation judge: Verify LLM adherence to prompts\\n  **Team Familiarity**:\\n- Platform exploration phase: Team has not yet fully explored Opik capabilities\\n- Reference materials: Git examples available for implementation patterns\\n- Action needed: All team members familiarize with Opik features (dashboards, prompt library, evaluation)\\n\\n---\\n\\n## LLM Provider Strategy - Multi-Provider Approach\\n\\n**Confirmed Providers**:\\n\\n1. **Gemini**: Sponsored/free option (primary for Charter agent)\\n2. **Ollama**: Completely free (local testing) - Mistral, DeepSeek tested\\n3. **Mistral**: French language optimization + potential sponsorship target (French govt/local alignment, political risk mitigation)\\n4. **OpenAI**: Already working in Chat service\\n5. **Perplexity**: Available option\\n   **Strategic Rationale**:\\n\\n- **French language**: Critical for citizen-facing content - Mistral chosen for optimization\\n- **Political optics**: Using French LLM provider avoids criticism of not supporting French solutions\\n- **Cost management**: Prioritize free/sponsored options (Gemini, Ollama)\\n- **Failsafe approach**: NOMIC primary + Mistral backup = \\"two tracks maximum\\" ([jnxmas]\'s preference given 4-week timeline)\\n\\n---\\n\\n## Development Workflow & Version Control\\n\\n**Git Strategy**:\\n\\n- **Protected branch**: `dev` branch - no direct pushes\\n- **Feature branches**: Mandatory for all work\\n- **PR workflow**: Victor successfully resolved upstream branch issue, has open PR ready for review\\n- **Review process**: [jnxmas] reviews and merges into `dev`\\n  **Dependency Management**:\\n- **Poetry ONLY**: NOT pip - ensures library compatibility\\n- **Command**: `poetry add `\\n- **Action**: Victor + Guru ensure local environments use Poetry\\n  **Documentation**:\\n- **Docusaurus blog**: All meeting summaries posted to `blog/` for async collaboration + AI context (Cursor/Claude code context)\\n- **GitHub tasks**: Self-assignment encouraged, commenting for async feedback\\n- **Task board**: 3 tasks \\"In Progress\\" with all three team members assigned\\n\\n---\\n\\n## Critical Technical Decisions Summary\\n\\n| Component             | Decision                                        | Owner             | Status                 |\\n| --------------------- | ----------------------------------------------- | ----------------- | ---------------------- |\\n| **Vector DB**         | VectorStore (standard)                          | Team              | \u2705 Confirmed           |\\n| **Embeddings**        | NOMIC primary, Mistral backup                   | Guru              | \u2705 Confirmed           |\\n| **Orchestration**     | N8N (Docker, viety.loki.io)                     | [jnxmas]          | \ud83d\udfe1 ~2h from deployment |\\n| **Crawl Tracking**    | SQL Lite + SQL Model                            | [jnxmas]          | \ud83d\udd34 Design phase        |\\n| **LLM Providers**     | Gemini, Ollama, Mistral, OpenAI, Perplexity     | Team              | \u2705 Multi-provider      |\\n| **Opik Setup**        | Single dashboard, Dev \u2192 Prod, multiple API keys | [jnxmas]          | \ud83d\udfe1 Access pending      |\\n| **OCR Libraries**     | pdf2ocr, Tabula, pypdf (test all 3)             | Victor \u2192 [jnxmas] | \ud83d\udd34 Blocked on crawling |\\n| **Prompt Management** | Hardcoded \u2192 Opik library (future)               | Guru              | \ud83d\udd34 Not started         |\\n| **Search Agent**      | Conditional on RAG completeness                 | TBD               | \ud83d\udfe1 On hold             |\\n\\n---\\n\\n## Firecrawl Pipeline Progress (Victor\'s Focus)\\n\\n**Completed**:\\n\\n- \u2705 Debugged and fixed scraper component\\n- \u2705 Fixed crawler functionality (operational after \\"small but critical\\" config issues)\\n- \u2705 Open PR ready for review\\n- \u2705 Resolved upstream branch issue\\n  **Current Issues**:\\n- \u26a0\ufe0f Pagination settings need adjustment (tested `max_pages=10`, returned only 1 page)\\n- \u26a0\ufe0f Full document retrieval tuning required\\n  **Victor\'s Timeline**:\\n- **Mon-Wed (this week)**: Intensive work, complete Firecrawl pipeline\\n- **Thu-Sun**: Unavailable (travel to France - pre-planned holiday)\\n- **Following week**: Returns and continues contributions\\n- **Goal**: Finish Firecrawl work before Wednesday departure\\n  **Next Steps**:\\n\\n1. Victor finalizes additional commits to feature branch\\n2. Victor signals when PR ready for final review\\n3. [jnxmas] reviews and merges into `dev`\\n4. [jnxmas] tests merged pipeline on additional sources during Victor\'s absence\\n5. Once crawling complete \u2192 Apply OCR to PDFs (pdf2ocr, Tabula, pypdf testing)\\n\\n---\\n\\n## OCR Pipeline Strategy (Post-Firecrawl)\\n\\n**Target Documents**: Scanned PDFs in municipal archives (~4,000+ documents)\\n**Libraries to Test**:\\n\\n1. pdf2ocr\\n2. Tabula\\n3. pypdf\\n   **Approach**: Test all 3, compare outputs for quality\\n   **Owner**: Victor (primary), [jnxmas] (testing during Victor\'s absence)\\n   **Status**: Blocked on Firecrawl crawling completion\\n\\n---\\n\\n## Project Background & Context\\n\\n**Locki Project Evolution**:\\n\\n- Origin: Started from hackathon 2 years ago\\n- Built agents on top of Locki stack\\n- Participated in cohorts to improve functionality\\n- Previous projects:\\n  - 3D objects on-chain (paused - too early/complex, slow blockchain)\\n  - Horse racing betting strategy (15 years expert knowledge \u2192 code/data layer, not yet commercialized)\\n  - Multiverse Six / XRP experience (3D NFTs)\\n    **[jnxmas]\'s Work**:\\n- Freelancing: Apps, websites, e-commerce development\\n- Computer teacher for small children (Thursdays, 2 hours)\\n- Locki is primary passion project (\\"what makes me wake up in the morning\\")\\n- Successfully built Locki mobile app prototype\\n  **Dev Environment**:\\n- VS Code with debug scripts for one-click launch\\n- Team using Cursor IDE may need to adapt scripts\\n- Victor considering switch to VS Code for easier workflow\\n\\n---\\n\\n## Open Questions & Decisions Needed\\n\\n### For Guru (Flagged for Response):\\n\\n1. \u2705 **Vector store preference**: VectorStore confirmed, NOMIC embeddings confirmed\\n2. \u23f3 **Opik user ID/Discord username**: Needed for dashboard access grant\\n3. \u23f3 **Stack alignment review**: Read architecture blog post in repo, suggest improvements\\n4. \u23f3 **Charter agent design**: Begin development, provide update in 1-2 days\\n\\n### For Victor:\\n\\n1. \u23f3 **Opik account status**: Confirm if account exists or needs creation\\n2. \u23f3 **Firecrawl PR readiness**: Signal when ready for final review\\n3. \u23f3 **Poetry environment**: Verify local setup uses Poetry (not pip)\\n\\n### For [jnxmas]:\\n\\n1. \u23f3 **N8N deployment**: Complete final ~2 hours of setup\\n2. \u23f3 **Opik dashboard access**: Invite Guru + Victor (need usernames)\\n3. \u23f3 **Document Service requirements**: Define scope and distinction from Chat Service\\n4. \u23f3 **Crawl scheduling**: Decide frequency (daily vs. weekly) for production\\n\\n### For Team Discussion:\\n\\n1. \u23f3 **Search Agent decision**: Revisit after RAG testing complete\\n2. \u23f3 **Citizen engagement UX**: Consider simplifying contribution system if low engagement persists\\n3. \u23f3 **Effort attribution**: Finalize \\"all ores tracking template\\" for fair team contribution recognition\\n4. \u23f3 **Prompt management migration**: Timeline for moving hardcoded prompts to Opik library\\n\\n---\\n\\n## Comprehensive Task List\\n\\n### URGENT (Next 48 Hours)\\n\\n**Task 1: Complete N8N Deployment & GitHub Integration**\\n\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Finish final ~2 hours of N8N Docker deployment on viety.loki.io, configure workflows to pull issues from `audierne2026` repo, trigger charter validation agent, push validated/labeled issues back, provide API endpoint for testing\\n- **Deadline**: Within 48 hours (before Guru needs to test agent)\\n- **Dependencies**: None (infrastructure task)\\n- **Success Criteria**: N8N accessible at viety.loki.io, test workflow successfully pulls/pushes GitHub issue, API endpoint documented\\n  **Task 2: Set Up Opik Dev Environment & Team Access**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Create/configure `Ocapistaine Dev` Opik project, generate separate API keys for [jnxmas]/Guru/Victor, grant dashboard access to all team members, document key assignment and usage tracking approach\\n- **Deadline**: Before Guru starts agent development (next 24 hours)\\n- **Dependencies**: Guru\'s Opik user ID/Discord username, Victor\'s Opik account confirmation\\n- **Success Criteria**: All team members can access dashboard, separate keys functional, usage trackable per developer\\n  **Task 3: Complete Firecrawl Pipeline Implementation**\\n- **Owner**: Victor (@zcbtvag)\\n- **Description**: Finalize additional commits to Firecrawl feature branch, fix pagination settings to ensure full document retrieval, test with multiple sources, signal when PR ready for final review\\n- **Deadline**: Wednesday (before France travel)\\n- **Dependencies**: Firecrawl API keys, crawler pagination tuning\\n- **Success Criteria**: PR merged without conflicts, Firecrawl successfully crawls full test dataset, documented in code\\n  **Task 4: Build Charter Validation Agent - Core Logic**\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: Develop charter validation agent that reads citizen contribution issues from `audierne2026` repo, validates against charter rules (respectful, no naming, constructive), auto-corrects category misclassifications (7 categories), returns binary validation + corrected category, integrates Opik evaluation at every decision point\\n- **Deadline**: Update in 1-2 days, full prototype ASAP (foundation for other workflows)\\n- **Dependencies**: Access to Opik dashboard, `audierne2026` repo read access, N8N API endpoint\\n- **Success Criteria**: Agent correctly validates 95%+ test cases, Opik traces show decision transparency, category corrections work\\n\\n### HIGH PRIORITY (This Week)\\n\\n**Task 5: Build RAG Agent with Opik Integration**\\n\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: Develop core RAG agent for citizen Q&A, integrate NOMIC embeddings (primary) + Mistral (backup), implement Opik for evaluation/tracing/hallucination prevention, generate neutral contextual responses with source attribution, cross-reference municipal program data\\n- **Deadline**: Update in 1-2 days, working prototype by end of week (Jan 30-31)\\n- **Dependencies**: VectorStore setup, crawled data (start with available), Opik access\\n- **Success Criteria**: Functional RAG agent with Opik tracing active, no hallucinations in test cases, proper French language responses\\n  **Task 6: Firecrawl PR Review & Merge**\\n- **Owner**: Victor (@zcbtvag) + [jnxmas] (review)\\n- **Description**: Victor signals PR ready, [jnxmas] reviews and merges into `dev` branch, test merged pipeline functionality\\n- **Deadline**: End of week (allow Victor time for improvements)\\n- **Dependencies**: Task 3 completion\\n- **Success Criteria**: PR merged, Firecrawl pipeline functional on test sources\\n  **Task 7: Test Firecrawl on Additional Sources & Build Crawl Tracking DB**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Intensively test Victor\'s Firecrawl code on ocapistaine repo PDFs/websites and other sources beyond current scope, begin SQL Lite/SQL Model database for tracking crawled content with metadata (crawl status, RAG inclusion, content category)\\n- **Deadline**: Sunday evening (status update)\\n- **Dependencies**: Task 6 completion (merged Firecrawl code)\\n- **Success Criteria**: Multiple sources tested successfully, tracking database prototype with crawl status and categorization functional\\n  **Task 8: Explore Opik Platform Features**\\n- **Owner**: All team members\\n- **Description**: Familiarize with Opik capabilities, dashboards, prompt library, evaluation features, tracing, metrics, experiment tracking\\n- **Deadline**: Next 2-3 days (parallel with development)\\n- **Dependencies**: Opik access granted (Task 2)\\n- **Success Criteria**: Team comfortable with platform, ready to maximize hackathon showcase, documented learnings\\n  **Task 9: Poetry Dependency Management Setup**\\n- **Owner**: Victor (@zcbtvag) + Guru (@GurmeherSingh)\\n- **Description**: Ensure local dev environments use Poetry (not pip) for all library additions, verify compatible with current workflows\\n- **Deadline**: Before next library additions\\n- **Dependencies**: Poetry installed locally\\n- **Success Criteria**: No pip-related dependency conflicts, `pyproject.toml` up to date, team using `poetry add ` exclusively\\n\\n### MEDIUM PRIORITY (Next Week)\\n\\n**Task 10: Test OCR Libraries on Scanned PDFs**\\n\\n- **Owner**: Victor (@zcbtvag) \u2192 [jnxmas] (if Victor unavailable)\\n- **Description**: Test pdf2ocr, Tabula, pypdf on sample scanned PDFs from municipal archives, compare outputs for quality, select best library/combination for production\\n- **Deadline**: Immediately after crawling complete (or during Victor\'s absence)\\n- **Dependencies**: Task 3/6 completion (crawling functional)\\n- **Success Criteria**: 3 libraries tested, quality comparison documented, production OCR library selected\\n  **Task 11: Architecture Documentation Review**\\n- **Owner**: Guru (@GurmeherSingh) + Victor (@zcbtvag)\\n- **Description**: Read architecture blog post [jnxmas] created (in `ocapistaine` repo), suggest additions specifically around NOMIC embedding implementation details, RAG service integration points, any conflicts/improvements from experience\\n- **Deadline**: Next 2-3 days (before architecture freeze)\\n- **Dependencies**: Access to blog in repo\\n- **Success Criteria**: Comments/suggestions posted, team aligned on architecture\\n  **Task 12: Define Document Service Requirements**\\n- **Owner**: [jnxmas] + Guru + Victor\\n- **Description**: Collaboratively define Document Service scope: query documentation/source info, scheduled re-crawling (detect new docs), document categorization + metadata tagging, change detection logic (compare current vs. new crawls), decide if separate DB needed, clarify distinction from Chat Service\\n- **Deadline**: Next sync meeting\\n- **Dependencies**: Vector store decision (confirmed), crawl tracking DB design (Task 7)\\n- **Success Criteria**: Document Service requirements documented, team aligned, ready for implementation\\n  **Task 13: Finish All Ores Tracking Template**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Complete effort attribution tracking system for fair team contribution recognition, share with team for feedback\\n- **Deadline**: ASAP (ongoing discussion on Discord)\\n- **Dependencies**: None\\n- **Success Criteria**: Template finalized, shared on Discord, team feedback incorporated\\n  **Task 14: Follow Up with Remaining Electoral List**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Contact 4th electoral list for outreach, gauge interest in Audierne2026 project\\n- **Deadline**: Before January 31 (contributions deadline)\\n- **Dependencies**: None\\n- **Success Criteria**: All 4 lists contacted, responses documented\\n\\n### FUTURE / CONDITIONAL\\n\\n**Task 15: Search Agent Design & Implementation** (CONDITIONAL)\\n\\n- **Owner**: TBD (likely Guru)\\n- **Description**: IF RAG agent proves insufficient during testing, design and implement Search Agent as fallback for citizen queries\\n- **Deadline**: Week 2 of sprint (after RAG testing complete)\\n- **Dependencies**: Task 5 completion (RAG agent functional), RAG sufficiency evaluation\\n- **Success Criteria**: Decision documented (Search Agent needed: yes/no), if yes \u2192 design document with Opik integration plan\\n  **Task 16: Migrate Prompts to Opik Library** (FUTURE)\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: After initial hardcoded prompts working, migrate to Opik prompt library for centralized management, versioning, experimentation\\n- **Deadline**: Post-hackathon or if time permits in sprint\\n- **Dependencies**: Opik platform familiarity (Task 8), working agents with hardcoded prompts\\n- **Success Criteria**: Prompts managed in Opik, agents use library-based prompts, versioning functional\\n  **Task 17: Redis Integration for Scheduler + Task Memory**\\n- **Owner**: [jnxmas] (@[jnxmas])\\n- **Description**: Integrate Redis for APScheduler persistence and task memory across restarts\\n- **Deadline**: Post-initial prototype (when scaling/production readiness needed)\\n- **Dependencies**: Working scheduler tasks (crawl updates, GitHub monitoring)\\n- **Success Criteria**: Scheduler tasks persist across app restarts, task memory functional\\n  **Task 18: Citizen Q&A RAG Agent - Planning** (After Charter Agent)\\n- **Owner**: Guru (@GurmeherSingh)\\n- **Description**: After charter agent working, design second RAG agent iteration for citizen questions: reads validated contributions from charter agent, generates neutral contextual responses, cross-references municipal program data, no hallucinations (Opik guardrails)\\n- **Deadline**: Week 2 of sprint (after charter agent complete)\\n- **Dependencies**: Charter agent functional (Task 4), N8N workflows ready, VectorStore populated\\n- **Success Criteria**: Design document with Opik integration plan, data flow diagram\\n\\n---\\n\\n## Risk Assessment & Mitigations\\n\\n| Risk                                                            | Impact   | Mitigation                                                                                                            | Owner             | Status                           |\\n| --------------------------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------- | ----------------- | -------------------------------- |\\n| **Guru missing from stack discussion**                          | Medium   | Record meetings, request written feedback on tasks, schedule follow-up calls                                          | [jnxmas]          | \ud83d\udfe2 Mitigated (recordings shared) |\\n| **Victor unavailable Thu-Sun**                                  | Medium   | Victor completes Firecrawl by Wed, [jnxmas] tests during absence                                                      | Victor + [jnxmas] | \ud83d\udfe2 Planned                       |\\n| **Crawler pagination not returning full results**               | High     | Victor debugging this week; if blocked, escalate to team                                                              | Victor            | \ud83d\udfe1 In progress                   |\\n| **N8N deployment blocking agent testing**                       | High     | [jnxmas] prioritizes ~2h completion ASAP                                                                              | [jnxmas]          | \ud83d\udfe1 In progress                   |\\n| **Opik access blocking Guru\'s development**                     | High     | [jnxmas] grants access within 24h (need Guru\'s username)                                                              | [jnxmas]          | \ud83d\udfe1 In progress                   |\\n| **Vector store decision blocking RAG**                          | Medium   | VectorStore + NOMIC confirmed; fallback = Mistral Studio                                                              | Guru + [jnxmas]   | \ud83d\udfe2 Resolved                      |\\n| **OCR quality unknown for scanned PDFs**                        | Medium   | Test 3 libraries (pdf2ocr, Tabula, pypdf), compare outputs                                                            | Victor \u2192 [jnxmas] | \ud83d\udfe1 Planned                       |\\n| **4-week sprint timeline pressure**                             | High     | Prioritize working prototype over perfection, ruthless task board management, limit to \\"two tracks\\" (NOMIC + Mistral) | All               | \ud83d\udfe1 Ongoing                       |\\n| **First agent not live before contributions deadline (~Feb 1)** | Critical | Fast-track Charter agent development this week, daily standups                                                        | Guru + [jnxmas]   | \ud83d\udd34 Active risk                   |\\n| **Low citizen engagement with contributions**                   | Medium   | Consider UX simplification, focus on chatbot quality over contribution volume                                         | [jnxmas]          | \ud83d\udfe1 Monitoring                    |\\n| **Team still in ideation phase despite deadline pressure**      | Medium   | Shift to execution mode immediately, lock architecture decisions                                                      | All               | \ud83d\udfe1 Transitioning                 |\\n| **French language hallucinations/bias in chatbot**              | Critical | Mistral backup, heavy Opik guardrails, manual testing in French                                                       | Guru + [jnxmas]   | \ud83d\udfe1 Design phase                  |\\n| **Hackathon Opik showcase insufficient**                        | Medium   | \\"Maximize Opik at every opportunity\\", document integration patterns, trace everything                                 | Guru              | \ud83d\udfe1 In progress                   |\\n\\n---\\n\\n## Alignment Confirmations & Strategic Notes\\n\\n**\u2705 Strong Alignments**:\\n\\n- Opik-first approach aligns perfectly with hackathon goals\\n- Multi-provider LLM strategy provides resilience and cost optimization\\n- French language focus (Mistral) addresses political optics and user needs\\n- Modular ETL architecture enables swapping components without rewrites\\n- Team expertise (NOMIC, Streamlit, VectorStore) matches stack decisions\\n- Task ownership clear and distributed well (Guru = agents, Victor = crawling, [jnxmas] = infrastructure/orchestration)\\n  **\u26a0\ufe0f Potential Misalignments**:\\n- **Timeline vs. scope**: 4 weeks for full pipeline (crawling + OCR + RAG + Charter agent + chatbot + Opik showcase) is aggressive\\n  - **Mitigation**: Limit to \\"two tracks\\" (NOMIC primary, Mistral backup), prioritize Charter agent + basic RAG over perfect Search Agent\\n- **Citizen engagement vs. effort**: Low contribution volume may not justify complex validation workflow\\n  - **Mitigation**: Focus on chatbot quality (broader citizen reach) over contribution automation\\n- **Team availability gaps**: Victor\'s Thu-Sun absence, Guru\'s jet lag, [jnxmas]\'s teaching commitment\\n  - **Mitigation**: Strong async collaboration (recordings, blog summaries, GitHub comments), clear handoffs\\n    **\ud83d\udd0d Clarifications Needed**:\\n- **Document Service vs. Chat Service**: Distinction still fuzzy (addressed as: Document = search/crawl management; Chat = conversational interface, but needs formal requirements doc)\\n- **Search Agent necessity**: Conditional decision pending RAG testing (good pragmatic approach)\\n- **Opik dashboard structure**: Single unified dashboard confirmed, but team needs to explore platform features to maximize value\\n  **\ud83d\udcc8 Recommended Focus Areas**:\\n\\n1. **This week**: Charter agent + RAG agent + Firecrawl completion + Opik access = critical path\\n2. **Next week**: OCR testing + Document Service definition + crawl tracking DB = data pipeline completion\\n3. **Week 3-4**: Integration, testing, French language validation, Opik showcase polish, citizen-facing chatbot MVP\\n\\n---\\n\\n## Documentation & Knowledge Management\\n\\n**Current Practices** (Strong):\\n\\n- \u2705 Docusaurus blog: Meeting summaries posted to `blog/` for async collaboration\\n- \u2705 GitHub tasks: Self-assignment, commenting for feedback\\n- \u2705 Task board: 3 tasks \\"In Progress\\" with assignments\\n- \u2705 Architecture blog post: Created for team review + AI context (Cursor/Claude)\\n- \u2705 Meeting recordings: Shared for async team members (Guru)\\n- \u2705 \\"Tell what we do and do what we tell\\": Commitment tracking across conversations\\n  **Improvements Suggested**:\\n- \ud83d\udcdd Document Opik integration patterns as you build (hackathon showcase value)\\n- \ud83d\udcdd Create crawl tracking DB schema diagram (avoid ambiguity)\\n- \ud83d\udcdd Formalize Document Service requirements doc (per Task 12)\\n- \ud83d\udcdd Keep citizen-facing deliverable timeline visible (dashboard/Gantt chart)\\n- \ud83d\udcdd Document OCR library comparison results (Task 10)\\n\\n---\\n\\n## Next Sync Meeting Agenda (Suggested)\\n\\n1. **N8N + Opik access**: Confirm both unblocked ([jnxmas] updates)\\n2. **Firecrawl PR status**: Review and merge if ready (Victor + [jnxmas])\\n3. **Charter agent progress**: Demo initial prototype, discuss Opik traces (Guru)\\n4. **RAG agent update**: Share approach, blockers, timeline (Guru)\\n5. **Crawl tracking DB**: Review schema design ([jnxmas])\\n6. **Document Service requirements**: Collaborative definition session (All)\\n7. **Task board review**: Close completed tasks, reprioritize open items (All)\\n8. **Opik showcase strategy**: What metrics/traces will impress hackathon judges? (All)\\n\\n---\\n\\n## Status Dashboard\\n\\n**Overall Progress**:\\n\\n- \ud83d\udfe2 **Architecture**: Finalized (VectorStore, NOMIC, Mistral, N8N, Opik strategy confirmed)\\n- \ud83d\udfe1 **Firecrawl Pipeline**: Victor progressing, PR open, completion target Wed\\n- \ud83d\udfe1 **N8N Deployment**: ~2 hours from completion (infrastructure blocker)\\n- \ud83d\udfe1 **Opik Setup**: Account exists, team access pending (need usernames)\\n- \ud83d\udd34 **Charter Agent**: Not started (blocked by Opik access + N8N)\\n- \ud83d\udfe1 **RAG Agent**: Starting development, update expected 1-2 days\\n- \ud83d\udd34 **OCR Pipeline**: Blocked on crawling completion\\n- \ud83d\udd34 **Crawl Tracking DB**: Design phase\\n- \ud83d\udfe2 **Team Coordination**: Strong communication, clear roles, async collaboration working\\n- \ud83d\udfe1 **Political Outreach**: 3/4 lists contacted, positive signals\\n- \ud83d\udd34 **Citizen Engagement**: Low contribution volume (UX consideration needed)\\n- \ud83d\udfe2 **Documentation**: Blog summaries active, recordings shared, task tracking functional\\n  **Open High-Priority Tasks** (Top 5):\\n\\n1. **\ud83d\udd34 URGENT**: Complete N8N deployment ([jnxmas], &lt;48h) - blocks agent testing\\n2. **\ud83d\udd34 URGENT**: Set up Opik team access ([jnxmas], &lt;24h) - blocks Guru\'s development\\n3. **\ud83d\udd34 URGENT**: Complete Firecrawl pipeline (Victor, by Wed) - data ingestion dependency\\n4. **\ud83d\udd34 HIGH**: Build Charter validation agent (Guru, update 1-2 days) - critical path for hackathon\\n5. **\ud83d\udd34 HIGH**: Build RAG agent with Opik (Guru, update 1-2 days) - citizen-facing deliverable\\n   **Next Milestones**:\\n\\n- **Week 1 Goal (by ~Jan 30-31)**: Charter validation agent functional with Opik tracing + Firecrawl pipeline merged + N8N orchestrating GitHub workflows + RAG agent prototype\\n- **Immediate Blockers**: N8N deployment (&lt;48h), Opik access (&lt;24h), Firecrawl pagination tuning (&lt;3 days)\\n- **Hackathon Prototype Delivery**: ~mid-February 2026 (2.5 weeks remaining from late Jan)\\n- **Critical Path**: Crawling \u2192 OCR \u2192 Vector DB \u2192 RAG + Opik \u2192 Chatbot MVP \u2192 French language validation\\n  **Team Availability This Week**:\\n- **Guru**: Available now (jet-lagged but active), development starting\\n- **Victor**: Intensive Mon-Wed, unavailable Thu-Sun (France travel)\\n- **[jnxmas]**: Full availability, prioritizing N8N/Opik/testing during Victor\'s absence\\n  **Risk Level**: \ud83d\udfe1 **MEDIUM-HIGH** - Timeline tight, first agent not yet live despite approaching contributions deadline, but team aligned and architecture solid. Immediate focus on unblocking N8N + Opik access will shift to \ud83d\udfe2 GREEN if completed within 48h.\\n\\n---\\n\\n## Action Summary - What Happens Next\\n\\n**Immediate (Next 24 Hours)**:\\n\\n1. [jnxmas] completes N8N deployment (~2 hours)\\n2. [jnxmas] sets up Opik team access (needs Guru + Victor usernames via Discord)\\n3. Guru shares Opik user ID/Discord username\\n4. Victor continues Firecrawl pagination debugging\\n5. Team explores Opik platform features once access granted\\n\\n**This Week (Next 3-7 Days)**:\\n\\n1. Victor completes Firecrawl PR by Wednesday\\n2. [jnxmas] reviews and merges Firecrawl PR\\n3. Guru develops Charter validation agent, provides update in 1-2 days\\n4. Guru develops RAG agent prototype, provides update in 1-2 days\\n5. [jnxmas] tests Firecrawl on additional sources during Victor\'s absence\\n6. [jnxmas] begins crawl tracking DB with SQL Model\\n7. Guru + Victor review architecture blog post, suggest improvements\\n8. All team members familiarize with Opik capabilities\\n\\n**Next Week (Week 2 of Sprint)**:\\n\\n1. OCR library testing begins (Victor returns, or [jnxmas] covers)\\n2. Document Service requirements defined collaboratively\\n3. RAG agent fully functional with Opik guardrails\\n4. Charter agent deployed to N8N workflows\\n5. Crawl tracking DB prototype operational\\n6. Architecture frozen, team shifts to integration phase\\n\\n**Week 3-4 (Final Sprint)**:\\n\\n1. Full pipeline integration testing\\n2. French language validation and bias checking\\n3. Citizen-facing chatbot MVP deployment\\n4. Opik showcase polish (metrics, traces, dashboards, experiment tracking)\\n5. Hackathon submission preparation\\n6. Final outreach to 4th electoral list\\n7. Documentation finalization\\n\\n---\\n\\n**Confidence Level**: \ud83d\udfe1 **CAUTIOUSLY OPTIMISTIC** - Strong team, solid architecture, clear tasks, but timeline aggressive and first agent not yet live. Success depends on unblocking N8N + Opik access within 48h and Charter agent prototype within 1 week. Victor\'s Wed deadline and Guru\'s jet lag are manageable with current plans.\\n**Recommendation**: Daily async standups (Discord) this week to track Charter agent + Firecrawl progress. Consider lightweight demo/review session Friday to validate week 1 progress before weekend."},{"id":"meher-jnxmas-letscode","metadata":{"permalink":"/fr/blog/meher-jnxmas-letscode","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-16-meher-jnxmas.mdx","source":"@site/blog/2026-01-16-meher-jnxmas.mdx","title":"Lets us code","description":"Project Overview & Vision","date":"2026-01-16T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"}],"readingTime":2.28,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"meher-jnxmas-letscode","title":"Lets us code","authors":["jnxmas"],"tags":["encode","civictech"]},"unlisted":false,"prevItem":{"title":"Let us choose the stack","permalink":"/fr/blog/meeting-ocapistaine-1"},"nextItem":{"title":"\xd2 Capistaine Kick-off","permalink":"/fr/blog/ocapistaine-hackathon-kickoff"}},"content":"### Project Overview & Vision\\n\\n- The core idea is building an **AI-powered civic transparency platform** focused on local democracy, citizen engagement, and real-world issues (starting with inspiration from India, but with potential global scalability).\\n- Goal: Create a standardized, bullshit-free alternative to Twitter/X discussions for civic topics \u2014 avoiding noise and enabling structured transparency for citizens, investors, and \\"democracy islands\\" (e.g., places like Audierne).\\n- It\'s tied to the **\\"Commit to Change\\" AI Agents Hackathon** (powered by Opik / Comet), running ~4 weeks starting mid-January 2026, with categories like Community Impact.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Hackathon Focus & Judging Criteria Emphasis\\n\\n- Heavy emphasis on **Opik integration** for observability, evaluation, metrics, dashboards, experiment tracking, and improving LLM/agent quality.\\n- Key criteria to nail: Functionality, real-world relevance (New Year\u2019s/civic goals), effective LLM/agent use, robust evaluation/monitoring, and deep Opik workflow integration (not just fluff).\\n- Plan: Automate Opik feedback into the platform for a \\"virtuous circle\\" of optimization. Showcase Opik at every stage (dev workflow, runtime monitoring, etc.).\\n- Strategy: Prioritize smooth, meaningful Opik use \u2192 even if some parts feel like \\"fluff,\\" lean into it for judging scores.\\n\\n### Team & Collaboration Setup\\n\\n- You created/invited Meher to the project using team join code: **0e10f89d** (valid until Jan 17, 2026).\\n- Repo: **Ocapistaine** (on GitHub) \u2014 you updated it with:\\n  - Clear license\\n  - Collaboration addendum / agreements\\n  - Docusaurus as submodule for docs\\n  - Project board with tasks (including Opik-specific ones)\\n- You proposed a fair structure for handling prize money / motivation (Meher called it \\"very clean\\" and liked it).\\n- Meher was pending \u2192 accepted invite; you both coordinated joining the hackathon portal/team.\\n- Another collaborator (Vic) self-assigned tasks.\\n- You shared the kickoff doc: https://docs.locki.io/blog/ocapistaine-hackathon-kickoff (titled \\"\xd2 Capistaine Kick-off | AI-Powered Civic Transparency for Local Democracy\\").\\n\\n### Monetization & Long-Term Ideas\\n\\n- You have ideas for monetizing / turning it into a full startup (trust-based, you\'ll share more).\\n- Potential global expansion discussed, but start focused (e.g., India as strong testbed).\\n- References to past hackathon success (you + Satish, 4th place with on-chain 3D objects + AI chatbot).\\n- Avoid overkill like Decidim platforms \u2014 keep it practical and thrilling.\\n\\n### Recent Status & Next Steps\\n\\n- Meher was occasionally busy/catching up (dinner, out, etc.) but engaged.\\n- As of last messages (~Jan 15\u201316, 2026):\\n  - Everyone\'s in the team/repo.\\n  - Ready to start **coding** (both excited: \\"tickles in fingers\\").\\n  - Emphasis on transparent task assignment (\\"tell what we do and do what we tell\\").\\n  - Call happened in Ocapistaine channel.\\n  - Brainstorming better Opik showcases ongoing.\\n\\n**Overall vibe**: Enthusiastic, trusting partnership (\\"I trust you!\\"). You\'re leading repo/docs/setup/strategy; Meher is on board, catching up, and eager to code + highlight Opik. Project is now properly set up and ready to build \u2014 focus on delivering a functional, Opik-heavy prototype for the hackathon deadline."},{"id":"ocapistaine-hackathon-kickoff","metadata":{"permalink":"/fr/blog/ocapistaine-hackathon-kickoff","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-15-let-the-journey-begin.mdx","source":"@site/blog/2026-01-15-let-the-journey-begin.mdx","title":"\xd2 Capistaine Kick-off","description":"AI-Powered Civic Transparency for Local Democracy","date":"2026-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Encode hackathon","permalink":"/fr/blog/tags/encode","description":"Information from the Encode hackathon"},{"inline":false,"label":"civitech","permalink":"/fr/blog/tags/civictech","description":"Citizen technologies and open source for the public good"}],"readingTime":2.17,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"ocapistaine-hackathon-kickoff","title":"\xd2 Capistaine Kick-off","authors":["jnxmas"],"tags":["encode","civictech"]},"unlisted":false,"prevItem":{"title":"Lets us code","permalink":"/fr/blog/meher-jnxmas-letscode"},"nextItem":{"title":"Project scope - Victor + JNS","permalink":"/fr/blog/victor-intro-project description"}},"content":"**AI-Powered Civic Transparency for Local Democracy**\\n\\n## My 2026 Resolution\\n\\n:::tip The Promise\\nThis year, I will finally understand my local elections and get involved as a citizen.\\n:::\\n\\nSound familiar? Every election cycle, millions of citizens want to participate but face the same wall: scattered documents, administrative jargon, and no time to dig through years of municipal decisions.\\n\\n**This January, I stopped just wishing \u2014 and started building.**\\n\\n\x3c!-- truncate --\x3e\\n\\n## What We\'re Building\\n\\n\xd2 Capistaine is my answer to the civic engagement resolution we\'ve all made (and broken). It\'s an AI-powered transparency tool that:\\n\\n| Feature               | Description                                               |\\n| --------------------- | --------------------------------------------------------- |\\n| **Document Crawling** | Index 4,000+ municipal documents with Firecrawl + OCR     |\\n| **Citizen Q&A**       | Answer questions in plain language via RAG                |\\n| **Quality Tracking**  | Monitor LLM accuracy with Opik (hallucination detection)  |\\n| **Multi-Channel**     | N8N workflows for Facebook, email, and chatbot engagement |\\n\\n:::info Live Platform\\nSupporting [audierne2026.fr](https://audierne2026.fr) \u2014 a participatory democracy platform where citizens co-create the 2026 municipal program.\\n:::\\n\\n## Progress Update (Checkpoint 1)\\n\\n### Status Overview\\n\\n| Component              | Status | Details                                                        |\\n| ---------------------- | :----: | -------------------------------------------------------------- |\\n| **audierne2026.fr**    |   \u2705   | Jekyll platform live, citizens contributing                    |\\n| **Document Corpus**    |   \ud83d\udfe1   | 42 Gwaien bulletins collected, 4,000+ arr\xeat\xe9s identified       |\\n| **Firecrawl Pipeline** |   \ud83d\udd34   | Infrastructure designed, crawling not yet operational          |\\n| **Opik Integration**   |   \ud83d\udfe1   | Tracing architecture planned, awaiting RAG implementation      |\\n| **N8N Workflows**      |   \ud83d\udfe1   | Vaettir repo created, FB/email integration designed            |\\n| **RAG System**         |   \ud83d\udd34   | Vector store + retrieval pipeline pending                      |\\n| **Documentation**      |   \u2705   | [docs.locki.io](https://docs.locki.io) live with methodologies |\\n\\n### What\'s Working\\n\\n- Live participation platform with real citizen contributions\\n- Dual-license structure (Apache 2.0 + ELv2) for open collaboration\\n- Bilingual documentation (EN/FR)\\n- Project planning and task tracking on GitHub\\n\\n### Next Steps\\n\\n1. **Fix Firecrawl pipeline** \u2014 Get municipal document crawling operational\\n2. **Deploy Opik tracing** \u2014 LLM observability from day one\\n3. **Build RAG retrieval** \u2014 With hallucination guardrails\\n4. **Launch citizen Q&A** \u2014 First chatbot interactions\\n\\n## Hackathon Tracks\\n\\n| Track                         | Why We Qualify                                                 |\\n| ----------------------------- | -------------------------------------------------------------- |\\n| **Social & Community Impact** | Civic transparency tool enabling local democracy participation |\\n| **Best Use of Opik**          | LLM-as-judge evaluations + tracing for RAG quality assurance   |\\n\\n:::note Democracy Can\'t Afford Hallucinations\\nWhen citizens ask \\"What happened with the school budget?\\", the answer must be accurate and sourced. Opik helps us guarantee that.\\n:::\\n\\n## Team\\n\\n| Name                      | Role                          | GitHub                                             |\\n| ------------------------- | ----------------------------- | -------------------------------------------------- |\\n| Jean-No\xebl Schilling       | Project Lead / Backend        | [@jnschilling](https://github.com/jnschilling)     |\\n| Victor A                  | Backend Python                | [@zcbtvag](https://github.com/zcbtvag)             |\\n| GurmeherSingh             | ML Engineer                   | [@GurmeherSingh](https://github.com/GurmeherSingh) |\\n| _(open for contributors)_ | Frontend / UX / Communication | \u2014                                                  |\\n\\n## Links\\n\\n| Resource      | URL                                                             | Public/private |\\n| ------------- | --------------------------------------------------------------- | -------------- |\\n| Live Platform | [audierne2026.fr](https://audierne2026.fr)                      | public         |\\n| Documentation | [docs.locki.io](https://docs.locki.io)                          | public         |\\n| GitHub        | [locki-io/ocapistaine](https://github.com/locki-io/ocapistaine) | private ATM    |\\n| Project Board | [GitHub Projects](https://github.com/orgs/locki-io/projects/2)  | public         |\\n\\n---\\n\\n_If AI can help us keep our New Year\'s resolutions, maybe the most impactful one is: becoming a better citizen._"},{"id":"victor-intro-project description","metadata":{"permalink":"/fr/blog/victor-intro-project description","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-14-meeting.md","source":"@site/blog/2026-01-14-meeting.md","title":"Project scope - Victor + JNS","description":"Location: Discord voice chat","date":"2026-01-14T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"}],"readingTime":9.05,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"victor-intro-project description","title":"Project scope - Victor + JNS","authors":["jnxmas"],"tags":["meeting"]},"unlisted":false,"prevItem":{"title":"\xd2 Capistaine Kick-off","permalink":"/fr/blog/ocapistaine-hackathon-kickoff"},"nextItem":{"title":"Hackathon kickoff meeting","permalink":"/fr/blog/encode-kickoff"}},"content":"> Location: Discord voice chat\\n> Attendees: jnxmas, Victor\\n\\n## Overview\\n\\nThis document summarizes a series of project meetings focused on building a community-focused AI application for a local election. The discussions cover team composition and recruitment, defining the project\'s scope for a hackathon, and outlining the technical architecture. Key activities include automating the processing of community contributions, developing a neutral chatbot to compare political programs, and initiating web crawling operations to gather data. The plan involves using technologies like Firecrawl, N8N, Pydantic, and a Retrieval-Augmented Generation (RAG) system, with a strong emphasis on collaborative development practices via GitHub.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Key Topics\\n\\n- Two new potential members from Audierne, France, were identified. They are developers focused on websites but are new to AI and Python, so they are considered to be starting from scratch.\\n- Their primary value is their familiarity with the local context of the project (audierne2026), making them a potential bridge to the local population. They are seen as good candidates for an \\"observer\\" role within the hackathon.\\n- They are connected to one of four local political lists, which is interested in participative community movements.\\n- An Indian developer named Satish, with whom a speaker previously worked on an AWS and Next.js project in a 2023 hackathon, is a potential collaborator. However, he is currently cautious about joining due to being busy with his job.\\n- A French individual named Max, who specializes in SEO and social media strategy, was mentioned but is not a coder.\\n- An Indian machine learning specialist, referred to as \\"Meher,\\" is considering joining. He is seen as a key \\"third guy\\" ML for the application architecture.\\n- There was a concern that the project\'s connection to a local election might disqualify it from the hackathon.\\n- A team member named Rebecca clarified in a general chat that the project is eligible to be submitted under the \\"social community impact\\" category.\\n- The team was advised that all questions should be posted in the general chat, as Rebecca will not be replying to DMs.\\n- Progress has been made on the project\'s GitHub Kanban board, with P0 tasks and some unprioritized tickets added.\\n- The data crawling phase (\\"filecrawl\\") is ready to start with an initial dataset of 150 links and 4,000 PDFs that require OCR. The speaker has paused this work to incorporate more contributions.\\n- The N8N orchestration workflow is nearly complete and ready for deployment.\\n  - It will be hosted on a server with a 6-core CPU and 16 gigabytes of RAM.\\n  - The team will consider moving to Vercel if the server cannot handle the load.\\n- N8N is a low-code/no-code platform for building workflows, and an example was shown for automating posts based on GitHub repository issues.\\n- The setup is encapsulated in Docker, making it easier to run.\\n- The project\'s code and tasks will be managed in the Ocapistan repository on GitHub.\\n- A key initial task is to push the ideation file (`ideation 13.1.2026`) to the main branch to serve as a foundation for future work.\\n- The team will use a feature branch workflow:\\n  - For each task, a developer will create a new feature branch from the main branch.\\n  - Once the task is complete, the branch will be pushed to the repository for review by others.\\n  - After review and debugging, the branch will be merged and closed.\\n- The team agreed to prioritize the Firecrawl operation as the starting point, despite its potential difficulty.\\n- Two team members will conduct parallel trials on different fire crawling tasks to gain experience and share learnings.\\n- Each member should get their own free Firecrawl API key, as they may need to use multiple free accounts by registering with different emails to maximize free API calls.\\n- The initial scraping task will target a list of PDFs from a specific URL (`script marie arete mary`).\\n- PDF processing will require testing various libraries like `pdf2ocr`, Tabula, and `pypdf` to find the most effective one.\\n- The team needs to develop a method to identify and set aside documents that only contain signatures, as this information has no value for the LLM.\\n- The project will use Python with type hinting and Pydantic for data handling to improve code quality.\\n- A modular \\"separation of concerns\\" approach will be used for the ETL (Extract, Transform, Load) process.\\n  - Extraction, transformation, and loading will be handled by separate workflows, likely implemented as three distinct classes.\\n  - This modularity will allow for different extraction methods (e.g., for plain text, HTML with Beautiful Soup, or OCR for PDFs) to be developed and called as needed.\\n- The project will use Ocapistan for code management, N8N for workflows, and a flexible AI provider handled by OPIC.\\n- Team members do not need to work at the same time but must communicate effectively. Progress will be tracked through changes in the project repository.\\n- Developers should assign tasks to themselves and break them down into smaller sub-tasks.\\n- Direct discussions will be necessary when merging work on the same files to resolve conflicts.\\n- **Current Process (Manual):**\\n  - Contributions are received via email.\\n  - They are manually reviewed against a \\"chart of contribution\\" to ensure they meet the criteria.\\n  - If approved, they are manually copy-pasted into a GitHub issue.\\n  - A daily summary of contributions is automatically posted to Facebook via M8N, but this post is anonymous and lacks detail.\\n- **Proposed Automated Process:**\\n  - The goal is to automate the entire workflow from email receipt to GitHub issue creation.\\n  - An AI agent will be developed to judge whether an incoming contribution respects the \\"chart of contribution.\\"\\n  - This agent will be part of the \\"OKAPI stand,\\" which will house all agents and the RAG system for the project.\\n- **Purpose:** After a contribution is validated and becomes a GitHub issue, a \\"creative agent\\" (also called the Okapi Sten proper) will process it.\\n- **Functionality:**\\n  - The agent generates an AI-made reply that contextualizes the new contribution.\\n  - It cross-references the submission with previous contributions in the same category to find echoes and avoid repetition.\\n  - The reply includes links to the sources used to construct the contextualization.\\n- **Handling New vs. Existing Topics:**\\n  - The workflow must handle two cases: when a contribution is for a brand-new category, and when it relates to a previously discussed topic.\\n  - In the latter case, the system will search existing issues and the RAG system to build a comprehensive answer.\\n- **LLM Testing:**\\n  - Grok has been used for initial testing. It was effective at searching for context online (including the audierne2026 project) and generating relevant, though coincidental, replies.\\n  - The team discussed that Grok\'s ability to search and synthesize information acts similarly to a basic RAG system.\\n- **RAG System Development:**\\n  - A dedicated RAG (Retrieval-Augmented Generation) system will be built to avoid repetitive outputs and manage context efficiently.\\n  - The team needs to decide how to store source links and other data for the RAG system, considering a NoSQL database like MongoDB for flexibility. A vector store will be used for training on gathered data.\\n- **Key Dates:**\\n  - The election preparation period is currently underway.\\n  - Contribution collection will continue until at least January 31.\\n  - The election day is around March 15-22.\\n- **February Focus:**\\n  - Work in February will focus purely on developing the chatbot.\\n  - The chatbot will be used to compare the programs of the four enlisted municipal lists.\\n  - It will be designed to provide neutral, impartial comparisons on topics like lodging, culture, and budget realism.\\n- **Using OPIK:**\\n  - The OPIK framework will be used to evaluate every AI interaction to ensure quality and impartiality.\\n  - The team is considering creating a feedback loop where OPIK\'s evaluations could automatically improve the prompts in N8N.\\n- **Maintaining Neutrality:**\\n  - A major challenge is ensuring the chatbot remains neutral and does not generate sycophantic or biased responses based on leading questions from users.\\n  - The system may need multiple prompts to check for constraints like budget, realism, and political neutrality before generating a reply.\\n\\n## Open Issues & Risks\\n\\n- It is unclear how the new team members from Audierne, who have limited technical experience in AI, will be integrated into the project.\\n- The availability of a key potential collaborator, Satish, is uncertain due to his current work commitments.\\n- The machine learning specialist, Meher has not yet confirmed if he will join the team.\\n- It is undecided how to best store source links and data for the RAG system, though a NoSQL database is being considered.\\n- It is unclear which LLMs (e.g., Gemini) will be chosen for the final implementation.\\n- A key challenge will be designing the chatbot to remain neutral and avoid generating biased responses to leading questions.\\n- The project\'s success depends on receiving a sufficient number of community contributions, which requires incentivizing and motivating people to participate.\\n\\n## Action Items\\n\\n- [ ] Prioritize project tasks.\\n- [ ] Set up a server for the Vaettir repo so the team can access it with a password.\\n- [ ] Start by building workflows, with more coding to begin next week.\\n- [ ] Set up an ollama platform to experiment with local LLMs.\\n- [ ] Push the `ideation 13.1.2026` file to the main Ocapistaine repository.\\n- [ ] Each team member to get a free Firecrawl API key.\\n- [ ] Begin experimenting with Firecrawl by creating a new branch on the Ocapistaine repository.\\n- [ ] Start working on scraping the documents from the \\"script marie arret\xe9 maririe\\" task.\\n- [ ] Test different PDF reading libraries (`pdf2ocr`, Tabula, `pypdf`) to determine the best option for the project.\\n\\n> **AI Suggestion**\\n> AI has identified the following issues that were not concluded in the meeting or lack clear action items; please pay attention:\\n>\\n> 1. **Critical Staffing and Team Formation Risk:** The project faces a significant risk of stalling due to unresolved team composition. Two key experts, developer Satish and machine learning specialist \\"Mayer,\\" have not committed to the project, leaving critical skill gaps. A clear action plan is needed to secure their participation or find qualified alternatives immediately to ensure the project can proceed.\\n> 2. **Unresolved Core Chatbot Neutrality:** A fundamental and unresolved challenge is how to technically implement and guarantee the election chatbot\'s neutrality and impartiality. There is no defined strategy for preventing the AI from giving biased responses, especially when faced with leading or manipulative user questions, which poses a major reputational and functional risk to the project\'s core objective.\\n> 3. **Lack of a Defined Community Contribution Workflow:** The entire process for receiving, validating, and integrating community-submitted content is undefined. This includes the creation of an AI agent to automate judging submissions and a clear workflow for handling both new and existing topics. Without this, the project cannot scale or effectively leverage community input, which is stated as a dependency for success.\\n> 4. **Undefined Technical Foundation for Data Processing and Storage:** Key decisions about the project\'s technical architecture are still pending. The team has not selected a database for the RAG system (e.g., NoSQL/MongoDB) or the specific Large Language Models (LLMs) for the final implementation. Furthermore, the method for processing varied document types like PDFs remains uncertain. These foundational decisions must be made to avoid delays in development."},{"id":"encode-kickoff","metadata":{"permalink":"/fr/blog/encode-kickoff","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2026-01-13-encode_hackathon.md","source":"@site/blog/2026-01-13-encode_hackathon.md","title":"Hackathon kickoff meeting","description":"Date & Time04:06","date":"2026-01-13T00:00:00.000Z","tags":[{"inline":false,"label":"Meeting","permalink":"/fr/blog/tags/meeting","description":"Meeting tag description"}],"readingTime":16.75,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"encode-kickoff","title":"Hackathon kickoff meeting","authors":["jnxmas"],"tags":["meeting"]},"unlisted":false,"prevItem":{"title":"Project scope - Victor + JNS","permalink":"/fr/blog/victor-intro-project description"},"nextItem":{"title":"Locki Labs in 2025 - Introducing Valkyria","permalink":"/fr/blog/locki-in-2025"}},"content":"> Date & Time: 2026-01-13 19:04:06\\n> Location: online presentation\\n> `AI Agent Hackathon` `New Year\'s Resolutions` `AI Evaluation`\\n\\n## Theme\\n\\nThis lecture introduces the \\"Commit to Change AI Agent Hackathon,\\" a four-week online event challenging participants to build AI agents that help users stick to their New Year\'s resolutions. The event offers $30,000 in prizes across five tracks: Productivity, Personal Growth, Social Impact, Health/Wellness, and Financial Health. It emphasizes the importance of AI evaluations, defining them as structured measurements of system behavior. The lecture details the hackathon\'s timeline, submission requirements using the ENCODE platform, and the mandatory use of the OPIC tool for evaluation, guiding participants from ideation to final project submission.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Takeaways\\n\\n1.  Introduction to the Commit to Change AI Agent Hackathon.\\n2.  The hackathon\'s goal is to build AI that turns New Year\'s resolutions into real results.\\n3.  Hackathon registration is required on the Encode Cloud platform for all participants, including those from Luma.\\n4.  The hackathon is sponsored by Comet, with supporting partners Basel and Google DeepMind.\\n5.  This is a four-week online hackathon with up to $30,000 in prizes.\\n6.  Statistics on New Year\'s resolutions: 23% give up within 13 days, and 43% give up by the end of January.\\n7.  Hackathon advice: Start with a problem you have faced and build a unique solution.\\n8.  The hackathon features five thematic tracks: Productivity and Work Habits, Personal Growth and Learning, Social and Community Impact, Health, Fitness and Wellness, and Financial Health.\\n9.  It\'s recommended to focus on one category to create a high-quality, specialized app.\\n10. There is an overall challenge for the \'Best use of OPIC\' for projects showcasing excellent evaluation and observability.\\n\\n## Highlights\\n\\n- `\\"AI evals are what turn that sort of really cool, fun prototype into a system that you can actually iterate on with confidence and start to think about exposing to the real world and to real people.\\"-- Abby`\\n- `\\"What\'s even cooler than a really cool prototype is, in my opinion, a cool tool that you can actually use in the real world on real data. And for that, you need some sort of system of evaluations.\\"-- Abby`\\n- `\\"Evaluation turns guesswork into science.\\"-- Abby`\\n- `\\"AI evaluations are how we turn random iteration into progress, and they give us a repeatable way to measure behavior, compare changes, and improve systematically instead of guessing.\\"-- Abby`\\n\\n## Chapters & Topics\\n\\n### Hackathon Overview and Goal\\n\\n> The Commit to Change AI Agent Hackathon is a four-week online event starting in January 2026, aimed at building AI agents and LLM-powered apps that help people stick to their New Year\'s resolutions and goals. It offers up to $30,000 in prizes.\\n\\n- **Keypoints**\\n  - The hackathon runs for four weeks online.\\n  - The goal is to build AI/LLM apps to help users stick to their goals.\\n  - There\'s a prize pool of up to $30,000.\\n  - It is sponsored by Comet, with support from Basel and Google DeepMind.\\n  - Participants must register on the Encode Cloud platform to get all updates and access resources.\\n- **Explanation**\\n  The hackathon is structured to guide participants from ideation to final submission. It includes workshops, deadlines to ensure progress, and resources provided by sponsors like Comet and partners like Google DeepMind. The central theme is leveraging AI to address the common problem of people giving up on their resolutions. Statistics show 23% of people give up 13 days into January, and 43% give up by the end of the month, highlighting the target audience for the projects.\\n\\n### Hackathon Tracks and Challenges\\n\\n> The hackathon is structured around five thematic tracks for projects, plus an overall challenge. The tracks are: Productivity and Work Habits, Personal Growth and Learning, Social and Community Impact, Health, Fitness and Wellness, and Financial Health. The overall challenge is for the \'Best Use of OPIC\', rewarding projects with excellent evaluation and observability.\\n\\n- **Keypoints**\\n  - Productivity and Work Habits: Build tools for smarter work and better routines.\\n  - Personal Growth and Learning: Build apps for learning new skills or developing self-awareness.\\n  - Social and Community Impact: Build tools for organizing communities or supporting environmental/social action.\\n  - Health, Fitness and Wellness: Build solutions for fitness, mental health, or general well-being.\\n  - Financial Health: Build AI/LLM apps for budgeting, saving, or understanding money.\\n  - Best Use of OPIC: A special category for projects with excellent evaluation and observability.\\n- **Explanation**\\n  Participants should choose one of the five themes to focus their project on. The themes are broad to accommodate a wide range of ideas. The \'Health, Fitness and Wellness\' category is noted as a particularly common area for New Year\'s resolutions. In addition to the thematic challenges, all projects are eligible for the \'Best Use of OPIC\' challenge, sponsored by Comet. This special prize can be won in conjunction with a thematic prize.\\n- **Considerations**\\n- Focus on one category rather than trying to build an app that spans multiple, as an app that does one thing well is better than one that does four things less well.\\n- Start with a problem that you yourself have faced to understand it well.\\n- Come up with a solution that sets you apart from everyone else; build something interesting and unique.\\n- Don\'t just do the bare minimum base idea; build on top of it.\\n- The best use of OPIC category can be won alongside a theme prize, which is the only two-in-one win possible.\\n\\n### Hackathon Timeline and Submission Requirements\\n\\n> The hackathon has a structured timeline with key deadlines and specific submission requirements for the final project. The timeline spans four weeks, starting with ideation, moving to building, and culminating in a final submission.\\n\\n- **Keypoints**\\n  - Week 1: Ideation and Project Creation Deadline.\\n  - Week 2: Building and a workshop on Gemini 3.\\n  - Week 2/3: Mid-hackathon Deadline (submit GitHub repo and description).\\n  - Final Submission Deadline: February 8th, 23:59 UTC-12.\\n  - Required final submission items: Video pitch with demo and public code base.\\n  - Recommended submission items: Hosted site and a presentation.\\n  - The mid-hackathon deadline forces early and regular code commits.\\n- **Explanation**\\n  The timeline is designed to keep participants on track.\\n\\n- Week 1: Launch, ideation, and a \'Project Creation Deadline\' to commit to an idea and team.\\n- Week 2: Start building, with a workshop from Google DeepMind on Gemini 3.\\n- End of Week 2/Start of Week 3: \'Mid-hackathon Deadline\' requiring submission of a GitHub repo and project description. This is not judged but ensures progress.\\n- Final Submission Deadline: February 8th at one minute to midnight, UTC-12. This means you can submit if it\'s still before midnight anywhere in the world.\\n  Final submissions must include a video pitch with a demo, a public codebase, and optionally a hosted site and presentation slides. These requirements are designed to give judges a comprehensive view of the project.\\n- **Considerations**\\n- Do not leave commits until the last minute; make regular commits from the start.\\n- The video pitch is the first impression for judges and needs to capture their attention immediately.\\n- While AI can be used for presentations, it is not recommended to use AI to generate the entire video pitch as it can be \'soul destroying\' for judges.\\n- A hosted site and presentation are optional but highly recommended to strengthen your submission.\\n- Do not submit at the last minute to avoid technical issues or mistakes.\\n\\n### Using the ENCODE Platform\\n\\n> The ENCODE platform is the central hub for the hackathon. It contains all necessary information, resources, and submission portals for participants.\\n\\n- **Keypoints**\\n  - The ENCODE platform is the home for the hackathon.\\n  - Participants must register on the platform to get all emails and updates.\\n  - To create a project and team, use the \'create project\' and \'join team code\' features.\\n  - The platform has a \'Lecture\' section with helpful videos.\\n  - The \'Events\' page lists all workshop links.\\n  - Challenge descriptions and partner resources (Comet docs, Gemini credits, etc.) are available on the platform.\\n  - All submissions are made through the participant\'s personal hackathon page on the platform.\\n- **Explanation**\\n  Participants will use the ENCODE platform for all hackathon-related activities. After the introductory session, participants who joined from Luma must register for the hackathon on the platform to receive emails and updates. The platform is where you create your project, add team members using a \'join code\', find lecture videos, access event links for workshops, read detailed challenge descriptions, and find partner resources like the Comet developer documentation and OPIC quick start guide. All submissions, from the mid-hackathon check-in to the final project, will be done through this platform.\\n\\n### Definition of an AI Evaluation\\n\\n> An evaluation is a structured measurement of a system\'s behavior against criteria we care about. This involves defining the vision of success and failure for the application. The process is a structured way to measure an AI system\'s behavior against defined criteria on representative tasks to support decisions and improve product development.\\n\\n- **Keypoints**\\n  - It\'s a structured measurement of a system\'s behavior.\\n  - It\'s measured against predefined criteria that define success.\\n  - The hardest part is often figuring out the criteria you care about.\\n  - It\'s important to think about success, failure, and potential failure modes from the beginning.\\n  - Failure modes can vary, from harmful content and incorrect outputs to having the wrong tone for a brand.\\n  - An evaluation system is often a set of many individual metrics.\\n  - These individual metrics are aggregated into an overall success score.\\n- **Explanation**\\n  To unpack the definition: \'Structure\' means repeatable and explicit, allowing for comparisons over time. \'Behavior\' refers to what the system does, such as responses, tool calls, latency, or cost. \'Criteria\' is how success is predefined, including accuracy, helpfulness, safety, or product-specific outcomes. An evaluation system is typically a set of many metrics aggregated into an overall success score.\\n\\n### The Four Ingredients of a Good Evaluation\\n\\n> A good evaluation generally consists of four main ingredients: a target, a test set/task, a scoring method, and a decision rule. These components work together to form a repeatable and useful evaluation process.\\n\\n- **Keypoints**\\n  - A target: The specific capability or outcome being tested (e.g., factual QA, customer support resolution).\\n  - A test set or task: Examples representing the real world, including edge cases and outliers.\\n  - A scoring method: A metric, rubric, or judge (human or LLM) to score performance, including how individual scores are aggregated (e.g., math equation, voting system).\\n  - A decision rule: Determines what to do with the results, such as shipping a feature, rolling it back, or retraining. It often includes a threshold (e.g., \'if the success rate improves by at least 20%, then ship it\').\\n- **Explanation**\\n  First, the \'target\' specifies the capability or outcome being tested (e.g., factual QA, tool use). Second, the \'test set\' includes real-world examples and edge cases. Third, the \'scoring method\' defines how performance is measured (e.g., a metric, rubric, LLM judge) and how scores are aggregated. Finally, the \'decision rule\' dictates the action to be taken based on the evaluation score, such as shipping a feature or rolling it back, often based on a threshold or comparison to a baseline.\\n\\n### Difference Between Benchmarks and Application Evals\\n\\n> Benchmarks are standardized test sets, often from academia, used for broad comparisons across different models. Application evaluations are specific to a product, matching its real distribution of prompts, workflows, and constraints, and are used to determine if a system is good enough to ship.\\n\\n- **Keypoints**\\n  - Benchmarks are standardized tests for comparing models.\\n  - Application evals are product-specific tests for system performance.\\n  - Benchmarks assess general ability; application evals assess behavior in a specific context.\\n  - Benchmarks score the model in isolation; application evals test the entire system (prompts, RAG, tools).\\n  - The biggest gap is distribution: benchmarks rarely match real traffic, edge cases, or domain language.\\n  - A model can score high on a benchmark but fail in your specific application context.\\n  - Benchmarks help narrow model choices; product evals tell you if the system is ready to ship.\\n- **Explanation**\\n  Benchmarks are useful for getting a quick read on a model\'s general capabilities and comparing model families (e.g., comparing one foundation model to another). However, a model can perform well on a benchmark and still fail in production because production success depends on behavior in a specific context. Application evals test the entire system\u2014including prompts, RAG, and tool use\u2014against your specific definition of success. The main gap is that benchmarks rarely match the distribution of real-world traffic, including edge cases and domain-specific language.\\n\\n### Challenges in Evaluating LLMs\\n\\n> Evaluating LLMs and agentic systems is inherently difficult due to several unique challenges that distinguish them from traditional software. These challenges include non-determinism, the subjectivity of tasks, high sensitivity to inputs, and the possibility of silent failures.\\n\\n- **Keypoints**\\n  - LLMs are non-deterministic: The same input does not guarantee the same output, making traditional monitoring difficult.\\n  - Many AI tasks lack a single correct answer: Tasks like summarization or content generation can have multiple valid outputs, making simple match comparisons insufficient.\\n  - Heuristic methods are largely ineffective: Simple heuristics like regex or pattern matching don\'t consider semantic meaning.\\n  - Evaluation metrics are subjective: Concepts like relevance, coherence, and conciseness are open to interpretation.\\n  - Human feedback is imperfect: It is expensive, can be inconsistent, and is difficult to scale.\\n  - LLMs are extremely sensitive to prompts and context: Small changes can drastically alter the output.\\n  - LLMs have silent failures: A system can produce a correct output but use flawed or unsafe reasoning to get there, which is a failure that isn\'t immediately obvious.\\n  - There\'s no standard set of evaluation metrics applicable to all products.\\n- **Explanation**\\n  LLMs are non-deterministic, meaning the same input can produce different outputs, making hard-coded logic and simple error handling ineffective. Many tasks like summarization have no single correct answer, so simple matching (like regex) fails; semantic meaning must be considered. Metrics like \'relevance\' are subjective, and even human annotators may disagree. LLMs are also very sensitive to small changes in prompts or context. Finally, they can have \'silent failures,\' where the final output appears correct, but the underlying reasoning was flawed or discriminatory, which can only be caught by observing the entire process.\\n- **Examples**\\n  > Traditional software monitoring uses tools like try-and-accept clauses to handle anticipated errors. However, with LLMs, we cannot anticipate every single possible output they might produce due to their non-deterministic nature. Therefore, a simple accept clause is not a scalable or effective solution for handling LLM failures.\\n\\n### Challenges in Monitoring AI Agents\\n\\n> Monitoring AI agents is significantly more complex than monitoring standalone Large Language Models (LLMs) because agents are composed of multiple LLMs and external tools, leading to compounded variability and numerous failure modes.\\n\\n- **Keypoints**\\n  - Agents are built on top of LLMs, inheriting their non-deterministic nature.\\n  - Chaining multiple LLM calls compounds variability and potential for error.\\n  - Agents are multi-step workflows with more moving parts and thus more failure modes.\\n  - The use of external tools introduces external dependencies, potential silent failures, and added unpredictability.\\n  - Dynamic memory and context in agents can lead to intent drift and performance degradation over time.\\n  - Evaluation of agents must include not just the final output, but also the reasoning, tool choice, and every step along the way.\\n- **Explanation**\\n  Agents are built on top of LLMs, which are non-deterministic systems. When you chain multiple LLM calls together, as is common in agents, the variability and potential for error at the beginning of the chain can be amplified through subsequent steps. Agents are also multi-step workflows with more moving parts, external tool dependencies (which can have silent failures), and dynamic memory/context. This complexity increases the number of failure modes and necessitates a more thorough evaluation process that goes beyond just the final output to include reasoning, tool choice, and each intermediate step. As agents are deployed in real-world scenarios with more complex workflows and higher usage frequency, tracking all these aspects becomes extremely difficult.\\n- **Examples**\\n  > A user engaged with a dealership\'s chatbot and managed to get it to agree to sell them a Chevy Tahoe for one US dollar. The chatbot even stated \'no takesies backsies\'. This agreement was legally upheld in court, forcing the dealership to sell the car for one dollar.\\n  - This example illustrates a real-world consequence of an AI agent (chatbot) going wrong.\\n  - The non-deterministic and unconstrained nature of the LLM powering the chatbot led to an unintended and costly outcome for the dealership.\\n  - It highlights the critical need for robust monitoring and evaluation of agent behavior to prevent such incidents.\\n  - The phrase \'no takesies backsies\' being considered legally binding underscores how interactions with AI can have unforeseen legal ramifications.\\n\\n### Hackathon Logistics and Rules\\n\\n> The \'Resolve to Evolve\' Hackathon is an event where participants build AI or LLM-powered applications to help people maintain their New Year\'s resolutions. The event has specific rules regarding submissions, team formation, judging, and tooling.\\n\\n- **Keypoints**\\n  - Objective: Build an AI/LLM-powered app to help with New Year\'s resolutions.\\n  - Team Formation: Solo or teams of any size are permitted (recommendation: 5 or less).\\n  - Submissions: You can submit to multiple tracks but win at most one.\\n  - Prizing: $5,000 for each of the five themes, plus a $5,000 special prize for the best use of OPIC.\\n  - Required Tooling: OPIC must be used for evaluation.\\n  - Allowed Tooling: Any LLM (e.g., Gemini, etc.) can be used.\\n  - Submission deliverable: A video demo is a mandatory and critical part of the submission, presenting the project and its functionality.\\n  - Project Scope: Build an MVP. Full production-ready apps are not expected.\\n  - Timeline: The hackathon has started, and coding can begin now. It lasts approximately 28 days.\\n  - Prior Work: You can build on a pre-existing project, but only functionality added during the hackathon will be judged.\\n- **Explanation**\\n  Participants are tasked with creating an MVP (Minimum Viable Product) of a web or mobile app. They can work solo or in teams of any size, though teams of 5 or fewer are recommended. Submissions can target multiple prize categories, but a project can only win one. Judging criteria are available on the hackathon platform. A key component of the submission is a video demo that serves as both a product pitch and a functional walkthrough. While participants can use any LLM, they are required to use OPIC for evaluation. The hackathon provides access to partner services with generous free tiers instead of specific credits. Participants can start coding immediately and can even build upon existing projects, but only work done during the hackathon period will be judged.\\n- **Special Circumstances**\\n- If building a mobile app that cannot be easily shared or hosted for judging, a very thorough demo video showing all functionality is sufficient.\\n- If you want to work on a project you have already started, you can, but you will only be judged on the new functionality and features built during the hackathon period.\\n\\n## Assignments & Suggestions\\n\\n- If you are joining from Luma, go into your programs page and register for the hackathon after the session.\\n- If you have questions that aren\'t answered live, put them in the Q&A to be answered in the Discord.\\n- Decide on the project you want to build, the theme to focus on, the solution to come up with, and what makes it special during the ideation stage in week one.\\n- By the project creation deadline at the end of week one, create and commit to the project idea, the challenge theme, and add team members.\\n- Start the building process in week two.\\n- For the mid-hackathon deadline, submit your publicly available GitHub repo and a fuller description of what you\'re building.\\n- For the final submission deadline on February 8th, submit a video pitch including a product demo, your public code base, a hosted site (optional but recommended), and a presentation (optional but recommended).\\n- Watch the helpful, short lecture videos on the platform to prepare for workshops and the wider hackathon.\\n- Run the code from the QR code provided to see how evaluations are created and look in OPIC. The QR code leads to a simple recipe generator agent in a GitHub gist. You need to copy the script, follow the directions for creating online evaluations, create a Comet account if you don\'t have one (it\'s free), and add your API key."},{"id":"locki-in-2025","metadata":{"permalink":"/fr/blog/locki-in-2025","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2025-01-15-locki-in-2025.mdx","source":"@site/blog/2025-01-15-locki-in-2025.mdx","title":"Locki Labs in 2025 - Introducing Valkyria","description":"After months of development on our horse racing analysis platform, we\'re taking a bold step forward. In 2025, Locki Labs shifts focus from real-time data aggregation to something far more ambitious: Valkyria \u2014 a temporal prediction system designed for scientific rigor and reproducible results.","date":"2025-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Locki Labs","permalink":"/fr/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"AI and Machine Learning","permalink":"/fr/blog/tags/ai-ml","description":"Articles on AI, machine learning, and related technologies"},{"inline":false,"label":"Temporal Predictions","permalink":"/fr/blog/tags/temporal-predictions","description":"Insights into temporal prediction models and applications"},{"inline":false,"label":"Machine Learning","permalink":"/fr/blog/tags/machine-learning","description":"Articles on machine learning and related technologies"}],"readingTime":3.94,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"locki-in-2025","title":"Locki Labs in 2025 - Introducing Valkyria","authors":["jnxmas"],"tags":["locki","valkyria","temporal-predictions","machine-learning"]},"unlisted":false,"prevItem":{"title":"Hackathon kickoff meeting","permalink":"/fr/blog/encode-kickoff"},"nextItem":{"title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","permalink":"/fr/blog/locki-journey-2023-2025"}},"content":"After months of development on our horse racing analysis platform, we\'re taking a bold step forward. In 2025, Locki Labs shifts focus from real-time data aggregation to something far more ambitious: **Valkyria** \u2014 a temporal prediction system designed for scientific rigor and reproducible results.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Problem We Set Out to Solve\\n\\nOur existing platform excels at real-time race analysis. But we discovered a fundamental limitation when it came to developing prediction models: **temporal blindness**.\\n\\nWhen analyzing a historical race from, say, November 16th, our system would use horse data from _today_ \u2014 including races that happened _after_ the race we\'re analyzing. This is called **data leakage**, and it makes prediction models unreliable.\\n\\n```\\nScenario: Analyzing a race from November 16, 2025\\n\\n\u274c Current approach:\\n   Uses horse career data as of TODAY\\n   \u2192 Includes future races (data leakage)\\n   \u2192 Predictions are scientifically invalid\\n\\n\u2705 Valkyria approach:\\n   Uses horse career data as of November 16\\n   \u2192 Only past information available\\n   \u2192 Predictions are reproducible and valid\\n```\\n\\n## What is Valkyria?\\n\\nValkyria is a **temporal prediction laboratory** \u2014 a system that can reproduce predictions with historical accuracy. The core principle is simple but powerful:\\n\\n> **Analyze any race using only the data that would have been available at that exact moment in time.**\\n\\nThis enables:\\n\\n- **Time-Travel Analysis**: Query any race from the past 18 months with temporally-accurate data\\n- **Model Training**: Train prediction algorithms on clean, causally-valid datasets\\n- **Backtesting**: Validate strategies on historical races without information leakage\\n- **Reproducibility**: Same race, same analysis, same results \u2014 every time\\n\\n## The Three-Tier Architecture\\n\\nValkyria operates on a three-tier temporal system:\\n\\n### Tier 1: Real-Time (48 hours)\\n\\nLive operations for current and upcoming races. Odds tracking, race analysis, chat features \u2014 all powered by Redis cache with 15-minute refresh cycles.\\n\\n### Tier 2: Recent History (7 days)\\n\\nFast access to recently finished races. Runner snapshots stored in Redis with file backup for durability.\\n\\n### Tier 3: Historical Archive (18 months)\\n\\n**This is the innovation.** A SQLite-based temporal database containing runner snapshots \u2014 immutable records of each horse\'s state at race time. No future information, ever.\\n\\n## Campaign-Based Population\\n\\nRather than fetching all historical data upfront, Valkyria uses a **campaign-based approach**:\\n\\n| Campaign | Period       | Estimated Races | Status   |\\n| -------- | ------------ | --------------- | -------- |\\n| Q4-2025  | Oct-Dec 2025 | ~4,500          | Priority |\\n| Q3-2025  | Jul-Sep 2025 | ~4,500          | Next     |\\n| Q2-2025  | Apr-Jun 2025 | ~4,500          | Planned  |\\n\\nEach campaign represents a 3-month slice of racing data, populated incrementally during off-peak hours. The database grows organically while maintaining full temporal accuracy.\\n\\n## Model Unification: One Model, Multiple Lifecycles\\n\\nA key architectural decision: **CanonicalRunner** becomes the single source of truth across all lifecycle stages:\\n\\n1. **Pre-Race**: Upcoming participant with updating odds\\n2. **Post-Race**: Finished runner with final results\\n3. **Career History**: Stored snapshot for temporal queries\\n\\nThis eliminates 88% of field duplication from our previous dual-model system and ensures consistency across the entire platform.\\n\\n## What This Means for Predictions\\n\\nWith Valkyria, we can finally build prediction models with scientific integrity:\\n\\n```\\nHistorical snapshots (18 months)\\n    \u2193\\nFeature engineering (career metrics, confrontations)\\n    \u2193\\nModel training (XGBoost, Neural Networks)\\n    \u2193\\nBacktesting (temporal validation)\\n    \u2193\\nProduction deployment (high confidence)\\n```\\n\\nWe\'ll be able to:\\n\\n- Compare multiple models on the same historical data\\n- Calculate accuracy by race type (HARNESS, FLAT, Quint\xe9)\\n- Calibrate confidence scores based on actual performance\\n- Generate algorithmic selections with transparent methodology\\n\\n## The Road Ahead\\n\\nValkyria development follows a phased approach:\\n\\n**Foundation** \u2014 Database schema, storage functions, basic snapshot capabilities\\n\\n**Daily Population** \u2014 Automated jobs to capture yesterday\'s races every night\\n\\n**Workflow Integration** \u2014 Career workflows query the temporal database for historical analysis\\n\\n**Campaign Population** \u2014 Bulk population of 3-month historical periods\\n\\n**Model Unification** \u2014 Full migration to CanonicalRunner across all analyzers\\n\\nEach phase delivers value independently. If we complete only the foundation and daily population, we still have a working temporal snapshot system. The full vision builds incrementally.\\n\\n## Storage & Retention\\n\\nThe numbers are reassuring:\\n\\n- **18 months of racing**: ~27,000 races, ~324,000 runner snapshots\\n- **Storage requirement**: ~486 MB\\n- **Cleanup policy**: Monthly removal of data older than 18 months\\n\\nSQLite handles this efficiently, and the system remains lightweight.\\n\\n## Why This Matters\\n\\nWithout temporal accuracy, predictions are anecdotal. With Valkyria:\\n\\n- \u2705 **Causal validity**: Only past data influences predictions\\n- \u2705 **Reproducibility**: Results can be verified and replicated\\n- \u2705 **Testability**: Objective performance metrics across historical data\\n- \u2705 **Confidence**: Know when and where models perform reliably\\n\\nThis isn\'t just a technical improvement \u2014 it\'s the foundation for next-generation prediction algorithms built on scientific rigor rather than intuition.\\n\\n## Looking Forward\\n\\n2025 marks a transition for Locki Labs. We\'re moving from \\"what does the data say right now?\\" to \\"what would we have known then, and how can we learn from it?\\"\\n\\nValkyria represents our commitment to building prediction systems we can trust, test, and continuously improve. One snapshot at a time.\\n\\n---\\n\\n_Stay tuned for updates as we progress through the Valkyria implementation phases._"},{"id":"locki-journey-2023-2025","metadata":{"permalink":"/fr/blog/locki-journey-2023-2025","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2023-09-29-locki-labs-journey.mdx","source":"@site/blog/2023-09-29-locki-labs-journey.mdx","title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","description":"Locki started as a vision during the Encode MultiversX Hackathon in October 2023, with the ambitious goal of creating a decentralized platform for minting, viewing, and interacting with 3D Data NFTs using the Itheum protocol.","date":"2024-01-15T00:00:00.000Z","tags":[{"inline":false,"label":"Locki Labs","permalink":"/fr/blog/tags/locki-labs","description":"Startup adventures at Locki Labs still in formation"},{"inline":false,"label":"Blockchain","permalink":"/fr/blog/tags/blockchain","description":"Articles related to blockchain technology"},{"inline":false,"label":"MultiversX","permalink":"/fr/blog/tags/multiversx","description":"Content about the MultiversX ecosystem"},{"inline":false,"label":"Itheum","permalink":"/fr/blog/tags/itheum","description":"Posts regarding Itheum platform"},{"inline":false,"label":"RAG","permalink":"/fr/blog/tags/rag","description":"Retrieval-Augmented Generation topics"},{"inline":false,"label":"Web3 Technologies","permalink":"/fr/blog/tags/web3","description":"Discussions on Web3 technologies and trends"}],"readingTime":3.43,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"locki-journey-2023-2025","title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","authors":["jnxmas"],"tags":["locki","blockchain","multiversx","itheum","rag","web3"],"date":"2024-01-15T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Locki Labs in 2025 - Introducing Valkyria","permalink":"/fr/blog/locki-in-2025"},"nextItem":{"title":"Locki blog introduction","permalink":"/fr/blog/help me write in the blog"}},"content":"Locki started as a vision during the **Encode MultiversX Hackathon in October 2023**, with the ambitious goal of creating a decentralized platform for minting, viewing, and interacting with 3D Data NFTs using the Itheum protocol.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Current Status\\n\\n:::info Project Status\\n\\nLocki dApp is currently in **alpha phase** on MultiversX devnet, and has been supported by the **xPand Itheum program**.\\n\\n:::\\n\\nThe platform has evolved significantly since its inception, now featuring:\\n\\n- **3D Data NFT minting and visualization** using Three.js and React Three Fiber\\n- **AI-powered chat assistant** for Blender Python scripting guidance\\n- **Whitelist management system** for controlled access\\n- **Integration with MultiversX wallets** including xAlias support\\n\\n## The Challenge of Collecting RAG Data and Intellectual Property\\n\\nOne of the most significant hurdles we\'ve encountered is **building a quality dataset for our RAG (Retrieval-Augmented Generation) system** while respecting intellectual property rights.\\n\\n### The IP Dilemma\\n\\nCreating an effective AI assistant for 3D modeling and Blender scripting requires extensive training data:\\n\\n- **Documentation licensing**: Much of the best Blender documentation exists under various licenses that complicate commercial use\\n- **Community content**: Forum posts, tutorials, and Stack Exchange answers have complex attribution requirements\\n- **Proprietary scripts**: Many advanced Blender scripts are commercial products with restrictive licenses\\n- **Version fragmentation**: Blender\'s rapid release cycle means documentation quickly becomes outdated\\n\\n### Our Approach\\n\\nWe\'ve had to carefully curate our data sources, focusing on:\\n\\n1. **Open-source documentation** with permissive licenses\\n2. **Original content creation** to fill knowledge gaps\\n3. **User-generated content** with explicit consent\\n4. **Partnerships** with content creators in the Blender ecosystem\\n\\n:::tip Locki Companion Status\\n\\nThe Locki companion AI feature is currently **on pause** while we navigate these data collection challenges and ensure full compliance with IP rights.\\n\\n:::\\n\\n## Technical Challenges: The Blockchain Moving Target\\n\\nPerhaps the most demanding aspect of maintaining Locki has been keeping pace with the **rapid evolution of blockchain infrastructure**.\\n\\n### SDK Version Churn\\n\\nThe MultiversX ecosystem has undergone substantial changes:\\n\\n```json\\n// Our current dependency snapshot\\n\\"@multiversx/sdk-core\\": \\"12.18.0\\",\\n\\"@multiversx/sdk-dapp\\": \\"2.28.7\\",\\n\\"@multiversx/sdk-network-providers\\": \\"2.3.0\\",\\n\\"@itheum/sdk-mx-data-nft\\": \\"2.7.0-beta.4\\"\\n```\\n\\nEach major version brings:\\n\\n- **Breaking API changes** requiring code refactoring\\n- **New authentication patterns** (we\'ve integrated xAlias, native auth tokens)\\n- **Smart contract interface updates** affecting our ABI integrations\\n- **Wallet provider deprecations** forcing migration to new connection methods\\n\\n### Specific Challenges We\'ve Faced\\n\\n1. **SSR Compatibility**: Next.js App Router with blockchain SDKs requires careful dynamic imports to avoid server-side rendering issues\\n\\n2. **Transaction Handling**: The move from legacy transaction signing to the new `signAndSendTransactions` utility required substantial refactoring\\n\\n3. **Smart Contract ABIs**: Contract updates on devnet mean our local ABIs must be continuously synchronized\\n\\n4. **Network Provider Changes**: API endpoint changes and rate limiting adjustments have required multiple backend adaptations\\n\\n### The Maintenance Burden\\n\\n```\\nRecent commits reflecting ongoing maintenance:\\n- \\"Upgrade: Status locki companion\\"\\n- \\"fix vulnerabilities\\"\\n- \\"Fixed build issues\\"\\n- \\"Fixes smart contract dependencies and code refactoring\\"\\n```\\n\\nEach vulnerability fix in upstream dependencies cascades through our codebase. The security-conscious nature of blockchain applications means we cannot defer these updates.\\n\\n## Lessons Learned\\n\\n### For Blockchain Developers\\n\\n1. **Abstract your SDK interactions**: Create wrapper classes (like our `baseSmartContract.ts`) to isolate breaking changes\\n2. **Pin versions carefully**: Use exact versions in production, but test against latest regularly\\n3. **Monitor ecosystem announcements**: Join Discord channels and follow GitHub releases\\n4. **Build with deprecation in mind**: What works today may be obsolete in 6 months\\n\\n### For AI/RAG Builders\\n\\n1. **Document your data sources**: Track provenance from day one\\n2. **Build consent mechanisms**: Make it easy for users to contribute data with clear licensing\\n3. **Plan for re-training**: Your model will need updates as source material evolves\\n4. **Consider synthetic data**: Generate training examples where real data is restricted\\n\\n## What\'s Next for Locki\\n\\nDespite these challenges, we remain committed to the vision:\\n\\n- **Mainnet deployment** once alpha testing is complete\\n- **Enhanced 3D NFT features** with improved GLTF/GLB support\\n- **Expanded AI capabilities** with properly licensed training data\\n- **Community governance** for whitelist and platform decisions\\n\\n---\\n\\n_Locki is an open-source project. We welcome contributors who share our passion for decentralized 3D asset ownership and AI-assisted creativity._\\n\\n**Special Collections on MultiversX Devnet:**\\n\\n- `DATANFTFT-e0b917`\\n- `I3TICKER-03e5c2`\\n- `COLNAMA-539838`"},{"id":"help me write in the blog","metadata":{"permalink":"/fr/blog/help me write in the blog","editUrl":"https://github.com/locki-io/docs.locki.io/tree/main/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Locki blog introduction","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/fr/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/fr/blog/tags/hello","description":"Hello tag description"}],"readingTime":0.85,"hasTruncateMarker":true,"authors":[{"name":"Jean-No\xebl Schilling","title":"Locki one / french maintainer","url":"https://github.com/jnschilling","socials":{"linkedin":"https://www.linkedin.com/in/jnschilling/","github":"https://github.com/jnschilling","newsletter":"https://www.stratej.fr"},"imageURL":"https://github.com/jnschilling.png","key":"jnxmas","page":null}],"frontMatter":{"slug":"help me write in the blog","title":"Locki blog introduction","authors":["jnxmas"],"tags":["facebook","hello"]},"unlisted":false,"prevItem":{"title":"Locki Labs: From Hackathon to Production - Navigating Blockchain Evolution and Data Challenges","permalink":"/fr/blog/locki-journey-2023-2025"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\n\\n:::tip\\nThe blog is interesting because it allows our agent in cursor and claude code to dive into our reflexion to have a set of the status and the priorities of the project.\\nUse it referencing our discussion for your feature branches.\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n:::tip\\nThe blog is interesting because it allows our agent in cursor and claude code to dive into our reflexion to have a set of the status and the priorities of the project.\\nUse it referencing our discussion for your feature branches.\\n:::\\nSimply add Markdown files (or folders) to the `blog` directory.\\n\\nRegular blog authors can be added to `authors.yml`.\\n\\nThe blog post date can be extracted from filenames, such as:\\n\\n- `2019-05-30-welcome.md`\\n- `2019-05-30-welcome/index.md`\\n\\nA blog post folder can be convenient to co-locate blog post images:\\n\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\\n\\nThe blog supports tags as well!"}]}}')}}]);